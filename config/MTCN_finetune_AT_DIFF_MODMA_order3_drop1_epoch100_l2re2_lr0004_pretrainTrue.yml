batch_size: 64
beta1: 0.93
beta2: 0.98
d_ff: 1024
d_model: 256
d_qkv: 64
data_type: mfcc
dataset_name: MODMA
dilation: 8
drop_rate: 0.1
epochs: 100
feature_dim: 39
filters: 39
gamma: 0.3
initial_lr: 0.05
kernel_size: 2
load_weight: true
lr: 0.0004
merge_type: linear
model_name: MTCN_finetune_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue
model_type: MTCN
multi_type: AT_DIFF
n_head: 8
n_layer: 3
num_class: 2
optimizer_type: 2
order: 3
patience: 10
pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt
random_seed: 34
save: true
scheduler_type: 1
seq_len: 313
spilt_rate:
- 0.6
- 0.2
- 0.2
step_size: 30
version: V1
warmup: 400
weight_decay: 0.2
