========================	2023-03-19 15:56:23	========================
model name: 	model_drop1_mfcc_smoothTrue_epoch50_l2re1_lr0001
addition: 	d_model: 256, n_head: 8, d_qkv: 64, d_ff: 1024, n_layer: 4	dilation: 6, filters: 39, drop_rate: 0.1	seq_len: 313, scheduler_type: 0	

========================	train begin	========================
train(final): 		train loss: 0.2761	 train accuracy: 99.434	 validation loss: 0.2791	 validation accuracy: 87.500 
train(max_min): 	train loss: 0.2761	 train accuracy: 99.575	 validation loss: 0.2602	 validation accuracy: 91.667 
best val accuracy: 91.666667 	 corresponding train accuracy: 91.552619
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2651 	 test accuracy:	 90.602 
confusion matrix: 
[149  15]
[10 92]

classification report: 
              precision    recall  f1-score   support

          HC       0.94      0.91      0.92       164
         MDD       0.86      0.90      0.88       102

    accuracy                           0.91       266
   macro avg       0.90      0.91      0.90       266
weighted avg       0.91      0.91      0.91       266

========================	test end	========================

========================	2023-03-22 17:07:51	========================
model name: 	pretrain_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002
addition: 	parameter setting:	mode: pretrain	model_name: pretrain_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002	epochs: 80	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.6289	 train accuracy: 96.339	 validation loss: 0.4046	 validation accuracy: 87.467 
train(max_min): 	train loss: 0.6267	 train accuracy: 96.772	 validation loss: 0.2208	 validation accuracy: 94.133 
best val accuracy: 94.133333 	 corresponding train accuracy: 95.540765
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2526 	 test accuracy:	 93.369 
confusion matrix: 
[44  5  0  0  0  0]
[ 7 42  0  0  0  0]
[  0   0 105   3   0   0]
[ 0  0 10 21  0  0]
[ 0  0  0  0 74  0]
[ 0  0  0  0  0 66]

classification report: 
              precision    recall  f1-score   support

       angry       0.86      0.90      0.88        49
     excited       0.89      0.86      0.88        49
  frustrated       0.91      0.97      0.94       108
       happy       0.88      0.68      0.76        31
     neutral       1.00      1.00      1.00        74
         sad       1.00      1.00      1.00        66

    accuracy                           0.93       377
   macro avg       0.92      0.90      0.91       377
weighted avg       0.93      0.93      0.93       377

========================	test end	========================

========================	2023-03-22 17:47:47	========================
model name: 	pretrain_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002
addition: 	parameter setting:	mode: pretrain	model_name: pretrain_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002	epochs: 80	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.6469	 train accuracy: 95.507	 validation loss: 0.2975	 validation accuracy: 91.467 
train(max_min): 	train loss: 0.6449	 train accuracy: 96.073	 validation loss: 0.2895	 validation accuracy: 92.267 
best val accuracy: 92.266667 	 corresponding train accuracy: 95.574043
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2900 	 test accuracy:	 93.103 
confusion matrix: 
[47  2  0  0  0  0]
[ 5 44  0  0  0  0]
[  0   0 105   2   1   0]
[ 0  0 16 15  0  0]
[ 0  0  0  0 74  0]
[ 0  0  0  0  0 66]

classification report: 
              precision    recall  f1-score   support

       angry       0.90      0.96      0.93        49
     excited       0.96      0.90      0.93        49
  frustrated       0.87      0.97      0.92       108
       happy       0.88      0.48      0.62        31
     neutral       0.99      1.00      0.99        74
         sad       1.00      1.00      1.00        66

    accuracy                           0.93       377
   macro avg       0.93      0.89      0.90       377
weighted avg       0.93      0.93      0.93       377

========================	test end	========================

========================	2023-03-22 20:23:28	========================
model name: 	pretrain_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002
addition: 	parameter setting:	mode: pretrain	model_name: pretrain_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002	epochs: 80	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.5766	 train accuracy: 96.606	 validation loss: 0.2234	 validation accuracy: 93.333 
train(max_min): 	train loss: 0.5766	 train accuracy: 96.972	 validation loss: 0.2205	 validation accuracy: 93.333 
best val accuracy: 93.333333 	 corresponding train accuracy: 96.772047
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2399 	 test accuracy:	 92.838 
confusion matrix: 
[45  4  0  0  0  0]
[ 6 43  0  0  0  0]
[  0   0 106   2   0   0]
[ 0  0 15 16  0  0]
[ 0  0  0  0 74  0]
[ 0  0  0  0  0 66]

classification report: 
              precision    recall  f1-score   support

       angry       0.88      0.92      0.90        49
     excited       0.91      0.88      0.90        49
  frustrated       0.88      0.98      0.93       108
       happy       0.89      0.52      0.65        31
     neutral       1.00      1.00      1.00        74
         sad       1.00      1.00      1.00        66

    accuracy                           0.93       377
   macro avg       0.93      0.88      0.90       377
weighted avg       0.93      0.93      0.92       377

========================	test end	========================

========================	2023-03-22 20:43:48	========================
model name: 	pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002
addition: 	parameter setting:	mode: pretrain	model_name: pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002	epochs: 100	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.5833	 train accuracy: 97.238	 validation loss: 0.1999	 validation accuracy: 94.133 
train(max_min): 	train loss: 0.5831	 train accuracy: 97.304	 validation loss: 0.1441	 validation accuracy: 96.267 
best val accuracy: 96.266667 	 corresponding train accuracy: 96.539101
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1533 	 test accuracy:	 96.552 
confusion matrix: 
[43  6  0  0  0  0]
[ 4 45  0  0  0  0]
[  0   0 108   0   0   0]
[ 0  0  3 28  0  0]
[ 0  0  0  0 74  0]
[ 0  0  0  0  0 66]

classification report: 
              precision    recall  f1-score   support

       angry       0.91      0.88      0.90        49
     excited       0.88      0.92      0.90        49
  frustrated       0.97      1.00      0.99       108
       happy       1.00      0.90      0.95        31
     neutral       1.00      1.00      1.00        74
         sad       1.00      1.00      1.00        66

    accuracy                           0.97       377
   macro avg       0.96      0.95      0.96       377
weighted avg       0.97      0.97      0.97       377

========================	test end	========================

========================	2023-03-22 21:29:03	========================
model name: 	pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002
addition: 	parameter setting:	mode: pretrain	model_name: pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002	epochs: 100	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	2023-03-22 21:30:25	========================
model name: 	pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002
addition: 	parameter setting:	mode: pretrain	model_name: pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002	epochs: 100	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	test begin	========================
test: 			test loss: 	0.1533 	 test accuracy:	 96.552 
confusion matrix: 
[43  6  0  0  0  0]
[ 4 45  0  0  0  0]
[  0   0 108   0   0   0]
[ 0  0  3 28  0  0]
[ 0  0  0  0 74  0]
[ 0  0  0  0  0 66]

classification report: 
              precision    recall  f1-score   support

       angry       0.91      0.88      0.90        49
     excited       0.88      0.92      0.90        49
  frustrated       0.97      1.00      0.99       108
       happy       1.00      0.90      0.95        31
     neutral       1.00      1.00      1.00        74
         sad       1.00      1.00      1.00        66

    accuracy                           0.97       377
   macro avg       0.96      0.95      0.96       377
weighted avg       0.97      0.97      0.97       377

========================	test end	========================

========================	2023-03-22 21:31:26	========================
model name: 	pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002
addition: 	parameter setting:	mode: pretrain	model_name: pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002	epochs: 100	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	2023-03-22 21:32:04	========================
model name: 	pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002
addition: 	parameter setting:	mode: pretrain	model_name: pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002	epochs: 100	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	test begin	========================
test: 			test loss: 	0.1533 	 test accuracy:	 96.552 
confusion matrix: 
[43  6  0  0  0  0]
[ 4 45  0  0  0  0]
[  0   0 108   0   0   0]
[ 0  0  3 28  0  0]
[ 0  0  0  0 74  0]
[ 0  0  0  0  0 66]

classification report: 
              precision    recall  f1-score   support

       angry       0.91      0.88      0.90        49
     excited       0.88      0.92      0.90        49
  frustrated       0.97      1.00      0.99       108
       happy       1.00      0.90      0.95        31
     neutral       1.00      1.00      1.00        74
         sad       1.00      1.00      1.00        66

    accuracy                           0.97       377
   macro avg       0.96      0.95      0.96       377
weighted avg       0.97      0.97      0.97       377

========================	test end	========================

========================	2023-03-22 21:32:26	========================
model name: 	pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002
addition: 	parameter setting:	mode: pretrain	model_name: pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002	epochs: 100	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	test begin	========================
test: 			test loss: 	0.1533 	 test accuracy:	 96.552 
confusion matrix: 
[43  6  0  0  0  0]
[ 4 45  0  0  0  0]
[  0   0 108   0   0   0]
[ 0  0  3 28  0  0]
[ 0  0  0  0 74  0]
[ 0  0  0  0  0 66]

classification report: 
              precision    recall  f1-score   support

       angry       0.91      0.88      0.90        49
     excited       0.88      0.92      0.90        49
  frustrated       0.97      1.00      0.99       108
       happy       1.00      0.90      0.95        31
     neutral       1.00      1.00      1.00        74
         sad       1.00      1.00      1.00        66

    accuracy                           0.97       377
   macro avg       0.96      0.95      0.96       377
weighted avg       0.97      0.97      0.97       377

========================	test end	========================

========================	2023-03-22 21:33:09	========================
model name: 	pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002
addition: 	parameter setting:	mode: pretrain	model_name: pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002	epochs: 100	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	test begin	========================
test: 			test loss: 	0.1533 	 test accuracy:	 96.552 
confusion matrix: 
[43  6  0  0  0  0]
[ 4 45  0  0  0  0]
[  0   0 108   0   0   0]
[ 0  0  3 28  0  0]
[ 0  0  0  0 74  0]
[ 0  0  0  0  0 66]

classification report: 
              precision    recall  f1-score   support

       angry       0.91      0.88      0.90        49
     excited       0.88      0.92      0.90        49
  frustrated       0.97      1.00      0.99       108
       happy       1.00      0.90      0.95        31
     neutral       1.00      1.00      1.00        74
         sad       1.00      1.00      1.00        66

    accuracy                           0.97       377
   macro avg       0.96      0.95      0.96       377
weighted avg       0.97      0.97      0.97       377

========================	test end	========================

========================	2023-03-22 21:34:04	========================
model name: 	pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002
addition: 	parameter setting:	mode: pretrain	model_name: pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002	epochs: 100	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	test begin	========================
test: 			test loss: 	0.1533 	 test accuracy:	 96.552 
confusion matrix: 
[43  6  0  0  0  0]
[ 4 45  0  0  0  0]
[  0   0 108   0   0   0]
[ 0  0  3 28  0  0]
[ 0  0  0  0 74  0]
[ 0  0  0  0  0 66]

classification report: 
              precision    recall  f1-score   support

       angry       0.91      0.88      0.90        49
     excited       0.88      0.92      0.90        49
  frustrated       0.97      1.00      0.99       108
       happy       1.00      0.90      0.95        31
     neutral       1.00      1.00      1.00        74
         sad       1.00      1.00      1.00        66

    accuracy                           0.97       377
   macro avg       0.96      0.95      0.96       377
weighted avg       0.97      0.97      0.97       377

========================	test end	========================

========================	2023-03-22 21:34:53	========================
model name: 	pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002
addition: 	parameter setting:	mode: pretrain	model_name: pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002	epochs: 100	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	test begin	========================
test: 			test loss: 	0.1533 	 test accuracy:	 96.552 
confusion matrix: 
[43  6  0  0  0  0]
[ 4 45  0  0  0  0]
[  0   0 108   0   0   0]
[ 0  0  3 28  0  0]
[ 0  0  0  0 74  0]
[ 0  0  0  0  0 66]

classification report: 
              precision    recall  f1-score   support

       angry       0.91      0.88      0.90        49
     excited       0.88      0.92      0.90        49
  frustrated       0.97      1.00      0.99       108
       happy       1.00      0.90      0.95        31
     neutral       1.00      1.00      1.00        74
         sad       1.00      1.00      1.00        66

    accuracy                           0.97       377
   macro avg       0.96      0.95      0.96       377
weighted avg       0.97      0.97      0.97       377

========================	test end	========================

========================	2023-03-22 21:36:02	========================
model name: 	pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002
addition: 	parameter setting:	mode: pretrain	model_name: pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002	epochs: 100	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	test begin	========================
test: 			test loss: 	0.1533 	 test accuracy:	 96.552 
confusion matrix: 
[43  6  0  0  0  0]
[ 4 45  0  0  0  0]
[  0   0 108   0   0   0]
[ 0  0  3 28  0  0]
[ 0  0  0  0 74  0]
[ 0  0  0  0  0 66]

classification report: 
              precision    recall  f1-score   support

       angry       0.91      0.88      0.90        49
     excited       0.88      0.92      0.90        49
  frustrated       0.97      1.00      0.99       108
       happy       1.00      0.90      0.95        31
     neutral       1.00      1.00      1.00        74
         sad       1.00      1.00      1.00        66

    accuracy                           0.97       377
   macro avg       0.96      0.95      0.96       377
weighted avg       0.97      0.97      0.97       377

========================	test end	========================

========================	2023-03-22 22:29:44	========================
model name: 	train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002
addition: 	parameter setting:	mode: train	model_name: train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002	epochs: 80	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: True	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-03-22 22:38:50	========================
model name: 	train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainTrue	epochs: 80	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: True	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-03-22 22:42:15	========================
model name: 	train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainTrue	epochs: 80	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: True	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2279	 train accuracy: 99.953	 validation loss: 0.0987	 validation accuracy: 95.880 
train(max_min): 	train loss: 0.2273	 train accuracy: 100.000	 validation loss: 0.0937	 validation accuracy: 96.629 
best val accuracy: 96.629213 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0614 	 test accuracy:	 98.885 
confusion matrix: 
[153   3]
[  0 113]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.98      0.99       156
         MDD       0.97      1.00      0.99       113

    accuracy                           0.99       269
   macro avg       0.99      0.99      0.99       269
weighted avg       0.99      0.99      0.99       269

========================	test end	========================

========================	2023-03-22 23:01:38	========================
model name: 	train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainFalse	epochs: 80	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-03-22 23:02:29	========================
model name: 	train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainFalse	epochs: 80	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-03-22 23:05:52	========================
model name: 	train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainFalse	epochs: 80	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2329	 train accuracy: 99.860	 validation loss: 0.1558	 validation accuracy: 95.506 
train(max_min): 	train loss: 0.2317	 train accuracy: 99.907	 validation loss: 0.1333	 validation accuracy: 96.255 
best val accuracy: 96.254682 	 corresponding train accuracy: 99.906586
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0964 	 test accuracy:	 97.770 
confusion matrix: 
[155   1]
[  5 108]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       156
         MDD       0.99      0.96      0.97       113

    accuracy                           0.98       269
   macro avg       0.98      0.97      0.98       269
weighted avg       0.98      0.98      0.98       269

========================	test end	========================

========================	2023-03-23 08:23:53	========================
model name: 	train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainFalse	epochs: 80	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2333	 train accuracy: 99.813	 validation loss: 0.1432	 validation accuracy: 95.506 
train(max_min): 	train loss: 0.2319	 train accuracy: 99.953	 validation loss: 0.1039	 validation accuracy: 97.004 
best val accuracy: 97.003745 	 corresponding train accuracy: 98.645493
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0848 	 test accuracy:	 97.026 
confusion matrix: 
[150   6]
[  2 111]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.96      0.97       156
         MDD       0.95      0.98      0.97       113

    accuracy                           0.97       269
   macro avg       0.97      0.97      0.97       269
weighted avg       0.97      0.97      0.97       269

========================	test end	========================

========================	2023-03-23 08:31:27	========================
model name: 	train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: train_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainTrue	epochs: 80	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: True	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2303	 train accuracy: 99.953	 validation loss: 0.1139	 validation accuracy: 96.255 
train(max_min): 	train loss: 0.2302	 train accuracy: 100.000	 validation loss: 0.0916	 validation accuracy: 97.378 
best val accuracy: 97.378277 	 corresponding train accuracy: 99.532929
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0681 	 test accuracy:	 99.257 
confusion matrix: 
[154   2]
[  0 113]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       156
         MDD       0.98      1.00      0.99       113

    accuracy                           0.99       269
   macro avg       0.99      0.99      0.99       269
weighted avg       0.99      0.99      0.99       269

========================	test end	========================


========================	2023-03-25 09:03:29	========================
model name: 	train_order1_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: train_order1_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainFalse	epochs: 80	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: False	order: 1	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 13	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2366	 train accuracy: 99.813	 validation loss: 0.0767	 validation accuracy: 98.127 
train(max_min): 	train loss: 0.2366	 train accuracy: 99.907	 validation loss: 0.0739	 validation accuracy: 98.127 
best val accuracy: 98.127341 	 corresponding train accuracy: 99.906586
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0534 	 test accuracy:	 98.513 
confusion matrix: 
[153   3]
[  1 112]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       156
         MDD       0.97      0.99      0.98       113

    accuracy                           0.99       269
   macro avg       0.98      0.99      0.98       269
weighted avg       0.99      0.99      0.99       269

========================	test end	========================

========================	2023-03-25 13:34:11	========================
model name: 	train_order3_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: train_order3_drop1_mfcc_smoothTrue_epoch80_l2re1_lr0002_pretrainTrue	epochs: 80	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: True	order: 3	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 4	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2246	 train accuracy: 99.714	 validation loss: 0.0982	 validation accuracy: 97.049 
train(max_min): 	train loss: 0.2246	 train accuracy: 99.877	 validation loss: 0.0853	 validation accuracy: 98.033 
best val accuracy: 98.032787 	 corresponding train accuracy: 99.263804
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1137 	 test accuracy:	 96.743 
confusion matrix: 
[139   3]
[  7 158]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.98      0.97       142
         MDD       0.98      0.96      0.97       165

    accuracy                           0.97       307
   macro avg       0.97      0.97      0.97       307
weighted avg       0.97      0.97      0.97       307

========================	test end	========================

========================	2023-03-25 13:47:54	========================
model name: 	train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue	epochs: 60	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: True	order: 3	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 4	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-03-25 14:01:16	========================
model name: 	train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue	epochs: 60	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: True	order: 3	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 4	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-03-25 14:03:14	========================
model name: 	train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue	epochs: 60	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: True	order: 3	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 4	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2743	 train accuracy: 99.168	 validation loss: 0.1506	 validation accuracy: 94.667 
train(max_min): 	train loss: 0.2743	 train accuracy: 99.334	 validation loss: 0.1446	 validation accuracy: 96.000 
best val accuracy: 96.000000 	 corresponding train accuracy: 98.585691
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1220 	 test accuracy:	 97.351 
confusion matrix: 
[88  3]
[ 1 59]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.97      0.98        91
         MDD       0.95      0.98      0.97        60

    accuracy                           0.97       151
   macro avg       0.97      0.98      0.97       151
weighted avg       0.97      0.97      0.97       151

========================	test end	========================

========================	2023-03-25 14:20:41	========================
model name: 	train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue	epochs: 60	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: True	order: 3	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 4	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	test begin	========================
test: 			test loss: 	0.1220 	 test accuracy:	 97.351 
confusion matrix: 
[88  3]
[ 1 59]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.97      0.98        91
         MDD       0.95      0.98      0.97        60

    accuracy                           0.97       151
   macro avg       0.97      0.98      0.97       151
weighted avg       0.97      0.97      0.97       151

========================	test end	========================

========================	2023-03-25 14:21:16	========================
model name: 	train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue	epochs: 60	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: True	order: 3	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 4	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	test begin	========================
test: 			test loss: 	0.1121 	 test accuracy:	 97.124 
confusion matrix: 
[242  10]
[  3 197]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.96      0.97       252
         MDD       0.95      0.98      0.97       200

    accuracy                           0.97       452
   macro avg       0.97      0.97      0.97       452
weighted avg       0.97      0.97      0.97       452

========================	test end	========================

========================	2023-03-25 15:19:52	========================
model name: 	train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue	epochs: 60	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: True	order: 3	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2726	 train accuracy: 99.334	 validation loss: 0.1178	 validation accuracy: 96.000 
train(max_min): 	train loss: 0.2707	 train accuracy: 99.834	 validation loss: 0.1019	 validation accuracy: 96.667 
best val accuracy: 96.666667 	 corresponding train accuracy: 99.417637
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0695 	 test accuracy:	 98.675 
confusion matrix: 
[90  1]
[ 1 59]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99        91
         MDD       0.98      0.98      0.98        60

    accuracy                           0.99       151
   macro avg       0.99      0.99      0.99       151
weighted avg       0.99      0.99      0.99       151

========================	test end	========================

========================	2023-03-25 16:18:06	========================
model name: 	train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue	epochs: 60	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: True	order: 3	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2457	 train accuracy: 99.393	 validation loss: 0.1309	 validation accuracy: 96.629 
train(max_min): 	train loss: 0.2418	 train accuracy: 99.673	 validation loss: 0.1215	 validation accuracy: 97.378 
best val accuracy: 97.378277 	 corresponding train accuracy: 99.626343
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1307 	 test accuracy:	 96.283 
confusion matrix: 
[154   2]
[  8 105]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.99      0.97       156
         MDD       0.98      0.93      0.95       113

    accuracy                           0.96       269
   macro avg       0.97      0.96      0.96       269
weighted avg       0.96      0.96      0.96       269

========================	test end	========================

========================	2023-03-26 21:45:15	========================
model name: 	train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainFalse	epochs: 60	lr: 0.0002	batch_size: 32	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 300	initial_lr: 0.08	load_weight: False	order: 3	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 2	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2398	 train accuracy: 99.860	 validation loss: 0.1510	 validation accuracy: 94.382 
train(max_min): 	train loss: 0.2398	 train accuracy: 99.860	 validation loss: 0.1510	 validation accuracy: 94.382 
best val accuracy: 94.382022 	 corresponding train accuracy: 99.859879
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1153 	 test accuracy:	 97.026 
confusion matrix: 
[150   6]
[  2 111]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.96      0.97       156
         MDD       0.95      0.98      0.97       113

    accuracy                           0.97       269
   macro avg       0.97      0.97      0.97       269
weighted avg       0.97      0.97      0.97       269

========================	test end	========================

========================	2023-03-30 20:58:50	========================
model name: 	SET_official_train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0008_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: SET_official_train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0008_pretrainFalse	epochs: 60	lr: 0.0008	batch_size: 64	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	order: 3	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.3204	 train accuracy: 99.715	 validation loss: 0.4667	 validation accuracy: 85.000 
train(max_min): 	train loss: 0.2915	 train accuracy: 100.000	 validation loss: 0.3558	 validation accuracy: 92.333 
best val accuracy: 92.333333 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	2023-03-30 21:05:06	========================
model name: 	SET_official_train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0008_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: SET_official_train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0008_pretrainFalse	epochs: 60	lr: 0.0008	batch_size: 64	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	order: 3	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	test begin	========================
test: 			test loss: 	0.2542 	 test accuracy:	 92.053 
confusion matrix: 
[85  6]
[ 6 54]

classification report: 
              precision    recall  f1-score   support

          HC       0.93      0.93      0.93        91
         MDD       0.90      0.90      0.90        60

    accuracy                           0.92       151
   macro avg       0.92      0.92      0.92       151
weighted avg       0.92      0.92      0.92       151

========================	test end	========================

========================	2023-03-30 21:39:44	========================
model name: 	CNN_ML_Transformer_train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0006_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: CNN_ML_Transformer_train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0006_pretrainFalse	epochs: 60	lr: 0.0006	batch_size: 64	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	order: 3	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2297	 train accuracy: 100.000	 validation loss: 0.3353	 validation accuracy: 91.667 
train(max_min): 	train loss: 0.2297	 train accuracy: 100.000	 validation loss: 0.3353	 validation accuracy: 93.333 
best val accuracy: 93.333333 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2542 	 test accuracy:	 92.053 
confusion matrix: 
[85  6]
[ 6 54]

classification report: 
              precision    recall  f1-score   support

          HC       0.93      0.93      0.93        91
         MDD       0.90      0.90      0.90        60

    accuracy                           0.92       151
   macro avg       0.92      0.92      0.92       151
weighted avg       0.92      0.92      0.92       151

========================	test end	========================

========================	2023-03-30 21:42:45	========================
model name: 	CNN_ML_Transformer_train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0006_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: CNN_ML_Transformer_train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0006_pretrainFalse	epochs: 60	lr: 0.0006	batch_size: 64	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	order: 3	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2294	 train accuracy: 100.000	 validation loss: 0.3208	 validation accuracy: 93.000 
train(max_min): 	train loss: 0.2294	 train accuracy: 100.000	 validation loss: 0.2747	 validation accuracy: 96.000 
best val accuracy: 96.000000 	 corresponding train accuracy: 99.904943
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1310 	 test accuracy:	 96.689 
confusion matrix: 
[86  5]
[ 0 60]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.95      0.97        91
         MDD       0.92      1.00      0.96        60

    accuracy                           0.97       151
   macro avg       0.96      0.97      0.97       151
weighted avg       0.97      0.97      0.97       151

========================	test end	========================

========================	2023-03-30 22:01:00	========================
model name: 	CNN_Transformer_train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0006_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0006_pretrainFalse	epochs: 60	lr: 0.0006	batch_size: 64	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	order: 3	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2302	 train accuracy: 100.000	 validation loss: 0.3329	 validation accuracy: 93.000 
train(max_min): 	train loss: 0.2302	 train accuracy: 100.000	 validation loss: 0.3012	 validation accuracy: 95.333 
best val accuracy: 95.333333 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1248 	 test accuracy:	 95.364 
confusion matrix: 
[89  2]
[ 5 55]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.98      0.96        91
         MDD       0.96      0.92      0.94        60

    accuracy                           0.95       151
   macro avg       0.96      0.95      0.95       151
weighted avg       0.95      0.95      0.95       151

========================	test end	========================

========================	2023-04-02 14:17:59	========================
model name: 	CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainTrue	epochs: 60	lr: 0.0006	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2244	 train accuracy: 99.810	 validation loss: 0.3251	 validation accuracy: 93.667 
train(max_min): 	train loss: 0.2221	 train accuracy: 100.000	 validation loss: 0.2659	 validation accuracy: 97.000 
best val accuracy: 97.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1286 	 test accuracy:	 96.026 
confusion matrix: 
[87  4]
[ 2 58]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.96      0.97        91
         MDD       0.94      0.97      0.95        60

    accuracy                           0.96       151
   macro avg       0.96      0.96      0.96       151
weighted avg       0.96      0.96      0.96       151

========================	test end	========================

========================	2023-04-02 14:33:11	========================
model name: 	CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainTrue	epochs: 60	lr: 0.0006	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2156	 train accuracy: 99.905	 validation loss: 0.2627	 validation accuracy: 95.333 
train(max_min): 	train loss: 0.2156	 train accuracy: 100.000	 validation loss: 0.2627	 validation accuracy: 95.667 
best val accuracy: 95.666667 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1006 	 test accuracy:	 97.351 
confusion matrix: 
[91  0]
[ 4 56]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      1.00      0.98        91
         MDD       1.00      0.93      0.97        60

    accuracy                           0.97       151
   macro avg       0.98      0.97      0.97       151
weighted avg       0.97      0.97      0.97       151

========================	test end	========================

========================	2023-04-02 14:36:41	========================
model name: 	CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainTrue	epochs: 60	lr: 0.0006	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2147	 train accuracy: 100.000	 validation loss: 0.3077	 validation accuracy: 94.333 
train(max_min): 	train loss: 0.2147	 train accuracy: 100.000	 validation loss: 0.2865	 validation accuracy: 94.333 
best val accuracy: 94.333333 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1277 	 test accuracy:	 95.364 
confusion matrix: 
[87  4]
[ 3 57]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.96      0.96        91
         MDD       0.93      0.95      0.94        60

    accuracy                           0.95       151
   macro avg       0.95      0.95      0.95       151
weighted avg       0.95      0.95      0.95       151

========================	test end	========================

========================	2023-04-02 14:39:54	========================
model name: 	CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse	epochs: 60	lr: 0.0006	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2342	 train accuracy: 99.905	 validation loss: 0.3235	 validation accuracy: 91.667 
train(max_min): 	train loss: 0.2336	 train accuracy: 100.000	 validation loss: 0.2950	 validation accuracy: 95.000 
best val accuracy: 95.000000 	 corresponding train accuracy: 99.714829
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1600 	 test accuracy:	 96.026 
confusion matrix: 
[86  5]
[ 1 59]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.95      0.97        91
         MDD       0.92      0.98      0.95        60

    accuracy                           0.96       151
   macro avg       0.96      0.96      0.96       151
weighted avg       0.96      0.96      0.96       151

========================	test end	========================

========================	2023-04-02 14:44:19	========================
model name: 	CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0002_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0002_pretrainTrue	epochs: 60	lr: 0.0002	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.3011	 train accuracy: 98.099	 validation loss: 0.3377	 validation accuracy: 93.667 
train(max_min): 	train loss: 0.2997	 train accuracy: 98.479	 validation loss: 0.3377	 validation accuracy: 93.667 
best val accuracy: 93.666667 	 corresponding train accuracy: 98.098859
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1663 	 test accuracy:	 96.026 
confusion matrix: 
[86  5]
[ 1 59]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.95      0.97        91
         MDD       0.92      0.98      0.95        60

    accuracy                           0.96       151
   macro avg       0.96      0.96      0.96       151
weighted avg       0.96      0.96      0.96       151

========================	test end	========================

========================	2023-04-02 14:48:57	========================
model name: 	CNN_Transformer_train_order3_drop1_mfcc_epoch80_l2re1_lr0004_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order3_drop1_mfcc_epoch80_l2re1_lr0004_pretrainTrue	epochs: 80	lr: 0.0004	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2336	 train accuracy: 100.000	 validation loss: 0.2793	 validation accuracy: 96.667 
train(max_min): 	train loss: 0.2332	 train accuracy: 100.000	 validation loss: 0.2717	 validation accuracy: 97.000 
best val accuracy: 97.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0733 	 test accuracy:	 98.013 
confusion matrix: 
[90  1]
[ 2 58]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98        91
         MDD       0.98      0.97      0.97        60

    accuracy                           0.98       151
   macro avg       0.98      0.98      0.98       151
weighted avg       0.98      0.98      0.98       151

========================	test end	========================

========================	2023-04-02 14:58:20	========================
model name: 	CNN_ML_Transformer_train_order3_drop1_mfcc_epoch80_l2re1_lr0004_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: CNN_ML_Transformer_train_order3_drop1_mfcc_epoch80_l2re1_lr0004_pretrainTrue	epochs: 80	lr: 0.0004	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_ML_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-02 15:08:18	========================
model name: 	CNN_ML_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: CNN_ML_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainTrue	epochs: 60	lr: 0.0006	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_ML_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2070	 train accuracy: 100.000	 validation loss: 0.3294	 validation accuracy: 92.667 
train(max_min): 	train loss: 0.2070	 train accuracy: 100.000	 validation loss: 0.2359	 validation accuracy: 98.000 
best val accuracy: 98.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0918 	 test accuracy:	 98.013 
confusion matrix: 
[89  2]
[ 1 59]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.98        91
         MDD       0.97      0.98      0.98        60

    accuracy                           0.98       151
   macro avg       0.98      0.98      0.98       151
weighted avg       0.98      0.98      0.98       151

========================	test end	========================

========================	2023-04-02 15:15:09	========================
model name: 	CNN_ML_Transformer_train_order3_drop1_mfcc_epoch80_l2re1_lr0006_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: CNN_ML_Transformer_train_order3_drop1_mfcc_epoch80_l2re1_lr0006_pretrainTrue	epochs: 80	lr: 0.0006	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_ML_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2159	 train accuracy: 100.000	 validation loss: 0.2658	 validation accuracy: 96.000 
train(max_min): 	train loss: 0.2151	 train accuracy: 100.000	 validation loss: 0.2642	 validation accuracy: 96.667 
best val accuracy: 96.666667 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1224 	 test accuracy:	 95.364 
confusion matrix: 
[85  6]
[ 1 59]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.93      0.96        91
         MDD       0.91      0.98      0.94        60

    accuracy                           0.95       151
   macro avg       0.95      0.96      0.95       151
weighted avg       0.96      0.95      0.95       151

========================	test end	========================

========================	2023-04-02 15:23:03	========================
model name: 	CNN_Transformer_train_order2_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order2_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse	epochs: 60	lr: 0.0006	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 2	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 26	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2540	 train accuracy: 99.525	 validation loss: 0.3168	 validation accuracy: 93.333 
train(max_min): 	train loss: 0.2526	 train accuracy: 99.810	 validation loss: 0.3160	 validation accuracy: 93.333 
best val accuracy: 93.333333 	 corresponding train accuracy: 99.524715
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1175 	 test accuracy:	 96.026 
confusion matrix: 
[90  1]
[ 5 55]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.99      0.97        91
         MDD       0.98      0.92      0.95        60

    accuracy                           0.96       151
   macro avg       0.96      0.95      0.96       151
weighted avg       0.96      0.96      0.96       151

========================	test end	========================

========================	2023-04-02 15:27:40	========================
model name: 	CNN_Transformer_train_order2_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order2_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse	epochs: 60	lr: 0.0006	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 2	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 26	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2381	 train accuracy: 100.000	 validation loss: 0.2832	 validation accuracy: 96.000 
train(max_min): 	train loss: 0.2381	 train accuracy: 100.000	 validation loss: 0.2832	 validation accuracy: 96.000 
best val accuracy: 96.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0863 	 test accuracy:	 98.675 
confusion matrix: 
[90  1]
[ 1 59]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99        91
         MDD       0.98      0.98      0.98        60

    accuracy                           0.99       151
   macro avg       0.99      0.99      0.99       151
weighted avg       0.99      0.99      0.99       151

========================	test end	========================

========================	2023-04-02 15:30:42	========================
model name: 	CNN_Transformer_train_order2_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order2_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse	epochs: 60	lr: 0.0006	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 2	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 26	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2209	 train accuracy: 99.810	 validation loss: 0.3597	 validation accuracy: 90.333 
train(max_min): 	train loss: 0.2209	 train accuracy: 100.000	 validation loss: 0.2958	 validation accuracy: 94.667 
best val accuracy: 94.666667 	 corresponding train accuracy: 99.904943
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0958 	 test accuracy:	 97.351 
confusion matrix: 
[91  0]
[ 4 56]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      1.00      0.98        91
         MDD       1.00      0.93      0.97        60

    accuracy                           0.97       151
   macro avg       0.98      0.97      0.97       151
weighted avg       0.97      0.97      0.97       151

========================	test end	========================

========================	2023-04-02 15:41:20	========================
model name: 	CNN_Transformer_train_order1_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order1_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse	epochs: 60	lr: 0.0006	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 1	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 13	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2390	 train accuracy: 99.905	 validation loss: 0.3345	 validation accuracy: 92.333 
train(max_min): 	train loss: 0.2390	 train accuracy: 100.000	 validation loss: 0.2849	 validation accuracy: 95.333 
best val accuracy: 95.333333 	 corresponding train accuracy: 99.904943
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1177 	 test accuracy:	 95.364 
confusion matrix: 
[89  2]
[ 5 55]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.98      0.96        91
         MDD       0.96      0.92      0.94        60

    accuracy                           0.95       151
   macro avg       0.96      0.95      0.95       151
weighted avg       0.95      0.95      0.95       151

========================	test end	========================

========================	2023-04-02 15:45:03	========================
model name: 	CNN_Transformer_train_order1_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order1_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse	epochs: 60	lr: 0.0006	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 1	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 13	dilation: 8	filters: 13	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.3442	 train accuracy: 94.202	 validation loss: 0.6033	 validation accuracy: 82.000 
train(max_min): 	train loss: 0.3442	 train accuracy: 94.202	 validation loss: 0.4738	 validation accuracy: 84.667 
best val accuracy: 84.666667 	 corresponding train accuracy: 90.969582
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2861 	 test accuracy:	 86.093 
confusion matrix: 
[91  0]
[21 39]

classification report: 
              precision    recall  f1-score   support

          HC       0.81      1.00      0.90        91
         MDD       1.00      0.65      0.79        60

    accuracy                           0.86       151
   macro avg       0.91      0.82      0.84       151
weighted avg       0.89      0.86      0.85       151

========================	test end	========================

========================	2023-04-02 15:49:11	========================
model name: 	CNN_Transformer_train_order2_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order2_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse	epochs: 60	lr: 0.0006	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 2	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 26	dilation: 8	filters: 26	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2755	 train accuracy: 98.289	 validation loss: 0.3273	 validation accuracy: 92.667 
train(max_min): 	train loss: 0.2755	 train accuracy: 98.574	 validation loss: 0.3235	 validation accuracy: 93.667 
best val accuracy: 93.666667 	 corresponding train accuracy: 96.863118
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1469 	 test accuracy:	 95.364 
confusion matrix: 
[87  4]
[ 3 57]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.96      0.96        91
         MDD       0.93      0.95      0.94        60

    accuracy                           0.95       151
   macro avg       0.95      0.95      0.95       151
weighted avg       0.95      0.95      0.95       151

========================	test end	========================

========================	2023-04-02 15:53:26	========================
model name: 	CNN_Transformer_train_order2_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order2_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse	epochs: 60	lr: 0.0006	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 2	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 26	dilation: 8	filters: 26	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2631	 train accuracy: 99.240	 validation loss: 0.3037	 validation accuracy: 95.000 
train(max_min): 	train loss: 0.2619	 train accuracy: 99.525	 validation loss: 0.3037	 validation accuracy: 95.000 
best val accuracy: 95.000000 	 corresponding train accuracy: 99.334601
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1110 	 test accuracy:	 98.013 
confusion matrix: 
[91  0]
[ 3 57]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      1.00      0.98        91
         MDD       1.00      0.95      0.97        60

    accuracy                           0.98       151
   macro avg       0.98      0.97      0.98       151
weighted avg       0.98      0.98      0.98       151

========================	test end	========================

========================	2023-04-02 15:56:53	========================
model name: 	CNN_Transformer_train_order2_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order2_drop1_mfcc_epoch60_l2re1_lr0006_pretrainFalse	epochs: 60	lr: 0.0006	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 2	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 26	dilation: 8	filters: 26	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2653	 train accuracy: 99.240	 validation loss: 0.3486	 validation accuracy: 91.000 
train(max_min): 	train loss: 0.2653	 train accuracy: 99.240	 validation loss: 0.3275	 validation accuracy: 93.333 
best val accuracy: 93.333333 	 corresponding train accuracy: 98.954373
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1594 	 test accuracy:	 94.702 
confusion matrix: 
[88  3]
[ 5 55]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.97      0.96        91
         MDD       0.95      0.92      0.93        60

    accuracy                           0.95       151
   macro avg       0.95      0.94      0.94       151
weighted avg       0.95      0.95      0.95       151

========================	test end	========================

========================	2023-04-02 21:05:50	========================
model name: 	CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainTrue	epochs: 60	lr: 0.0006	pretrain_model_path: pretrain_mode.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-02 21:06:44	========================
model name: 	CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainTrue	epochs: 60	lr: 0.0006	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-02 21:08:40	========================
model name: 	CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainTrue
addition: 	parameter setting:	mode: train	model_name: CNN_Transformer_train_order3_drop1_mfcc_epoch60_l2re1_lr0006_pretrainTrue	epochs: 60	lr: 0.0006	pretrain_model_path: models/dann_iemocap_modma_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: CNN_Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-03 09:44:13	========================
model name: 	Transformer_TIM_train_order3_drop1_mfcc_epoch60_l2re1_lr001_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_TIM_train_order3_drop1_mfcc_epoch60_l2re1_lr001_pretrainFalse	epochs: 60	lr: 0.001	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 153.8792	 train accuracy: 99.430	 validation loss: 0.3306	 validation accuracy: 93.333 
train(max_min): 	train loss: 153.8776	 train accuracy: 99.905	 validation loss: 0.3142	 validation accuracy: 93.333 
best val accuracy: 93.333333 	 corresponding train accuracy: 99.714829
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2365 	 test accuracy:	 92.715 
confusion matrix: 
[86  5]
[ 6 54]

classification report: 
              precision    recall  f1-score   support

          HC       0.93      0.95      0.94        91
         MDD       0.92      0.90      0.91        60

    accuracy                           0.93       151
   macro avg       0.93      0.92      0.92       151
weighted avg       0.93      0.93      0.93       151

========================	test end	========================

========================	2023-04-03 09:51:26	========================
model name: 	Transformer_TIM_train_order3_drop1_mfcc_epoch60_l2re0_lr001_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_TIM_train_order3_drop1_mfcc_epoch60_l2re0_lr001_pretrainFalse	epochs: 60	lr: 0.001	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-03 12:54:54	========================
model name: 	Transformer_TIM_train_order3_drop1_mfcc_epoch60_l2re1_lr001_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_TIM_train_order3_drop1_mfcc_epoch60_l2re1_lr001_pretrainFalse	epochs: 60	lr: 0.001	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-03 12:56:51	========================
model name: 	Transformer_TIM_train_order3_drop1_mfcc_epoch60_l2re1_lr0005_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_TIM_train_order3_drop1_mfcc_epoch60_l2re1_lr0005_pretrainFalse	epochs: 60	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-03 13:09:09	========================
model name: 	Transformer_TIM_train_order3_drop1_mfcc_epoch4_l2re1_lr0005_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_TIM_train_order3_drop1_mfcc_epoch4_l2re1_lr0005_pretrainFalse	epochs: 4	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-03 13:11:13	========================
model name: 	Transformer_TIM_train_order3_drop1_mfcc_epoch4_l2re1_lr0005_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_TIM_train_order3_drop1_mfcc_epoch4_l2re1_lr0005_pretrainFalse	epochs: 4	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-03 13:12:57	========================
model name: 	Transformer_TIM_train_order3_drop1_mfcc_epoch4_l2re1_lr0005_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_TIM_train_order3_drop1_mfcc_epoch4_l2re1_lr0005_pretrainFalse	epochs: 4	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-03 13:13:50	========================
model name: 	Transformer_TIM_train_order3_drop1_mfcc_epoch4_l2re1_lr0005_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_TIM_train_order3_drop1_mfcc_epoch4_l2re1_lr0005_pretrainFalse	epochs: 4	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 10.2783	 train accuracy: 94.297	 validation loss: 0.3666	 validation accuracy: 89.333 
train(max_min): 	train loss: 10.2783	 train accuracy: 94.297	 validation loss: 0.3666	 validation accuracy: 89.333 
best val accuracy: 89.333333 	 corresponding train accuracy: 94.296578
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2588 	 test accuracy:	 89.404 
confusion matrix: 
[77 14]
[ 2 58]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.85      0.91        91
         MDD       0.81      0.97      0.88        60

    accuracy                           0.89       151
   macro avg       0.89      0.91      0.89       151
weighted avg       0.91      0.89      0.90       151

========================	test end	========================

========================	2023-04-04 12:44:14	========================
model name: 	TIM_train_order3_drop1_mfcc_epoch4_l2re1_lr0005_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_order3_drop1_mfcc_epoch4_l2re1_lr0005_pretrainFalse	epochs: 4	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.5423	 train accuracy: 81.274	 validation loss: 0.7652	 validation accuracy: 74.667 
train(max_min): 	train loss: 0.5423	 train accuracy: 81.274	 validation loss: 0.7652	 validation accuracy: 74.667 
best val accuracy: 74.666667 	 corresponding train accuracy: 81.273764
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.5258 	 test accuracy:	 80.795 
confusion matrix: 
[81 10]
[19 41]

classification report: 
              precision    recall  f1-score   support

          HC       0.81      0.89      0.85        91
         MDD       0.80      0.68      0.74        60

    accuracy                           0.81       151
   macro avg       0.81      0.79      0.79       151
weighted avg       0.81      0.81      0.80       151

========================	test end	========================

========================	2023-04-04 12:46:37	========================
model name: 	TIM_train_order3_drop1_mfcc_epoch80_l2re1_lr0005_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_order3_drop1_mfcc_epoch80_l2re1_lr0005_pretrainFalse	epochs: 80	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2581	 train accuracy: 100.000	 validation loss: 0.3864	 validation accuracy: 92.000 
train(max_min): 	train loss: 0.2581	 train accuracy: 100.000	 validation loss: 0.3492	 validation accuracy: 93.000 
best val accuracy: 93.000000 	 corresponding train accuracy: 99.049430
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2213 	 test accuracy:	 94.040 
confusion matrix: 
[85  6]
[ 3 57]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.93      0.95        91
         MDD       0.90      0.95      0.93        60

    accuracy                           0.94       151
   macro avg       0.94      0.94      0.94       151
weighted avg       0.94      0.94      0.94       151

========================	test end	========================

========================	2023-04-04 12:49:03	========================
model name: 	Transformer_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse	epochs: 100	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-04 12:51:05	========================
model name: 	Transformer_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse	epochs: 100	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2511	 validation accuracy: 97.000 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2490	 validation accuracy: 97.667 
best val accuracy: 97.666667 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1192 	 test accuracy:	 98.013 
confusion matrix: 
[91  0]
[ 3 57]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      1.00      0.98        91
         MDD       1.00      0.95      0.97        60

    accuracy                           0.98       151
   macro avg       0.98      0.97      0.98       151
weighted avg       0.98      0.98      0.98       151

========================	test end	========================

========================	2023-04-04 13:02:40	========================
model name: 	Transformer_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse	epochs: 100	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-04 13:05:45	========================
model name: 	Transformer_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse	epochs: 100	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-09 12:25:55	========================
model name: 	AT_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse	epochs: 100	lr: 0.0003	pretrain_model_path: pretrain_model.pt	batch_size: 128	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 25	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 100	num_class: 2	


========================	2023-04-09 12:29:25	========================
model name: 	AT_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse	epochs: 100	lr: 0.0003	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 25	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 100	num_class: 2	


========================	2023-04-09 12:34:53	========================
model name: 	AT_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse	epochs: 100	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 100	num_class: 2	


========================	2023-04-09 12:46:44	========================
model name: 	AT_TIM_train_order3_drop1_mfcc_epoch2_l2re1_lr0005_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_order3_drop1_mfcc_epoch2_l2re1_lr0005_pretrainFalse	epochs: 2	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 100	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.6409	 train accuracy: 64.815	 validation loss: 0.6384	 validation accuracy: 67.278 
train(max_min): 	train loss: 0.6409	 train accuracy: 64.815	 validation loss: 0.6384	 validation accuracy: 67.278 
best val accuracy: 67.277856 	 corresponding train accuracy: 64.814815
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.6179 	 test accuracy:	 64.607 
confusion matrix: 
[172  15]
[111  58]

classification report: 
              precision    recall  f1-score   support

          HC       0.61      0.92      0.73       187
         MDD       0.79      0.34      0.48       169

    accuracy                           0.65       356
   macro avg       0.70      0.63      0.61       356
weighted avg       0.70      0.65      0.61       356

========================	test end	========================

========================	2023-04-09 12:50:41	========================
model name: 	AT_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse	epochs: 100	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 100	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2048	 train accuracy: 99.678	 validation loss: 0.2921	 validation accuracy: 94.922 
train(max_min): 	train loss: 0.2027	 train accuracy: 99.960	 validation loss: 0.2850	 validation accuracy: 96.192 
best val accuracy: 96.191819 	 corresponding train accuracy: 99.355878
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1545 	 test accuracy:	 93.820 
confusion matrix: 
[179   8]
[ 14 155]

classification report: 
              precision    recall  f1-score   support

          HC       0.93      0.96      0.94       187
         MDD       0.95      0.92      0.93       169

    accuracy                           0.94       356
   macro avg       0.94      0.94      0.94       356
weighted avg       0.94      0.94      0.94       356

========================	test end	========================

========================	2023-04-09 12:55:07	========================
model name: 	AT_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0006_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0006_pretrainFalse	epochs: 100	lr: 0.0006	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 100	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2004	 train accuracy: 99.960	 validation loss: 0.2870	 validation accuracy: 96.333 
train(max_min): 	train loss: 0.1997	 train accuracy: 100.000	 validation loss: 0.2772	 validation accuracy: 97.602 
best val accuracy: 97.602257 	 corresponding train accuracy: 99.879227
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1398 	 test accuracy:	 96.348 
confusion matrix: 
[184   3]
[ 10 159]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.98      0.97       187
         MDD       0.98      0.94      0.96       169

    accuracy                           0.96       356
   macro avg       0.96      0.96      0.96       356
weighted avg       0.96      0.96      0.96       356

========================	test end	========================

========================	2023-04-09 13:00:51	========================
model name: 	Transformer_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse	epochs: 100	lr: 0.0003	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1994	 train accuracy: 100.000	 validation loss: 0.2121	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1994	 train accuracy: 100.000	 validation loss: 0.2111	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0656 	 test accuracy:	 99.438 
confusion matrix: 
[186   1]
[  1 168]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       187
         MDD       0.99      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-09 13:16:23	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse	epochs: 100	lr: 0.0003	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2023	 train accuracy: 99.879	 validation loss: 0.2411	 validation accuracy: 97.320 
train(max_min): 	train loss: 0.2018	 train accuracy: 100.000	 validation loss: 0.2362	 validation accuracy: 98.025 
best val accuracy: 98.025388 	 corresponding train accuracy: 99.919485
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0850 	 test accuracy:	 98.034 
confusion matrix: 
[184   3]
[  4 165]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       187
         MDD       0.98      0.98      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-09 13:26:20	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse	epochs: 100	lr: 0.0003	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-09 13:29:26	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse	epochs: 100	lr: 0.0003	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2036	 train accuracy: 99.839	 validation loss: 0.2466	 validation accuracy: 97.179 
train(max_min): 	train loss: 0.2028	 train accuracy: 99.960	 validation loss: 0.2384	 validation accuracy: 97.884 
best val accuracy: 97.884344 	 corresponding train accuracy: 99.879227
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1103 	 test accuracy:	 97.472 
confusion matrix: 
[183   4]
[  5 164]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.98      0.98       187
         MDD       0.98      0.97      0.97       169

    accuracy                           0.97       356
   macro avg       0.97      0.97      0.97       356
weighted avg       0.97      0.97      0.97       356

========================	test end	========================

========================	2023-04-09 13:47:57	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterTrue
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterTrue	epochs: 100	lr: 0.0003	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2040	 train accuracy: 99.839	 validation loss: 0.2326	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.2025	 train accuracy: 99.960	 validation loss: 0.2319	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 99.959742
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0770 	 test accuracy:	 98.876 
confusion matrix: 
[186   1]
[  3 166]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       187
         MDD       0.99      0.98      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-09 13:55:42	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterTrue
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterTrue	epochs: 100	lr: 0.0003	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2070	 train accuracy: 99.799	 validation loss: 0.2492	 validation accuracy: 97.320 
train(max_min): 	train loss: 0.2050	 train accuracy: 99.879	 validation loss: 0.2440	 validation accuracy: 97.884 
best val accuracy: 97.884344 	 corresponding train accuracy: 99.758454
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1015 	 test accuracy:	 96.910 
confusion matrix: 
[180   7]
[  4 165]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.96      0.97       187
         MDD       0.96      0.98      0.97       169

    accuracy                           0.97       356
   macro avg       0.97      0.97      0.97       356
weighted avg       0.97      0.97      0.97       356

========================	test end	========================

========================	2023-04-09 14:04:09	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterTrue
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterTrue	epochs: 100	lr: 0.0003	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-09 14:06:02	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterTrue
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterTrue	epochs: 100	lr: 0.0003	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 100	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2136	 train accuracy: 99.557	 validation loss: 0.3168	 validation accuracy: 94.358 
train(max_min): 	train loss: 0.2113	 train accuracy: 99.799	 validation loss: 0.3110	 validation accuracy: 94.781 
best val accuracy: 94.781382 	 corresponding train accuracy: 99.476651
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1661 	 test accuracy:	 93.820 
confusion matrix: 
[179   8]
[ 14 155]

classification report: 
              precision    recall  f1-score   support

          HC       0.93      0.96      0.94       187
         MDD       0.95      0.92      0.93       169

    accuracy                           0.94       356
   macro avg       0.94      0.94      0.94       356
weighted avg       0.94      0.94      0.94       356

========================	test end	========================

========================	2023-04-09 14:09:13	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse_clusterTrue
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse_clusterTrue	epochs: 100	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 100	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2069	 train accuracy: 99.678	 validation loss: 0.3160	 validation accuracy: 95.769 
train(max_min): 	train loss: 0.2049	 train accuracy: 99.799	 validation loss: 0.2936	 validation accuracy: 96.051 
best val accuracy: 96.050776 	 corresponding train accuracy: 99.798712
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1337 	 test accuracy:	 96.348 
confusion matrix: 
[180   7]
[  6 163]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.96      0.97       187
         MDD       0.96      0.96      0.96       169

    accuracy                           0.96       356
   macro avg       0.96      0.96      0.96       356
weighted avg       0.96      0.96      0.96       356

========================	test end	========================

========================	2023-04-09 14:15:52	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse_clusterTrue
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse_clusterTrue	epochs: 100	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 100	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2018	 train accuracy: 99.879	 validation loss: 0.2863	 validation accuracy: 95.205 
train(max_min): 	train loss: 0.2008	 train accuracy: 100.000	 validation loss: 0.2724	 validation accuracy: 96.615 
best val accuracy: 96.614951 	 corresponding train accuracy: 99.798712
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1400 	 test accuracy:	 95.506 
confusion matrix: 
[185   2]
[ 14 155]

classification report: 
              precision    recall  f1-score   support

          HC       0.93      0.99      0.96       187
         MDD       0.99      0.92      0.95       169

    accuracy                           0.96       356
   macro avg       0.96      0.95      0.95       356
weighted avg       0.96      0.96      0.95       356

========================	test end	========================

========================	2023-04-09 14:56:29	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse_clusterTrue
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0005_pretrainFalse_clusterTrue	epochs: 100	lr: 0.0005	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: True	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 100	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2028	 train accuracy: 99.799	 validation loss: 0.3100	 validation accuracy: 96.051 
train(max_min): 	train loss: 0.2021	 train accuracy: 99.960	 validation loss: 0.2990	 validation accuracy: 97.038 
best val accuracy: 97.038082 	 corresponding train accuracy: 99.718196
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1223 	 test accuracy:	 96.629 
confusion matrix: 
[178   9]
[  3 166]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.95      0.97       187
         MDD       0.95      0.98      0.97       169

    accuracy                           0.97       356
   macro avg       0.97      0.97      0.97       356
weighted avg       0.97      0.97      0.97       356

========================	test end	========================

========================	2023-04-09 15:15:13	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: pretrain_model.pt	batch_size: 128	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-09 15:15:48	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: pretrain_model.pt	batch_size: 128	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-09 15:17:04	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: pretrain_model.pt	batch_size: 256	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-09 15:23:21	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0006_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0006_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0006	pretrain_model_path: pretrain_model.pt	batch_size: 256	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-09 15:25:51	========================
model name: 	AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0006_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_order3_drop1_mfcc_epoch100_l2re1_lr0006_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0006	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-09 16:56:17	========================
model name: 	Transformer_DeltaTIM_train_order3_drop2_mfcc_epoch100_l2re3_lr0001_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_order3_drop2_mfcc_epoch100_l2re3_lr0001_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0001	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-09 16:57:29	========================
model name: 	Transformer_DeltaTIM_train_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainFalse_clusterFalse	epochs: 100	lr: 8e-05	pretrain_model_path: pretrain_model.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.4261	 train accuracy: 100.000	 validation loss: 0.4580	 validation accuracy: 98.916 
train(max_min): 	train loss: 0.4261	 train accuracy: 100.000	 validation loss: 0.4553	 validation accuracy: 99.119 
best val accuracy: 99.119241 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	2023-04-09 20:22:25	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse	epochs: 100	lr: 8e-05	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-09 20:31:45	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse	epochs: 100	lr: 8e-05	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-09 20:39:16	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse	epochs: 100	lr: 8e-05	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-09 20:40:01	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse	epochs: 100	lr: 8e-05	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-09 20:42:05	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse	epochs: 100	lr: 8e-05	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-09 20:42:37	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse	epochs: 100	lr: 8e-05	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-09 20:44:18	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse	epochs: 100	lr: 8e-05	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-09 20:57:09	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr8e-05_pretrainTrue_clusterFalse	epochs: 100	lr: 8e-05	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-09 20:59:14	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr0002_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr0002_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-09 20:59:54	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr0002_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr0002_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-09 21:02:48	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr0003_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr0003_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-09 21:05:57	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr0002_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr0002_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 30	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2008	 train accuracy: 100.000	 validation loss: 0.2361	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.2007	 train accuracy: 100.000	 validation loss: 0.2345	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1076 	 test accuracy:	 98.876 
confusion matrix: 
[185   2]
[  2 167]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       187
         MDD       0.99      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-09 21:11:51	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr0002_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr0002_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.2	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-09 21:17:26	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr0003_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop2_mfcc_epoch100_l2re3_lr0003_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1994	 train accuracy: 100.000	 validation loss: 0.2200	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1994	 train accuracy: 100.000	 validation loss: 0.2183	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0668 	 test accuracy:	 99.719 
confusion matrix: 
[187   0]
[  1 168]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      1.00       187
         MDD       1.00      0.99      1.00       169

    accuracy                           1.00       356
   macro avg       1.00      1.00      1.00       356
weighted avg       1.00      1.00      1.00       356

========================	test end	========================

========================	2023-04-09 21:40:33	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 20	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1996	 train accuracy: 100.000	 validation loss: 0.2139	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1996	 train accuracy: 100.000	 validation loss: 0.2137	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0734 	 test accuracy:	 99.438 
confusion matrix: 
[186   1]
[  1 168]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       187
         MDD       0.99      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-10 21:14:58	========================
model name: 	AT_DeltaTIM_train_IEMOCAP_order3_drop1_mfcc_epoch120_l2re5_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_IEMOCAP_order3_drop1_mfcc_epoch120_l2re5_lr0004_pretrainFalse_clusterFalse	epochs: 120	lr: 0.0004	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.5	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 25	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.5686	 train accuracy: 93.844	 validation loss: 0.5545	 validation accuracy: 94.173 
train(max_min): 	train loss: 0.5683	 train accuracy: 94.077	 validation loss: 0.5545	 validation accuracy: 94.173 
best val accuracy: 94.173442 	 corresponding train accuracy: 93.921796
========================	train end	========================

========================	2023-04-10 21:28:55	========================
model name: 	AT_DeltaTIM_train_IEMOCAP_order3_drop1_mfcc_epoch150_l2re5_lr0005_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_IEMOCAP_order3_drop1_mfcc_epoch150_l2re5_lr0005_pretrainFalse_clusterFalse	epochs: 150	lr: 0.0005	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.5	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 25	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.4763	 train accuracy: 99.613	 validation loss: 0.4936	 validation accuracy: 98.509 
train(max_min): 	train loss: 0.4746	 train accuracy: 99.710	 validation loss: 0.4919	 validation accuracy: 98.509 
best val accuracy: 98.509485 	 corresponding train accuracy: 99.670925
========================	train end	========================

========================	2023-04-10 21:59:52	========================
model name: 	AT_DeltaTIM_train_IEMOCAP_order3_drop1_mfcc_epoch150_l2re5_lr0005_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_IEMOCAP_order3_drop1_mfcc_epoch150_l2re5_lr0005_pretrainFalse_clusterFalse	epochs: 150	lr: 0.0005	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.5	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 25	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-10 22:15:51	========================
model name: 	AT_DeltaTIM_train_IEMOCAP_order3_drop1_mfcc_epoch150_l2re5_lr0005_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_IEMOCAP_order3_drop1_mfcc_epoch150_l2re5_lr0005_pretrainFalse_clusterFalse	epochs: 150	lr: 0.0005	pretrain_model_path: iemocap_pretrain.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.5	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.4990	 train accuracy: 98.068	 validation loss: 0.5790	 validation accuracy: 92.853 
train(max_min): 	train loss: 0.4982	 train accuracy: 98.142	 validation loss: 0.5497	 validation accuracy: 94.462 
best val accuracy: 94.462331 	 corresponding train accuracy: 97.406181
========================	train end	========================

========================	2023-04-11 00:01:45	========================
model name: 	AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch150_l2re3_lr0003_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch150_l2re3_lr0003_pretrainTrue_clusterFalse	epochs: 150	lr: 0.0003	pretrain_model_path: AT_DeltaTIM_iemocap_v2.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2053	 train accuracy: 99.879	 validation loss: 0.2283	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.2034	 train accuracy: 100.000	 validation loss: 0.2240	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 99.838969
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0842 	 test accuracy:	 98.596 
confusion matrix: 
[184   3]
[  2 167]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       187
         MDD       0.98      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-11 00:17:36	========================
model name: 	AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re3_lr0002_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re3_lr0002_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: AT_DeltaTIM_iemocap_v2.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2105	 train accuracy: 99.638	 validation loss: 0.2642	 validation accuracy: 96.756 
train(max_min): 	train loss: 0.2105	 train accuracy: 99.879	 validation loss: 0.2614	 validation accuracy: 97.179 
best val accuracy: 97.179126 	 corresponding train accuracy: 99.476651
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1039 	 test accuracy:	 96.629 
confusion matrix: 
[180   7]
[  5 164]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.96      0.97       187
         MDD       0.96      0.97      0.96       169

    accuracy                           0.97       356
   macro avg       0.97      0.97      0.97       356
weighted avg       0.97      0.97      0.97       356

========================	test end	========================

========================	2023-04-11 00:23:29	========================
model name: 	AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re3_lr0002_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re3_lr0002_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: AT_DeltaTIM_iemocap_v2.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-11 13:57:28	========================
model name: 	AT_DeltaTIM_v2_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0005_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_v2_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0005_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0005	pretrain_model_path: AT_DeltaTIM_iemocap_v2.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM_v2	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2255	 validation accuracy: 98.307 
train(max_min): 	train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2229	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0815 	 test accuracy:	 98.315 
confusion matrix: 
[183   4]
[  2 167]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.98       187
         MDD       0.98      0.99      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-11 23:27:25	========================
model name: 	AT_DeltaTIM_v2_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0005_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_v2_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0005_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0005	pretrain_model_path: AT_DeltaTIM_iemocap_v2.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM_v2	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2014	 train accuracy: 99.960	 validation loss: 0.2521	 validation accuracy: 98.166 
train(max_min): 	train loss: 0.2009	 train accuracy: 99.960	 validation loss: 0.2342	 validation accuracy: 98.449 
best val accuracy: 98.448519 	 corresponding train accuracy: 99.959742
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1010 	 test accuracy:	 98.315 
confusion matrix: 
[184   3]
[  3 166]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       187
         MDD       0.98      0.98      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-11 23:38:18	========================
model name: 	AT_DeltaTIM_v2_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0005_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_v2_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0005_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0005	pretrain_model_path: AT_DeltaTIM_iemocap_v2.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM_v2	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2010	 train accuracy: 99.919	 validation loss: 0.2246	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2010	 train accuracy: 99.960	 validation loss: 0.2228	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 99.959742
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0663 	 test accuracy:	 99.438 
confusion matrix: 
[185   2]
[  0 169]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       187
         MDD       0.99      1.00      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-13 15:43:33	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: AT_DeltaTIM_iemocap_v2.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-13 15:50:55	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: AT_DeltaTIM_iemocap_v2.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================
test: 			test loss: 	0.1051 	 test accuracy:	 98.034 
confusion matrix: 
[184   3]
[  4 165]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       187
         MDD       0.98      0.98      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-13 15:55:34	========================
model name: 	MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse	epochs: 20	lr: 0.0001	pretrain_model_path: AT_DeltaTIM_iemocap_v2.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: DAIC	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 188	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.1986	 validation accuracy: 100.000 
train(max_min): 	train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.1985	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0457 	 test accuracy:	 100.000 
confusion matrix: 
[2207    0]
[  0 977]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      1.00      1.00      2207
         MDD       1.00      1.00      1.00       977

    accuracy                           1.00      3184
   macro avg       1.00      1.00      1.00      3184
weighted avg       1.00      1.00      1.00      3184

========================	test end	========================

========================	2023-04-13 16:02:20	========================
model name: 	MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse	epochs: 20	lr: 0.0001	pretrain_model_path: AT_DeltaTIM_iemocap_v2.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: DAIC	order: 3	version: V2	attention_type: MH	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 188	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.1985	 validation accuracy: 100.000 
train(max_min): 	train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.1985	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0483 	 test accuracy:	 100.000 
confusion matrix: 
[2207    0]
[  0 977]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      1.00      1.00      2207
         MDD       1.00      1.00      1.00       977

    accuracy                           1.00      3184
   macro avg       1.00      1.00      1.00      3184
weighted avg       1.00      1.00      1.00      3184

========================	test end	========================

========================	2023-04-13 16:08:08	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse	epochs: 20	lr: 0.0001	pretrain_model_path: AT_DeltaTIM_iemocap_v2.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: MH	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================
test: 			test loss: 	1.5657 	 test accuracy:	 47.472 
confusion matrix: 
[  0 187]
[  0 169]

classification report: 
              precision    recall  f1-score   support

          HC       0.00      0.00      0.00       187
         MDD       0.47      1.00      0.64       169

    accuracy                           0.47       356
   macro avg       0.24      0.50      0.32       356
weighted avg       0.23      0.47      0.31       356

========================	test end	========================

========================	2023-04-13 16:28:12	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re3_lr0005_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re3_lr0005_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0005	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.3	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2261	 train accuracy: 99.195	 validation loss: 0.2809	 validation accuracy: 95.769 
train(max_min): 	train loss: 0.2246	 train accuracy: 99.356	 validation loss: 0.2809	 validation accuracy: 95.769 
best val accuracy: 95.768688 	 corresponding train accuracy: 99.355878
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1405 	 test accuracy:	 94.944 
confusion matrix: 
[183   4]
[ 14 155]

classification report: 
              precision    recall  f1-score   support

          HC       0.93      0.98      0.95       187
         MDD       0.97      0.92      0.95       169

    accuracy                           0.95       356
   macro avg       0.95      0.95      0.95       356
weighted avg       0.95      0.95      0.95       356

========================	test end	========================

========================	2023-04-13 16:32:23	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.1	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-13 16:35:31	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0006_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0006_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0006	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2198	 train accuracy: 99.436	 validation loss: 0.2629	 validation accuracy: 95.487 
train(max_min): 	train loss: 0.2184	 train accuracy: 99.557	 validation loss: 0.2627	 validation accuracy: 95.910 
best val accuracy: 95.909732 	 corresponding train accuracy: 99.315620
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1271 	 test accuracy:	 95.506 
confusion matrix: 
[182   5]
[ 11 158]

classification report: 
              precision    recall  f1-score   support

          HC       0.94      0.97      0.96       187
         MDD       0.97      0.93      0.95       169

    accuracy                           0.96       356
   macro avg       0.96      0.95      0.95       356
weighted avg       0.96      0.96      0.96       356

========================	test end	========================

========================	2023-04-13 16:42:08	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0006_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0006_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0006	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-13 16:42:31	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0006_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0006_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0006	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: MH	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.3039	 train accuracy: 93.961	 validation loss: 0.3474	 validation accuracy: 92.807 
train(max_min): 	train loss: 0.3011	 train accuracy: 94.364	 validation loss: 0.3461	 validation accuracy: 93.089 
best val accuracy: 93.088858 	 corresponding train accuracy: 93.035427
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2701 	 test accuracy:	 88.483 
confusion matrix: 
[167  20]
[ 21 148]

classification report: 
              precision    recall  f1-score   support

          HC       0.89      0.89      0.89       187
         MDD       0.88      0.88      0.88       169

    accuracy                           0.88       356
   macro avg       0.88      0.88      0.88       356
weighted avg       0.88      0.88      0.88       356

========================	test end	========================

========================	2023-04-13 16:47:41	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch150_l2re2_lr0006_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch150_l2re2_lr0006_pretrainTrue_clusterFalse	epochs: 150	lr: 0.0006	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: MH	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.3429	 train accuracy: 91.989	 validation loss: 0.4374	 validation accuracy: 88.011 
train(max_min): 	train loss: 0.3421	 train accuracy: 92.069	 validation loss: 0.4358	 validation accuracy: 88.717 
best val accuracy: 88.716502 	 corresponding train accuracy: 90.418680
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2796 	 test accuracy:	 87.640 
confusion matrix: 
[168  19]
[ 25 144]

classification report: 
              precision    recall  f1-score   support

          HC       0.87      0.90      0.88       187
         MDD       0.88      0.85      0.87       169

    accuracy                           0.88       356
   macro avg       0.88      0.88      0.88       356
weighted avg       0.88      0.88      0.88       356

========================	test end	========================

========================	2023-04-13 16:57:00	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0006_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0006_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0006	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: MH	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2880	 train accuracy: 96.216	 validation loss: 0.3605	 validation accuracy: 92.102 
train(max_min): 	train loss: 0.2857	 train accuracy: 96.820	 validation loss: 0.3584	 validation accuracy: 92.243 
best val accuracy: 92.242595 	 corresponding train accuracy: 96.095008
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2034 	 test accuracy:	 92.135 
confusion matrix: 
[180   7]
[ 21 148]

classification report: 
              precision    recall  f1-score   support

          HC       0.90      0.96      0.93       187
         MDD       0.95      0.88      0.91       169

    accuracy                           0.92       356
   macro avg       0.93      0.92      0.92       356
weighted avg       0.92      0.92      0.92       356

========================	test end	========================

========================	2023-04-13 17:32:23	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0006_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0006_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0006	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: MH	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2152	 train accuracy: 99.879	 validation loss: 0.3207	 validation accuracy: 95.346 
train(max_min): 	train loss: 0.2144	 train accuracy: 100.000	 validation loss: 0.3170	 validation accuracy: 95.487 
best val accuracy: 95.486601 	 corresponding train accuracy: 99.838969
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1747 	 test accuracy:	 93.539 
confusion matrix: 
[176  11]
[ 12 157]

classification report: 
              precision    recall  f1-score   support

          HC       0.94      0.94      0.94       187
         MDD       0.93      0.93      0.93       169

    accuracy                           0.94       356
   macro avg       0.94      0.94      0.94       356
weighted avg       0.94      0.94      0.94       356

========================	test end	========================

========================	2023-04-13 17:39:17	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0006_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0006_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0006	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: MH	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2190	 train accuracy: 99.638	 validation loss: 0.3051	 validation accuracy: 93.935 
train(max_min): 	train loss: 0.2189	 train accuracy: 99.799	 validation loss: 0.3050	 validation accuracy: 94.076 
best val accuracy: 94.076164 	 corresponding train accuracy: 99.718196
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1599 	 test accuracy:	 94.101 
confusion matrix: 
[184   3]
[ 18 151]

classification report: 
              precision    recall  f1-score   support

          HC       0.91      0.98      0.95       187
         MDD       0.98      0.89      0.93       169

    accuracy                           0.94       356
   macro avg       0.95      0.94      0.94       356
weighted avg       0.94      0.94      0.94       356

========================	test end	========================

========================	2023-04-13 20:14:08	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: MH	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-13 20:21:21	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.4679	 train accuracy: 98.767	 validation loss: 0.6613	 validation accuracy: 90.341 
train(max_min): 	train loss: 0.4670	 train accuracy: 99.099	 validation loss: 0.5454	 validation accuracy: 95.879 
best val accuracy: 95.878944 	 corresponding train accuracy: 98.785872
========================	train end	========================

========================	2023-04-13 20:31:23	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.1	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.5097	 train accuracy: 96.321	 validation loss: 0.5776	 validation accuracy: 93.046 
train(max_min): 	train loss: 0.5068	 train accuracy: 96.376	 validation loss: 0.5556	 validation accuracy: 94.076 
best val accuracy: 94.075982 	 corresponding train accuracy: 95.493010
========================	train end	========================

========================	2023-04-13 20:42:09	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.1	step_size: 20	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-13 20:47:10	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.1	step_size: 20	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.5050	 train accuracy: 96.376	 validation loss: 0.5848	 validation accuracy: 90.406 
train(max_min): 	train loss: 0.5047	 train accuracy: 96.376	 validation loss: 0.5458	 validation accuracy: 93.625 
best val accuracy: 93.625241 	 corresponding train accuracy: 95.676968
========================	train end	========================

========================	2023-04-13 22:16:57	========================
model name: 	baseModel_train_MODMA_order3_drop1_mfcc_epoch150_l2re2_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: baseModel_train_MODMA_order3_drop1_mfcc_epoch150_l2re2_lr0002_pretrainFalse_clusterFalse	epochs: 150	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 20	random_seed: 34	model_type: baseModel	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-13 22:18:17	========================
model name: 	baseModel_train_MODMA_order3_drop1_mfcc_epoch150_l2re2_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: baseModel_train_MODMA_order3_drop1_mfcc_epoch150_l2re2_lr0002_pretrainFalse_clusterFalse	epochs: 150	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 20	random_seed: 34	model_type: baseModel	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-13 22:19:33	========================
model name: 	baseModel_train_MODMA_order3_drop1_mfcc_epoch150_l2re2_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: baseModel_train_MODMA_order3_drop1_mfcc_epoch150_l2re2_lr0002_pretrainFalse_clusterFalse	epochs: 150	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 20	random_seed: 34	model_type: baseModel	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.5340	 train accuracy: 75.443	 validation loss: 0.5353	 validation accuracy: 77.010 
train(max_min): 	train loss: 0.5216	 train accuracy: 78.060	 validation loss: 0.5353	 validation accuracy: 77.292 
best val accuracy: 77.291961 	 corresponding train accuracy: 77.657005
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.5029 	 test accuracy:	 77.528 
confusion matrix: 
[163  24]
[ 56 113]

classification report: 
              precision    recall  f1-score   support

          HC       0.74      0.87      0.80       187
         MDD       0.82      0.67      0.74       169

    accuracy                           0.78       356
   macro avg       0.78      0.77      0.77       356
weighted avg       0.78      0.78      0.77       356

========================	test end	========================

========================	2023-04-13 22:24:19	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch150_l2re2_lr0002_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch150_l2re2_lr0002_pretrainTrue_clusterFalse	epochs: 150	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 20	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.3485	 train accuracy: 90.982	 validation loss: 0.3893	 validation accuracy: 91.537 
train(max_min): 	train loss: 0.3450	 train accuracy: 91.787	 validation loss: 0.3893	 validation accuracy: 91.819 
best val accuracy: 91.819464 	 corresponding train accuracy: 91.747182
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2516 	 test accuracy:	 89.326 
confusion matrix: 
[170  17]
[ 21 148]

classification report: 
              precision    recall  f1-score   support

          HC       0.89      0.91      0.90       187
         MDD       0.90      0.88      0.89       169

    accuracy                           0.89       356
   macro avg       0.89      0.89      0.89       356
weighted avg       0.89      0.89      0.89       356

========================	test end	========================

========================	2023-04-13 22:32:28	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch150_l2re2_lr0002_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch150_l2re2_lr0002_pretrainTrue_clusterFalse	epochs: 150	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 20	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2552	 train accuracy: 97.987	 validation loss: 0.2952	 validation accuracy: 96.333 
train(max_min): 	train loss: 0.2552	 train accuracy: 98.430	 validation loss: 0.2939	 validation accuracy: 96.474 
best val accuracy: 96.473907 	 corresponding train accuracy: 97.906602
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1365 	 test accuracy:	 95.225 
confusion matrix: 
[178   9]
[  8 161]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.95      0.95       187
         MDD       0.95      0.95      0.95       169

    accuracy                           0.95       356
   macro avg       0.95      0.95      0.95       356
weighted avg       0.95      0.95      0.95       356

========================	test end	========================

========================	2023-04-13 22:37:41	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch150_l2re2_lr0002_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch150_l2re2_lr0002_pretrainTrue_clusterFalse	epochs: 150	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 20	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: MH	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2495	 train accuracy: 97.665	 validation loss: 0.3392	 validation accuracy: 93.512 
train(max_min): 	train loss: 0.2477	 train accuracy: 98.068	 validation loss: 0.3385	 validation accuracy: 93.653 
best val accuracy: 93.653032 	 corresponding train accuracy: 97.423510
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1532 	 test accuracy:	 94.382 
confusion matrix: 
[177  10]
[ 10 159]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.95      0.95       187
         MDD       0.94      0.94      0.94       169

    accuracy                           0.94       356
   macro avg       0.94      0.94      0.94       356
weighted avg       0.94      0.94      0.94       356

========================	test end	========================

========================	2023-04-13 22:44:18	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch150_l2re2_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch150_l2re2_lr0002_pretrainFalse_clusterFalse	epochs: 150	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 20	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: MH	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-13 22:44:43	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 20	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-13 22:50:17	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.4289	 train accuracy: 100.000	 validation loss: 0.6862	 validation accuracy: 87.737 
train(max_min): 	train loss: 0.4288	 train accuracy: 100.000	 validation loss: 0.4503	 validation accuracy: 98.713 
best val accuracy: 98.712737 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	2023-04-13 23:01:11	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2343	 train accuracy: 99.316	 validation loss: 0.2632	 validation accuracy: 98.025 
train(max_min): 	train loss: 0.2340	 train accuracy: 99.316	 validation loss: 0.2632	 validation accuracy: 98.025 
best val accuracy: 98.025388 	 corresponding train accuracy: 99.315620
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0982 	 test accuracy:	 97.753 
confusion matrix: 
[184   3]
[  5 164]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.98      0.98       187
         MDD       0.98      0.97      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-13 23:08:03	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0001_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0001_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0001	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-13 23:13:41	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-13 23:16:27	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-13 23:19:23	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-13 23:24:37	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-13 23:26:22	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re5_lr0003_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re5_lr0003_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.5	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-13 23:28:04	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop3_mfcc_epoch100_l2re5_lr0003_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop3_mfcc_epoch100_l2re5_lr0003_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.5	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.3	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.4511	 train accuracy: 99.458	 validation loss: 0.7710	 validation accuracy: 90.650 
train(max_min): 	train loss: 0.4511	 train accuracy: 99.516	 validation loss: 0.5095	 validation accuracy: 97.561 
best val accuracy: 97.560976 	 corresponding train accuracy: 99.264421
========================	train end	========================

========================	2023-04-13 23:36:21	========================
model name: 	AT_TIM_train_IEMOCAP_order3_drop3_mfcc_epoch100_l2re5_lr0003_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_IEMOCAP_order3_drop3_mfcc_epoch100_l2re5_lr0003_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.5	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.3	is_weight: True	seq_len: 313	num_class: 6	


========================	2023-04-13 23:43:51	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop3_mfcc_epoch100_l2re5_lr0003_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop3_mfcc_epoch100_l2re5_lr0003_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.5	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.3	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-14 09:40:27	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0003_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0003_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2371	 train accuracy: 99.436	 validation loss: 0.2697	 validation accuracy: 97.602 
train(max_min): 	train loss: 0.2370	 train accuracy: 99.597	 validation loss: 0.2692	 validation accuracy: 97.884 
best val accuracy: 97.884344 	 corresponding train accuracy: 99.516908
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0987 	 test accuracy:	 98.315 
confusion matrix: 
[182   5]
[  1 168]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.97      0.98       187
         MDD       0.97      0.99      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-14 09:45:59	========================
model name: 	AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0003_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0003_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.4	step_size: 20	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2224	 train accuracy: 99.919	 validation loss: 0.2519	 validation accuracy: 97.743 
train(max_min): 	train loss: 0.2221	 train accuracy: 99.960	 validation loss: 0.2511	 validation accuracy: 98.307 
best val accuracy: 98.307475 	 corresponding train accuracy: 99.838969
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0965 	 test accuracy:	 98.315 
confusion matrix: 
[185   2]
[  4 165]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       187
         MDD       0.99      0.98      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-14 09:50:18	========================
model name: 	AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0003_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0003_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-14 09:52:56	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0003_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0003_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-14 09:53:16	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2215	 train accuracy: 99.879	 validation loss: 0.2477	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.2213	 train accuracy: 99.879	 validation loss: 0.2466	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 99.838969
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0899 	 test accuracy:	 98.315 
confusion matrix: 
[185   2]
[  4 165]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       187
         MDD       0.99      0.98      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-14 09:56:14	========================
model name: 	AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1995	 train accuracy: 100.000	 validation loss: 0.2423	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1994	 train accuracy: 100.000	 validation loss: 0.2313	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0726 	 test accuracy:	 98.315 
confusion matrix: 
[185   2]
[  4 165]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       187
         MDD       0.99      0.98      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-14 10:02:00	========================
model name: 	AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: MH	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	test begin	========================
test: 			test loss: 	0.0719 	 test accuracy:	 98.315 
confusion matrix: 
[185   2]
[  4 165]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       187
         MDD       0.99      0.98      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-14 10:02:40	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch2_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch2_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 2	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: MH	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	test begin	========================
test: 			test loss: 	0.0719 	 test accuracy:	 98.315 
confusion matrix: 
[185   2]
[  4 165]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       187
         MDD       0.99      0.98      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-14 10:03:13	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch2_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch2_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 2	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: MH	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.5016	 train accuracy: 80.274	 validation loss: 0.4688	 validation accuracy: 83.780 
train(max_min): 	train loss: 0.5016	 train accuracy: 80.274	 validation loss: 0.4688	 validation accuracy: 83.780 
best val accuracy: 83.779972 	 corresponding train accuracy: 80.273752
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.4171 	 test accuracy:	 79.775 
confusion matrix: 
[163  24]
[ 48 121]

classification report: 
              precision    recall  f1-score   support

          HC       0.77      0.87      0.82       187
         MDD       0.83      0.72      0.77       169

    accuracy                           0.80       356
   macro avg       0.80      0.79      0.79       356
weighted avg       0.80      0.80      0.80       356

========================	test end	========================

========================	2023-04-14 10:03:48	========================
model name: 	AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: MH	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2195	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2189	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0909 	 test accuracy:	 97.753 
confusion matrix: 
[185   2]
[  6 163]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       187
         MDD       0.99      0.96      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-14 10:21:45	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-14 10:22:34	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-14 10:23:03	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-14 10:23:41	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-14 10:24:18	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-14 10:25:09	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-14 10:26:02	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-14 10:41:00	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-14 10:41:23	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2538	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2289	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0998 	 test accuracy:	 97.472 
confusion matrix: 
[184   3]
[  6 163]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.98      0.98       187
         MDD       0.98      0.96      0.97       169

    accuracy                           0.97       356
   macro avg       0.98      0.97      0.97       356
weighted avg       0.97      0.97      0.97       356

========================	test end	========================

========================	2023-04-14 11:03:28	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2778	 validation accuracy: 97.884 
train(max_min): 	train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2377	 validation accuracy: 98.025 
best val accuracy: 98.025388 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0810 	 test accuracy:	 98.596 
confusion matrix: 
[184   3]
[  2 167]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       187
         MDD       0.98      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-14 11:23:28	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-14 11:26:19	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2171	 train accuracy: 99.960	 validation loss: 0.2365	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2167	 train accuracy: 99.960	 validation loss: 0.2362	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 99.959742
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0835 	 test accuracy:	 98.876 
confusion matrix: 
[184   3]
[  1 168]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       187
         MDD       0.98      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-14 11:28:54	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-14 11:32:25	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1987	 train accuracy: 100.000	 validation loss: 0.2256	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.1987	 train accuracy: 100.000	 validation loss: 0.2196	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0717 	 test accuracy:	 99.157 
confusion matrix: 
[185   2]
[  1 168]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       187
         MDD       0.99      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-14 11:37:23	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-14 11:37:49	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2002	 train accuracy: 99.960	 validation loss: 0.2936	 validation accuracy: 97.602 
train(max_min): 	train loss: 0.2001	 train accuracy: 99.960	 validation loss: 0.2535	 validation accuracy: 98.025 
best val accuracy: 98.025388 	 corresponding train accuracy: 99.597424
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1049 	 test accuracy:	 98.034 
confusion matrix: 
[184   3]
[  4 165]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       187
         MDD       0.98      0.98      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-14 11:42:31	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2229	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2203	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0748 	 test accuracy:	 98.315 
confusion matrix: 
[183   4]
[  2 167]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.98       187
         MDD       0.98      0.99      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-14 12:44:41	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-14 12:48:14	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-14 12:51:59	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1987	 train accuracy: 100.000	 validation loss: 0.2303	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.1987	 train accuracy: 100.000	 validation loss: 0.2255	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0637 	 test accuracy:	 99.438 
confusion matrix: 
[186   1]
[  1 168]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       187
         MDD       0.99      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-14 12:55:03	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1987	 train accuracy: 100.000	 validation loss: 0.2179	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1987	 train accuracy: 100.000	 validation loss: 0.2147	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0627 	 test accuracy:	 99.438 
confusion matrix: 
[185   2]
[  0 169]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       187
         MDD       0.99      1.00      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-14 13:10:37	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2659	 validation accuracy: 97.743 
train(max_min): 	train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2399	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 99.798712
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0855 	 test accuracy:	 98.034 
confusion matrix: 
[185   2]
[  5 164]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       187
         MDD       0.99      0.97      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-14 13:15:38	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2145	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2125	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0684 	 test accuracy:	 99.157 
confusion matrix: 
[186   1]
[  2 167]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       187
         MDD       0.99      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-14 13:24:11	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2125	 train accuracy: 100.000	 validation loss: 0.2418	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2123	 train accuracy: 100.000	 validation loss: 0.2414	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0706 	 test accuracy:	 98.596 
confusion matrix: 
[186   1]
[  4 165]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       187
         MDD       0.99      0.98      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-14 13:33:47	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-14 14:14:21	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2172	 train accuracy: 100.000	 validation loss: 0.2397	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2168	 train accuracy: 100.000	 validation loss: 0.2397	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 99.879227
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0812 	 test accuracy:	 99.438 
confusion matrix: 
[185   2]
[  0 169]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       187
         MDD       0.99      1.00      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-14 14:17:41	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2183	 train accuracy: 99.919	 validation loss: 0.2384	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2182	 train accuracy: 99.960	 validation loss: 0.2379	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 99.919485
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0807 	 test accuracy:	 99.438 
confusion matrix: 
[185   2]
[  0 169]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       187
         MDD       0.99      1.00      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-14 14:28:53	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2115	 train accuracy: 100.000	 validation loss: 0.2450	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2112	 train accuracy: 100.000	 validation loss: 0.2400	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0777 	 test accuracy:	 98.876 
confusion matrix: 
[184   3]
[  1 168]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       187
         MDD       0.98      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-14 14:32:09	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2103	 train accuracy: 100.000	 validation loss: 0.2372	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.2101	 train accuracy: 100.000	 validation loss: 0.2348	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0799 	 test accuracy:	 99.438 
confusion matrix: 
[185   2]
[  0 169]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       187
         MDD       0.99      1.00      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-14 14:45:39	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse_best.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.4251	 train accuracy: 100.000	 validation loss: 0.4380	 validation accuracy: 99.593 
train(max_min): 	train loss: 0.4251	 train accuracy: 100.000	 validation loss: 0.4375	 validation accuracy: 99.729 
best val accuracy: 99.728997 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	2023-04-14 14:57:39	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2230	 train accuracy: 100.000	 validation loss: 0.2533	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.2230	 train accuracy: 100.000	 validation loss: 0.2499	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0753 	 test accuracy:	 99.438 
confusion matrix: 
[185   2]
[  0 169]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       187
         MDD       0.99      1.00      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-14 15:00:27	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2770	 train accuracy: 97.142	 validation loss: 0.3043	 validation accuracy: 96.474 
train(max_min): 	train loss: 0.2770	 train accuracy: 97.262	 validation loss: 0.3031	 validation accuracy: 96.897 
best val accuracy: 96.897038 	 corresponding train accuracy: 96.578100
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1672 	 test accuracy:	 94.663 
confusion matrix: 
[180   7]
[ 12 157]

classification report: 
              precision    recall  f1-score   support

          HC       0.94      0.96      0.95       187
         MDD       0.96      0.93      0.94       169

    accuracy                           0.95       356
   macro avg       0.95      0.95      0.95       356
weighted avg       0.95      0.95      0.95       356

========================	test end	========================

========================	2023-04-15 23:07:48	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2196	 train accuracy: 99.879	 validation loss: 0.2461	 validation accuracy: 98.307 
train(max_min): 	train loss: 0.2190	 train accuracy: 99.919	 validation loss: 0.2457	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 99.758454
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0805 	 test accuracy:	 99.157 
confusion matrix: 
[185   2]
[  1 168]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       187
         MDD       0.99      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-15 23:10:14	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2182	 train accuracy: 99.879	 validation loss: 0.2374	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2178	 train accuracy: 99.879	 validation loss: 0.2371	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 99.879227
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0680 	 test accuracy:	 99.438 
confusion matrix: 
[186   1]
[  1 168]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       187
         MDD       0.99      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-15 23:13:48	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2112	 train accuracy: 100.000	 validation loss: 0.2335	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2112	 train accuracy: 100.000	 validation loss: 0.2331	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 99.919485
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0925 	 test accuracy:	 98.596 
confusion matrix: 
[185   2]
[  3 166]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       187
         MDD       0.99      0.98      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-15 23:20:03	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2308	 validation accuracy: 97.884 
train(max_min): 	train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2224	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0657 	 test accuracy:	 99.438 
confusion matrix: 
[185   2]
[  0 169]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       187
         MDD       0.99      1.00      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-15 23:24:03	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1993	 train accuracy: 100.000	 validation loss: 0.2274	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.1993	 train accuracy: 100.000	 validation loss: 0.2243	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0814 	 test accuracy:	 98.876 
confusion matrix: 
[185   2]
[  2 167]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       187
         MDD       0.99      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-15 23:27:38	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1993	 train accuracy: 100.000	 validation loss: 0.2333	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.1993	 train accuracy: 100.000	 validation loss: 0.2238	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0656 	 test accuracy:	 99.157 
confusion matrix: 
[185   2]
[  1 168]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       187
         MDD       0.99      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-15 23:31:33	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2270	 train accuracy: 99.758	 validation loss: 0.2463	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2270	 train accuracy: 99.758	 validation loss: 0.2444	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 99.758454
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0856 	 test accuracy:	 99.719 
confusion matrix: 
[186   1]
[  0 169]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      1.00       187
         MDD       0.99      1.00      1.00       169

    accuracy                           1.00       356
   macro avg       1.00      1.00      1.00       356
weighted avg       1.00      1.00      1.00       356

========================	test end	========================

========================	2023-04-15 23:32:55	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2209	 train accuracy: 99.799	 validation loss: 0.2406	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2209	 train accuracy: 99.799	 validation loss: 0.2392	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 99.637681
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0916 	 test accuracy:	 99.157 
confusion matrix: 
[184   3]
[  0 169]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.98      0.99       187
         MDD       0.98      1.00      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-15 23:35:35	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.3228	 train accuracy: 94.364	 validation loss: 0.3555	 validation accuracy: 94.358 
train(max_min): 	train loss: 0.3226	 train accuracy: 94.686	 validation loss: 0.3554	 validation accuracy: 95.063 
best val accuracy: 95.063470 	 corresponding train accuracy: 94.082126
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2447 	 test accuracy:	 93.539 
confusion matrix: 
[176  11]
[ 12 157]

classification report: 
              precision    recall  f1-score   support

          HC       0.94      0.94      0.94       187
         MDD       0.93      0.93      0.93       169

    accuracy                           0.94       356
   macro avg       0.94      0.94      0.94       356
weighted avg       0.94      0.94      0.94       356

========================	test end	========================

========================	2023-04-15 23:38:57	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2107	 train accuracy: 100.000	 validation loss: 0.2386	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2107	 train accuracy: 100.000	 validation loss: 0.2386	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 99.959742
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0666 	 test accuracy:	 100.000 
confusion matrix: 
[187   0]
[  0 169]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      1.00      1.00       187
         MDD       1.00      1.00      1.00       169

    accuracy                           1.00       356
   macro avg       1.00      1.00      1.00       356
weighted avg       1.00      1.00      1.00       356

========================	test end	========================

========================	2023-04-15 23:43:37	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-15 23:43:52	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-15 23:50:13	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.4245	 train accuracy: 100.000	 validation loss: 0.4330	 validation accuracy: 99.549 
train(max_min): 	train loss: 0.4245	 train accuracy: 100.000	 validation loss: 0.4330	 validation accuracy: 99.549 
best val accuracy: 99.549259 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	2023-04-16 00:04:29	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-16 00:05:10	========================
model name: 	MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-16 09:09:39	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1990	 train accuracy: 99.960	 validation loss: 0.2331	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2260	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0891 	 test accuracy:	 98.315 
confusion matrix: 
[184   3]
[  3 166]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       187
         MDD       0.98      0.98      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-16 09:13:45	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-16 09:18:32	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-16 09:19:23	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-16 09:23:19	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1992	 train accuracy: 99.960	 validation loss: 0.2437	 validation accuracy: 97.320 
train(max_min): 	train loss: 0.1992	 train accuracy: 99.960	 validation loss: 0.2307	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 99.919485
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0956 	 test accuracy:	 98.315 
confusion matrix: 
[183   4]
[  2 167]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.98       187
         MDD       0.98      0.99      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-16 09:29:56	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-16 09:34:34	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-16 09:35:33	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2263	 train accuracy: 99.758	 validation loss: 0.2526	 validation accuracy: 98.307 
train(max_min): 	train loss: 0.2261	 train accuracy: 99.758	 validation loss: 0.2510	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 99.718196
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0933 	 test accuracy:	 98.034 
confusion matrix: 
[185   2]
[  5 164]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       187
         MDD       0.99      0.97      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-16 09:37:31	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2243	 train accuracy: 99.879	 validation loss: 0.2493	 validation accuracy: 98.307 
train(max_min): 	train loss: 0.2243	 train accuracy: 99.919	 validation loss: 0.2491	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 99.838969
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0863 	 test accuracy:	 99.157 
confusion matrix: 
[186   1]
[  2 167]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       187
         MDD       0.99      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-16 09:40:54	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2293	 train accuracy: 99.758	 validation loss: 0.2454	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2292	 train accuracy: 99.839	 validation loss: 0.2446	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 99.436393
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0955 	 test accuracy:	 98.315 
confusion matrix: 
[184   3]
[  3 166]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       187
         MDD       0.98      0.98      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-16 09:44:43	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================
test: 			test loss: 	0.1025 	 test accuracy:	 98.315 
confusion matrix: 
[184   3]
[  3 166]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       187
         MDD       0.98      0.98      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-16 09:45:13	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2247	 train accuracy: 99.879	 validation loss: 0.2442	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2247	 train accuracy: 99.879	 validation loss: 0.2442	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 99.758454
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0910 	 test accuracy:	 99.438 
confusion matrix: 
[185   2]
[  0 169]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       187
         MDD       0.99      1.00      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-16 09:46:45	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2214	 train accuracy: 99.919	 validation loss: 0.2506	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.2210	 train accuracy: 99.919	 validation loss: 0.2460	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 99.919485
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0971 	 test accuracy:	 98.315 
confusion matrix: 
[186   1]
[  5 164]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       187
         MDD       0.99      0.97      0.98       169

    accuracy                           0.98       356
   macro avg       0.98      0.98      0.98       356
weighted avg       0.98      0.98      0.98       356

========================	test end	========================

========================	2023-04-16 09:49:34	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2241	 train accuracy: 99.879	 validation loss: 0.2490	 validation accuracy: 98.307 
train(max_min): 	train loss: 0.2241	 train accuracy: 99.919	 validation loss: 0.2457	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 99.879227
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0950 	 test accuracy:	 99.719 
confusion matrix: 
[186   1]
[  0 169]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      1.00       187
         MDD       0.99      1.00      1.00       169

    accuracy                           1.00       356
   macro avg       1.00      1.00      1.00       356
weighted avg       1.00      1.00      1.00       356

========================	test end	========================

========================	2023-04-16 09:52:27	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2270	 train accuracy: 99.718	 validation loss: 0.2529	 validation accuracy: 98.025 
train(max_min): 	train loss: 0.2266	 train accuracy: 99.879	 validation loss: 0.2492	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 99.879227
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0875 	 test accuracy:	 99.438 
confusion matrix: 
[187   0]
[  2 167]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       187
         MDD       1.00      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-16 10:00:31	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2247	 train accuracy: 99.839	 validation loss: 0.2501	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2246	 train accuracy: 99.919	 validation loss: 0.2485	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 99.718196
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1019 	 test accuracy:	 98.596 
confusion matrix: 
[185   2]
[  3 166]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       187
         MDD       0.99      0.98      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-16 10:02:58	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2265	 train accuracy: 99.718	 validation loss: 0.2597	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.2265	 train accuracy: 99.799	 validation loss: 0.2569	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 99.798712
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0927 	 test accuracy:	 98.596 
confusion matrix: 
[184   3]
[  2 167]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       187
         MDD       0.98      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-16 10:06:06	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2294	 train accuracy: 99.718	 validation loss: 0.2481	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2294	 train accuracy: 99.718	 validation loss: 0.2475	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 99.718196
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1015 	 test accuracy:	 98.876 
confusion matrix: 
[184   3]
[  1 168]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       187
         MDD       0.98      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-16 10:07:45	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.7, 0.2, 0.1]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2247	 train accuracy: 99.758	 validation loss: 0.2450	 validation accuracy: 98.307 
train(max_min): 	train loss: 0.2244	 train accuracy: 99.839	 validation loss: 0.2416	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 99.798712
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0890 	 test accuracy:	 99.157 
confusion matrix: 
[185   2]
[  1 168]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       187
         MDD       0.99      0.99      0.99       169

    accuracy                           0.99       356
   macro avg       0.99      0.99      0.99       356
weighted avg       0.99      0.99      0.99       356

========================	test end	========================

========================	2023-04-16 10:10:21	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2261	 train accuracy: 99.859	 validation loss: 0.2334	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2261	 train accuracy: 99.906	 validation loss: 0.2334	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 99.906059
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1046 	 test accuracy:	 98.172 
confusion matrix: 
[371   3]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 10:12:12	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2308	 train accuracy: 99.812	 validation loss: 0.2408	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2305	 train accuracy: 99.859	 validation loss: 0.2408	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 99.859089
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1028 	 test accuracy:	 98.031 
confusion matrix: 
[370   4]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 10:14:20	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2187	 train accuracy: 99.953	 validation loss: 0.2318	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.2187	 train accuracy: 100.000	 validation loss: 0.2318	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0873 	 test accuracy:	 98.734 
confusion matrix: 
[371   3]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 10:17:29	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2196	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2140	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 99.812118
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0795 	 test accuracy:	 98.875 
confusion matrix: 
[370   4]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 10:48:26	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: CS	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-16 10:48:45	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: CS	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2157	 train accuracy: 100.000	 validation loss: 0.2392	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2153	 train accuracy: 100.000	 validation loss: 0.2388	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 99.953030
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0936 	 test accuracy:	 98.453 
confusion matrix: 
[371   3]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 10:50:57	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: CS	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2276	 train accuracy: 99.718	 validation loss: 0.2326	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.2276	 train accuracy: 99.765	 validation loss: 0.2326	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 99.765148
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1011 	 test accuracy:	 98.734 
confusion matrix: 
[371   3]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 10:53:25	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: CS	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2225	 train accuracy: 99.953	 validation loss: 0.2358	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.2223	 train accuracy: 99.953	 validation loss: 0.2357	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 99.953030
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0947 	 test accuracy:	 99.015 
confusion matrix: 
[373   1]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 14:40:30	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-16 14:42:14	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2001	 train accuracy: 99.906	 validation loss: 0.2298	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.1997	 train accuracy: 99.953	 validation loss: 0.2260	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 99.953030
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0961 	 test accuracy:	 98.172 
confusion matrix: 
[371   3]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 14:46:58	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2237	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2220	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1015 	 test accuracy:	 97.609 
confusion matrix: 
[369   5]
[ 12 325]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.98      0.96      0.97       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 14:54:49	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1998	 train accuracy: 99.953	 validation loss: 0.2393	 validation accuracy: 97.884 
train(max_min): 	train loss: 0.1997	 train accuracy: 99.953	 validation loss: 0.2319	 validation accuracy: 98.307 
best val accuracy: 98.307475 	 corresponding train accuracy: 99.765148
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0882 	 test accuracy:	 98.312 
confusion matrix: 
[366   8]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.98       374
         MDD       0.98      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 14:59:07	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2325	 validation accuracy: 98.166 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2253	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0921 	 test accuracy:	 98.172 
confusion matrix: 
[365   9]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.98       374
         MDD       0.97      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 15:04:02	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-16 15:06:42	========================
model name: 	MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2259	 train accuracy: 99.765	 validation loss: 0.2432	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.2256	 train accuracy: 99.859	 validation loss: 0.2427	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 99.859089
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1112 	 test accuracy:	 98.312 
confusion matrix: 
[372   2]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 15:08:39	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2109	 train accuracy: 100.000	 validation loss: 0.2271	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.2105	 train accuracy: 100.000	 validation loss: 0.2267	 validation accuracy: 98.449 
best val accuracy: 98.448519 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0782 	 test accuracy:	 98.734 
confusion matrix: 
[374   0]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.97      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 15:10:38	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2080	 train accuracy: 100.000	 validation loss: 0.2215	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2079	 train accuracy: 100.000	 validation loss: 0.2212	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0654 	 test accuracy:	 99.297 
confusion matrix: 
[373   1]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 15:15:00	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2548	 train accuracy: 98.685	 validation loss: 0.2578	 validation accuracy: 98.025 
train(max_min): 	train loss: 0.2548	 train accuracy: 98.779	 validation loss: 0.2578	 validation accuracy: 98.025 
best val accuracy: 98.025388 	 corresponding train accuracy: 98.778769
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1508 	 test accuracy:	 97.328 
confusion matrix: 
[367   7]
[ 12 325]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.98      0.97       374
         MDD       0.98      0.96      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-16 15:16:30	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2227	 train accuracy: 99.859	 validation loss: 0.2467	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2222	 train accuracy: 99.906	 validation loss: 0.2461	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 99.859089
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1148 	 test accuracy:	 97.609 
confusion matrix: 
[367   7]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.98      0.98       374
         MDD       0.98      0.97      0.97       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 15:33:02	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-16 15:36:54	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2264	 train accuracy: 99.812	 validation loss: 0.2477	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.2260	 train accuracy: 99.859	 validation loss: 0.2473	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 99.765148
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1107 	 test accuracy:	 98.312 
confusion matrix: 
[371   3]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 15:45:44	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2290	 train accuracy: 99.812	 validation loss: 0.2457	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2287	 train accuracy: 99.812	 validation loss: 0.2457	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 99.812118
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1179 	 test accuracy:	 98.594 
confusion matrix: 
[371   3]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 15:48:29	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2203	 train accuracy: 99.953	 validation loss: 0.2487	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.2203	 train accuracy: 99.953	 validation loss: 0.2484	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 99.906059
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1014 	 test accuracy:	 98.734 
confusion matrix: 
[373   1]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 15:52:05	========================
model name: 	TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2394	 train accuracy: 99.577	 validation loss: 0.2499	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2389	 train accuracy: 99.577	 validation loss: 0.2498	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 99.530296
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1343 	 test accuracy:	 97.609 
confusion matrix: 
[372   2]
[ 15 322]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.99      0.98       374
         MDD       0.99      0.96      0.97       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 15:55:41	========================
model name: 	Transformer_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 2048	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2138	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2121	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0998 	 test accuracy:	 97.890 
confusion matrix: 
[371   3]
[ 12 325]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.99      0.96      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 16:12:34	========================
model name: 	AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2227	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2207	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0755 	 test accuracy:	 98.875 
confusion matrix: 
[372   2]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 16:22:37	========================
model name: 	AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2235	 validation accuracy: 98.307 
train(max_min): 	train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2163	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1211 	 test accuracy:	 97.750 
confusion matrix: 
[369   5]
[ 11 326]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.98      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 16:27:35	========================
model name: 	AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2316	 validation accuracy: 98.307 
train(max_min): 	train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2291	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 99.953030
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0790 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 16:36:22	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2064	 validation accuracy: 99.718 
train(max_min): 	train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2015	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0588 	 test accuracy:	 99.578 
confusion matrix: 
[373   1]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      1.00       374
         MDD       1.00      0.99      1.00       337

    accuracy                           1.00       711
   macro avg       1.00      1.00      1.00       711
weighted avg       1.00      1.00      1.00       711

========================	test end	========================

========================	2023-04-16 16:51:22	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1992	 train accuracy: 100.000	 validation loss: 0.2301	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.1992	 train accuracy: 100.000	 validation loss: 0.2183	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1187 	 test accuracy:	 97.890 
confusion matrix: 
[369   5]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.98      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 17:04:48	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-16 17:06:01	========================
model name: 	Transformer_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2106	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2089	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0560 	 test accuracy:	 99.578 
confusion matrix: 
[374   0]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      1.00       374
         MDD       1.00      0.99      1.00       337

    accuracy                           1.00       711
   macro avg       1.00      1.00      1.00       711
weighted avg       1.00      1.00      1.00       711

========================	test end	========================

========================	2023-04-16 17:33:56	========================
model name: 	AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2004	 train accuracy: 99.953	 validation loss: 0.2325	 validation accuracy: 98.025 
train(max_min): 	train loss: 0.1998	 train accuracy: 100.000	 validation loss: 0.2273	 validation accuracy: 98.307 
best val accuracy: 98.307475 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1005 	 test accuracy:	 98.031 
confusion matrix: 
[368   6]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 17:40:38	========================
model name: 	AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2296	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2236	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0820 	 test accuracy:	 98.594 
confusion matrix: 
[368   6]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       374
         MDD       0.98      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 17:44:50	========================
model name: 	AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2409	 validation accuracy: 97.743 
train(max_min): 	train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2369	 validation accuracy: 98.166 
best val accuracy: 98.166432 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0849 	 test accuracy:	 98.594 
confusion matrix: 
[370   4]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 17:50:01	========================
model name: 	AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1999	 train accuracy: 100.000	 validation loss: 0.2178	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1998	 train accuracy: 100.000	 validation loss: 0.2172	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0931 	 test accuracy:	 98.031 
confusion matrix: 
[368   6]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 17:56:15	========================
model name: 	AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1998	 train accuracy: 99.953	 validation loss: 0.2240	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.1996	 train accuracy: 100.000	 validation loss: 0.2238	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 99.953030
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1151 	 test accuracy:	 97.890 
confusion matrix: 
[368   6]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 19:16:04	========================
model name: 	AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2001	 train accuracy: 99.953	 validation loss: 0.2432	 validation accuracy: 97.602 
train(max_min): 	train loss: 0.1998	 train accuracy: 100.000	 validation loss: 0.2421	 validation accuracy: 97.743 
best val accuracy: 97.743300 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0856 	 test accuracy:	 98.453 
confusion matrix: 
[370   4]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 19:28:24	========================
model name: 	AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_DeltaTIM_train_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2271	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2229	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 99.953030
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0914 	 test accuracy:	 98.172 
confusion matrix: 
[368   6]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 19:37:12	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2268	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2229	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0856 	 test accuracy:	 98.594 
confusion matrix: 
[371   3]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 19:41:01	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2231	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2210	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0762 	 test accuracy:	 98.875 
confusion matrix: 
[373   1]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 19:48:09	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2316	 validation accuracy: 98.166 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2251	 validation accuracy: 98.449 
best val accuracy: 98.448519 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0912 	 test accuracy:	 98.172 
confusion matrix: 
[368   6]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 19:53:27	========================
model name: 	TIM_train__MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train__MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: 	feature_dim: 39	dilation: 6	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2336	 train accuracy: 99.812	 validation loss: 0.2515	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2336	 train accuracy: 99.812	 validation loss: 0.2514	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 99.812118
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1181 	 test accuracy:	 98.172 
confusion matrix: 
[370   4]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 19:56:14	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2607	 train accuracy: 97.980	 validation loss: 0.2671	 validation accuracy: 97.602 
train(max_min): 	train loss: 0.2607	 train accuracy: 98.215	 validation loss: 0.2671	 validation accuracy: 97.602 
best val accuracy: 97.602257 	 corresponding train accuracy: 98.215124
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1781 	 test accuracy:	 96.624 
confusion matrix: 
[364  10]
[ 14 323]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.97      0.97       374
         MDD       0.97      0.96      0.96       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-16 19:57:34	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2415	 train accuracy: 99.483	 validation loss: 0.2573	 validation accuracy: 97.461 
train(max_min): 	train loss: 0.2415	 train accuracy: 99.624	 validation loss: 0.2573	 validation accuracy: 97.743 
best val accuracy: 97.743300 	 corresponding train accuracy: 99.483326
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1402 	 test accuracy:	 98.031 
confusion matrix: 
[371   3]
[ 11 326]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 20:00:03	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: CS	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2416	 train accuracy: 99.295	 validation loss: 0.2528	 validation accuracy: 98.307 
train(max_min): 	train loss: 0.2416	 train accuracy: 99.436	 validation loss: 0.2527	 validation accuracy: 98.449 
best val accuracy: 98.448519 	 corresponding train accuracy: 99.342414
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1380 	 test accuracy:	 97.609 
confusion matrix: 
[369   5]
[ 12 325]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.98      0.96      0.97       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 20:07:05	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1987	 train accuracy: 100.000	 validation loss: 0.2313	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2299	 validation accuracy: 98.449 
best val accuracy: 98.448519 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0727 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 20:12:40	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2147	 train accuracy: 100.000	 validation loss: 0.2353	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2147	 train accuracy: 100.000	 validation loss: 0.2353	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0903 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 20:22:48	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2159	 train accuracy: 99.953	 validation loss: 0.2417	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2158	 train accuracy: 100.000	 validation loss: 0.2409	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1033 	 test accuracy:	 98.594 
confusion matrix: 
[369   5]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 20:27:20	========================
model name: 	MultiTIM_train_ADD_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_BiDIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-16 20:30:47	========================
model name: 	MultiTIM_train_ADD_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_BiDIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-16 20:32:00	========================
model name: 	MultiTIM_train_ADD_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_BiDIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-16 20:32:32	========================
model name: 	MultiTIM_train_ADD_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_BiDIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2095	 train accuracy: 100.000	 validation loss: 0.2321	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2093	 train accuracy: 100.000	 validation loss: 0.2320	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0817 	 test accuracy:	 99.015 
confusion matrix: 
[372   2]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 20:43:34	========================
model name: 	MultiTIM_train_ADD_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_BiDIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2108	 train accuracy: 100.000	 validation loss: 0.2383	 validation accuracy: 98.166 
train(max_min): 	train loss: 0.2103	 train accuracy: 100.000	 validation loss: 0.2357	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 99.906059
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0953 	 test accuracy:	 98.172 
confusion matrix: 
[368   6]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 20:52:34	========================
model name: 	MultiTIM_train_ADD_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_BiDIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2142	 train accuracy: 100.000	 validation loss: 0.2429	 validation accuracy: 97.743 
train(max_min): 	train loss: 0.2142	 train accuracy: 100.000	 validation loss: 0.2422	 validation accuracy: 98.449 
best val accuracy: 98.448519 	 corresponding train accuracy: 99.953030
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0996 	 test accuracy:	 98.312 
confusion matrix: 
[370   4]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 20:57:29	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2166	 train accuracy: 100.000	 validation loss: 0.2335	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.2165	 train accuracy: 100.000	 validation loss: 0.2334	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0850 	 test accuracy:	 98.734 
confusion matrix: 
[371   3]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 21:04:06	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2163	 train accuracy: 99.953	 validation loss: 0.2364	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2163	 train accuracy: 100.000	 validation loss: 0.2361	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0890 	 test accuracy:	 98.453 
confusion matrix: 
[370   4]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 21:09:01	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2154	 train accuracy: 100.000	 validation loss: 0.2423	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2150	 train accuracy: 100.000	 validation loss: 0.2423	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1007 	 test accuracy:	 98.172 
confusion matrix: 
[368   6]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 21:13:23	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-16 21:15:24	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2118	 train accuracy: 100.000	 validation loss: 0.2379	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2118	 train accuracy: 100.000	 validation loss: 0.2359	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0852 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 21:19:49	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_DIFF	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2139	 train accuracy: 99.953	 validation loss: 0.2342	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2136	 train accuracy: 100.000	 validation loss: 0.2340	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0851 	 test accuracy:	 99.297 
confusion matrix: 
[370   4]
[  1 336]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       374
         MDD       0.99      1.00      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 21:28:11	========================
model name: 	MultiTIM_train_ADD_Conv_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_Conv_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_Conv	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2033	 train accuracy: 100.000	 validation loss: 0.2332	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2033	 train accuracy: 100.000	 validation loss: 0.2324	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0865 	 test accuracy:	 99.015 
confusion matrix: 
[370   4]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 21:34:09	========================
model name: 	MultiTIM_train_ADD_Conv_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_Conv_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_Conv	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2026	 train accuracy: 100.000	 validation loss: 0.2266	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.2024	 train accuracy: 100.000	 validation loss: 0.2252	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0913 	 test accuracy:	 98.734 
confusion matrix: 
[369   5]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 21:43:09	========================
model name: 	MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_AT	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2148	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2147	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0775 	 test accuracy:	 98.734 
confusion matrix: 
[371   3]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 21:52:23	========================
model name: 	MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_AT	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2234	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.1987	 train accuracy: 100.000	 validation loss: 0.2200	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0654 	 test accuracy:	 99.578 
confusion matrix: 
[374   0]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      1.00       374
         MDD       1.00      0.99      1.00       337

    accuracy                           1.00       711
   macro avg       1.00      1.00      1.00       711
weighted avg       1.00      1.00      1.00       711

========================	test end	========================

========================	2023-04-16 21:58:01	========================
model name: 	MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_AT	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2222	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2206	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0966 	 test accuracy:	 98.594 
confusion matrix: 
[371   3]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 22:11:58	========================
model name: 	MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_AT	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-16 22:12:34	========================
model name: 	MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_AT	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-16 22:14:05	========================
model name: 	MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_AT	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2389	 validation accuracy: 97.884 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2306	 validation accuracy: 98.449 
best val accuracy: 98.448519 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0940 	 test accuracy:	 98.312 
confusion matrix: 
[369   5]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-16 22:24:46	========================
model name: 	MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_AT	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2711	 validation accuracy: 96.051 
train(max_min): 	train loss: 0.1987	 train accuracy: 100.000	 validation loss: 0.2512	 validation accuracy: 97.038 
best val accuracy: 97.038082 	 corresponding train accuracy: 99.906059
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1894 	 test accuracy:	 94.233 
confusion matrix: 
[374   0]
[ 41 296]

classification report: 
              precision    recall  f1-score   support

          HC       0.90      1.00      0.95       374
         MDD       1.00      0.88      0.94       337

    accuracy                           0.94       711
   macro avg       0.95      0.94      0.94       711
weighted avg       0.95      0.94      0.94       711

========================	test end	========================

========================	2023-04-16 22:31:41	========================
model name: 	MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: ADD_AT	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2375	 validation accuracy: 98.025 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2191	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 99.906059
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1261 	 test accuracy:	 96.765 
confusion matrix: 
[371   3]
[ 20 317]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.99      0.97       374
         MDD       0.99      0.94      0.96       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-16 22:37:08	========================
model name: 	MultiTIM_train_AT_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: AT_AT	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2192	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2178	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0743 	 test accuracy:	 99.156 
confusion matrix: 
[372   2]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 22:46:04	========================
model name: 	MultiTIM_train_AT_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: AT_AT	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1992	 train accuracy: 100.000	 validation loss: 0.2104	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2104	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0871 	 test accuracy:	 98.734 
confusion matrix: 
[369   5]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 22:51:59	========================
model name: 	MultiTIM_train_AT_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	multi_type: AT_AT	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2113	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2097	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0883 	 test accuracy:	 98.734 
confusion matrix: 
[370   4]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-16 23:01:17	========================
model name: 	MultiTIM_train_AT_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_AT_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_AT	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2258	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2242	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0814 	 test accuracy:	 98.453 
confusion matrix: 
[369   5]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-17 09:22:45	========================
model name: 	MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-17 09:24:35	========================
model name: 	MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.4345	 train accuracy: 99.936	 validation loss: 0.4647	 validation accuracy: 99.420 
train(max_min): 	train loss: 0.4345	 train accuracy: 99.936	 validation loss: 0.4626	 validation accuracy: 99.485 
best val accuracy: 99.484868 	 corresponding train accuracy: 99.935608
========================	train end	========================

========================	2023-04-17 09:37:39	========================
model name: 	MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	test begin	========================
test: 			test loss: 	0.0880 	 test accuracy:	 98.842 
confusion matrix: 
[227   6   0   0   0   0]
[  6 224   0   0   0   0]
[  0   0 382   2   0   0]
[  0   0   4 119   0   0]
[  0   0   0   0 355   0]
[  0   0   0   0   0 229]

classification report: 
              precision    recall  f1-score   support

       angry       0.97      0.97      0.97       233
     excited       0.97      0.97      0.97       230
  frustrated       0.99      0.99      0.99       384
       happy       0.98      0.97      0.98       123
     neutral       1.00      1.00      1.00       355
         sad       1.00      1.00      1.00       229

    accuracy                           0.99      1554
   macro avg       0.99      0.99      0.99      1554
weighted avg       0.99      0.99      0.99      1554

========================	test end	========================

========================	2023-04-17 09:40:33	========================
model name: 	MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-17 09:42:03	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-17 09:42:24	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2424	 train accuracy: 99.342	 validation loss: 0.2604	 validation accuracy: 97.461 
train(max_min): 	train loss: 0.2420	 train accuracy: 99.389	 validation loss: 0.2593	 validation accuracy: 98.307 
best val accuracy: 98.307475 	 corresponding train accuracy: 99.342414
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1271 	 test accuracy:	 98.312 
confusion matrix: 
[367   7]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.98       374
         MDD       0.98      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-17 09:46:10	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-17 09:48:11	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0006_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0006_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0006	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2248	 train accuracy: 99.906	 validation loss: 0.2616	 validation accuracy: 97.461 
train(max_min): 	train loss: 0.2248	 train accuracy: 99.906	 validation loss: 0.2612	 validation accuracy: 97.743 
best val accuracy: 97.743300 	 corresponding train accuracy: 99.859089
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1181 	 test accuracy:	 96.484 
confusion matrix: 
[373   1]
[ 24 313]

classification report: 
              precision    recall  f1-score   support

          HC       0.94      1.00      0.97       374
         MDD       1.00      0.93      0.96       337

    accuracy                           0.96       711
   macro avg       0.97      0.96      0.96       711
weighted avg       0.97      0.96      0.96       711

========================	test end	========================

========================	2023-04-17 09:51:16	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-17 09:53:31	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2478	 train accuracy: 99.014	 validation loss: 0.2577	 validation accuracy: 97.602 
train(max_min): 	train loss: 0.2463	 train accuracy: 99.202	 validation loss: 0.2577	 validation accuracy: 97.884 
best val accuracy: 97.884344 	 corresponding train accuracy: 99.154533
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1678 	 test accuracy:	 95.921 
confusion matrix: 
[366   8]
[ 21 316]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.98      0.96       374
         MDD       0.98      0.94      0.96       337

    accuracy                           0.96       711
   macro avg       0.96      0.96      0.96       711
weighted avg       0.96      0.96      0.96       711

========================	test end	========================

========================	2023-04-17 09:57:42	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2471	 train accuracy: 99.248	 validation loss: 0.2667	 validation accuracy: 97.461 
train(max_min): 	train loss: 0.2464	 train accuracy: 99.389	 validation loss: 0.2663	 validation accuracy: 98.307 
best val accuracy: 98.307475 	 corresponding train accuracy: 99.107562
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1392 	 test accuracy:	 96.765 
confusion matrix: 
[364  10]
[ 13 324]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.97      0.97       374
         MDD       0.97      0.96      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-17 10:04:35	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2584	 train accuracy: 98.074	 validation loss: 0.2689	 validation accuracy: 97.884 
train(max_min): 	train loss: 0.2578	 train accuracy: 98.356	 validation loss: 0.2686	 validation accuracy: 97.884 
best val accuracy: 97.884344 	 corresponding train accuracy: 98.356036
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1486 	 test accuracy:	 95.077 
confusion matrix: 
[368   6]
[ 29 308]

classification report: 
              precision    recall  f1-score   support

          HC       0.93      0.98      0.95       374
         MDD       0.98      0.91      0.95       337

    accuracy                           0.95       711
   macro avg       0.95      0.95      0.95       711
weighted avg       0.95      0.95      0.95       711

========================	test end	========================

========================	2023-04-17 10:07:44	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2299	 train accuracy: 99.718	 validation loss: 0.2586	 validation accuracy: 98.307 
train(max_min): 	train loss: 0.2290	 train accuracy: 99.765	 validation loss: 0.2542	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 99.765148
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1146 	 test accuracy:	 98.172 
confusion matrix: 
[366   8]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.98       374
         MDD       0.98      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-17 10:11:53	========================
model name: 	MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	2023-04-17 10:15:10	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2124	 train accuracy: 100.000	 validation loss: 0.2352	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.2124	 train accuracy: 100.000	 validation loss: 0.2351	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0980 	 test accuracy:	 98.172 
confusion matrix: 
[373   1]
[ 12 325]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      1.00      0.98       374
         MDD       1.00      0.96      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-17 10:18:50	========================
model name: 	MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: IEMOCAP	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.4260	 train accuracy: 100.000	 validation loss: 0.4609	 validation accuracy: 98.916 
train(max_min): 	train loss: 0.4258	 train accuracy: 100.000	 validation loss: 0.4406	 validation accuracy: 99.729 
best val accuracy: 99.728997 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0997 	 test accuracy:	 99.458 
confusion matrix: 
[220   0   0   0   0   0]
[  4 179   0   0   0   0]
[  0   0 382   1   0   0]
[  0   0   3 119   0   0]
[  0   0   0   0 344   0]
[  0   0   0   0   0 224]

classification report: 
              precision    recall  f1-score   support

       angry       0.98      1.00      0.99       220
     excited       1.00      0.98      0.99       183
  frustrated       0.99      1.00      0.99       383
       happy       0.99      0.98      0.98       122
     neutral       1.00      1.00      1.00       344
         sad       1.00      1.00      1.00       224

    accuracy                           0.99      1476
   macro avg       0.99      0.99      0.99      1476
weighted avg       0.99      0.99      0.99      1476

========================	test end	========================

========================	2023-04-17 10:27:11	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2422	 train accuracy: 99.202	 validation loss: 0.2610	 validation accuracy: 97.602 
train(max_min): 	train loss: 0.2421	 train accuracy: 99.389	 validation loss: 0.2594	 validation accuracy: 97.884 
best val accuracy: 97.884344 	 corresponding train accuracy: 99.389385
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1401 	 test accuracy:	 96.624 
confusion matrix: 
[369   5]
[ 19 318]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.99      0.97       374
         MDD       0.98      0.94      0.96       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-17 10:36:53	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2648	 train accuracy: 97.933	 validation loss: 0.2618	 validation accuracy: 97.743 
train(max_min): 	train loss: 0.2645	 train accuracy: 98.168	 validation loss: 0.2610	 validation accuracy: 97.884 
best val accuracy: 97.884344 	 corresponding train accuracy: 97.698450
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1548 	 test accuracy:	 95.359 
confusion matrix: 
[366   8]
[ 25 312]

classification report: 
              precision    recall  f1-score   support

          HC       0.94      0.98      0.96       374
         MDD       0.97      0.93      0.95       337

    accuracy                           0.95       711
   macro avg       0.96      0.95      0.95       711
weighted avg       0.95      0.95      0.95       711

========================	test end	========================

========================	2023-04-17 10:43:19	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2425	 train accuracy: 99.436	 validation loss: 0.2584	 validation accuracy: 97.602 
train(max_min): 	train loss: 0.2423	 train accuracy: 99.577	 validation loss: 0.2584	 validation accuracy: 98.166 
best val accuracy: 98.166432 	 corresponding train accuracy: 99.342414
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1452 	 test accuracy:	 97.468 
confusion matrix: 
[370   4]
[ 14 323]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.99      0.98       374
         MDD       0.99      0.96      0.97       337

    accuracy                           0.97       711
   macro avg       0.98      0.97      0.97       711
weighted avg       0.98      0.97      0.97       711

========================	test end	========================

========================	2023-04-17 10:47:50	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-17 10:49:07	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-17 10:49:36	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2401	 train accuracy: 98.826	 validation loss: 0.2558	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.2386	 train accuracy: 99.202	 validation loss: 0.2504	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 98.684829
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1365 	 test accuracy:	 96.624 
confusion matrix: 
[370   4]
[ 20 317]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.99      0.97       374
         MDD       0.99      0.94      0.96       337

    accuracy                           0.97       711
   macro avg       0.97      0.96      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-17 10:52:04	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2234	 train accuracy: 99.812	 validation loss: 0.2493	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2231	 train accuracy: 99.953	 validation loss: 0.2493	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 99.530296
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0987 	 test accuracy:	 97.609 
confusion matrix: 
[363  11]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.97      0.98       374
         MDD       0.97      0.98      0.97       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-17 10:56:52	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================
test: 			test loss: 	0.1141 	 test accuracy:	 97.046 
confusion matrix: 
[367   7]
[ 14 323]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.98      0.97       374
         MDD       0.98      0.96      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-17 11:04:24	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================
test: 			test loss: 	0.0987 	 test accuracy:	 97.609 
confusion matrix: 
[363  11]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.97      0.98       374
         MDD       0.97      0.98      0.97       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-17 15:54:30	========================
model name: 	MultiTIM_train_ADD_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: CASIA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-17 15:55:02	========================
model name: 	MultiTIM_train_ADD_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: CASIA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.4246	 train accuracy: 100.000	 validation loss: 0.4365	 validation accuracy: 100.000 
train(max_min): 	train loss: 0.4245	 train accuracy: 100.000	 validation loss: 0.4348	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0575 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-04-17 16:02:36	========================
model name: 	MultiTIM_train_ADD_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re2_lr0002_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: CASIA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.4493	 train accuracy: 99.560	 validation loss: 0.4812	 validation accuracy: 99.931 
train(max_min): 	train loss: 0.4493	 train accuracy: 99.676	 validation loss: 0.4630	 validation accuracy: 99.931 
best val accuracy: 99.930556 	 corresponding train accuracy: 99.675926
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0709 	 test accuracy:	 99.861 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 240   0   0   2]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      0.99      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       0.99      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-04-17 16:13:19	========================
model name: 	MultiTIM_train_ADD_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: CASIA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.4252	 train accuracy: 100.000	 validation loss: 0.5104	 validation accuracy: 95.625 
train(max_min): 	train loss: 0.4252	 train accuracy: 100.000	 validation loss: 0.4446	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1797 	 test accuracy:	 95.486 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 177   0   0  65]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      0.73      0.84       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       0.78      1.00      0.88       237

    accuracy                           0.95      1440
   macro avg       0.96      0.96      0.95      1440
weighted avg       0.96      0.95      0.95      1440

========================	test end	========================

========================	2023-04-17 16:23:06	========================
model name: 	MultiTIM_train_ADD_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: CASIA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.4273	 train accuracy: 100.000	 validation loss: 0.4332	 validation accuracy: 100.000 
train(max_min): 	train loss: 0.4271	 train accuracy: 100.000	 validation loss: 0.4322	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0628 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-04-17 16:36:31	========================
model name: 	MultiTIM_train_ADD_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re2_lr0001_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re2_lr0001_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0001	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: CASIA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.4975	 train accuracy: 97.894	 validation loss: 0.4839	 validation accuracy: 99.861 
train(max_min): 	train loss: 0.4974	 train accuracy: 98.194	 validation loss: 0.4837	 validation accuracy: 99.861 
best val accuracy: 99.861111 	 corresponding train accuracy: 98.194444
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0730 	 test accuracy:	 99.722 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 239   0   0   3]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   1   0   0 236]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      0.99      0.99       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       0.99      1.00      0.99       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-04-17 16:46:49	========================
model name: 	MultiTIM_train_ADD_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re2_lr0003_pretrainTrue_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re2_lr0003_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: CASIA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.4409	 train accuracy: 99.884	 validation loss: 0.4650	 validation accuracy: 99.861 
train(max_min): 	train loss: 0.4409	 train accuracy: 99.884	 validation loss: 0.4633	 validation accuracy: 99.931 
best val accuracy: 99.930556 	 corresponding train accuracy: 99.837963
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0680 	 test accuracy:	 99.792 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 239   0   0   3]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      0.99      0.99       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       0.99      1.00      0.99       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-04-17 21:02:01	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-17 21:05:09	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-17 21:08:32	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2106	 train accuracy: 100.000	 validation loss: 0.3109	 validation accuracy: 94.076 
train(max_min): 	train loss: 0.2103	 train accuracy: 100.000	 validation loss: 0.3095	 validation accuracy: 94.499 
best val accuracy: 94.499295 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2485 	 test accuracy:	 92.827 
confusion matrix: 
[359  15]
[ 36 301]

classification report: 
              precision    recall  f1-score   support

          HC       0.91      0.96      0.93       374
         MDD       0.95      0.89      0.92       337

    accuracy                           0.93       711
   macro avg       0.93      0.93      0.93       711
weighted avg       0.93      0.93      0.93       711

========================	test end	========================

========================	2023-04-17 21:13:15	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2239	 train accuracy: 99.906	 validation loss: 0.3223	 validation accuracy: 93.371 
train(max_min): 	train loss: 0.2222	 train accuracy: 100.000	 validation loss: 0.3200	 validation accuracy: 94.076 
best val accuracy: 94.076164 	 corresponding train accuracy: 99.859089
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.3075 	 test accuracy:	 93.530 
confusion matrix: 
[355  19]
[ 27 310]

classification report: 
              precision    recall  f1-score   support

          HC       0.93      0.95      0.94       374
         MDD       0.94      0.92      0.93       337

    accuracy                           0.94       711
   macro avg       0.94      0.93      0.94       711
weighted avg       0.94      0.94      0.94       711

========================	test end	========================

========================	2023-04-17 21:18:20	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2018	 train accuracy: 100.000	 validation loss: 0.2741	 validation accuracy: 96.474 
train(max_min): 	train loss: 0.2018	 train accuracy: 100.000	 validation loss: 0.2741	 validation accuracy: 96.474 
best val accuracy: 96.473907 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2513 	 test accuracy:	 97.046 
confusion matrix: 
[363  11]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.97      0.97       374
         MDD       0.97      0.97      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-17 21:39:22	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2018	 train accuracy: 100.000	 validation loss: 0.2759	 validation accuracy: 95.910 
train(max_min): 	train loss: 0.2018	 train accuracy: 100.000	 validation loss: 0.2732	 validation accuracy: 96.756 
best val accuracy: 96.755994 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1742 	 test accuracy:	 97.046 
confusion matrix: 
[365   9]
[ 12 325]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.98      0.97       374
         MDD       0.97      0.96      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-17 21:41:09	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2011	 train accuracy: 100.000	 validation loss: 0.3088	 validation accuracy: 95.063 
train(max_min): 	train loss: 0.2011	 train accuracy: 100.000	 validation loss: 0.3045	 validation accuracy: 95.205 
best val accuracy: 95.204513 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2067 	 test accuracy:	 93.390 
confusion matrix: 
[353  21]
[ 26 311]

classification report: 
              precision    recall  f1-score   support

          HC       0.93      0.94      0.94       374
         MDD       0.94      0.92      0.93       337

    accuracy                           0.93       711
   macro avg       0.93      0.93      0.93       711
weighted avg       0.93      0.93      0.93       711

========================	test end	========================

========================	2023-04-17 21:46:47	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2032	 train accuracy: 100.000	 validation loss: 0.3063	 validation accuracy: 94.076 
train(max_min): 	train loss: 0.2032	 train accuracy: 100.000	 validation loss: 0.3024	 validation accuracy: 94.781 
best val accuracy: 94.781382 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2498 	 test accuracy:	 92.827 
confusion matrix: 
[354  20]
[ 31 306]

classification report: 
              precision    recall  f1-score   support

          HC       0.92      0.95      0.93       374
         MDD       0.94      0.91      0.92       337

    accuracy                           0.93       711
   macro avg       0.93      0.93      0.93       711
weighted avg       0.93      0.93      0.93       711

========================	test end	========================

========================	2023-04-17 21:56:40	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-17 21:57:37	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.5248	 validation accuracy: 76.305 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.4596	 validation accuracy: 82.511 
best val accuracy: 82.510578 	 corresponding train accuracy: 95.866604
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.4983 	 test accuracy:	 74.121 
confusion matrix: 
[289  85]
[ 99 238]

classification report: 
              precision    recall  f1-score   support

          HC       0.74      0.77      0.76       374
         MDD       0.74      0.71      0.72       337

    accuracy                           0.74       711
   macro avg       0.74      0.74      0.74       711
weighted avg       0.74      0.74      0.74       711

========================	test end	========================

========================	2023-04-17 22:00:07	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.5428	 validation accuracy: 74.753 
train(max_min): 	train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.4805	 validation accuracy: 79.408 
best val accuracy: 79.407616 	 corresponding train accuracy: 94.222640
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.5566 	 test accuracy:	 72.996 
confusion matrix: 
[292  82]
[110 227]

classification report: 
              precision    recall  f1-score   support

          HC       0.73      0.78      0.75       374
         MDD       0.73      0.67      0.70       337

    accuracy                           0.73       711
   macro avg       0.73      0.73      0.73       711
weighted avg       0.73      0.73      0.73       711

========================	test end	========================

========================	2023-04-17 22:04:13	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2002	 train accuracy: 100.000	 validation loss: 0.5170	 validation accuracy: 76.446 
train(max_min): 	train loss: 0.2002	 train accuracy: 100.000	 validation loss: 0.4731	 validation accuracy: 80.113 
best val accuracy: 80.112835 	 corresponding train accuracy: 99.953030
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.4913 	 test accuracy:	 76.231 
confusion matrix: 
[311  63]
[106 231]

classification report: 
              precision    recall  f1-score   support

          HC       0.75      0.83      0.79       374
         MDD       0.79      0.69      0.73       337

    accuracy                           0.76       711
   macro avg       0.77      0.76      0.76       711
weighted avg       0.76      0.76      0.76       711

========================	test end	========================

========================	2023-04-17 22:06:52	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2003	 train accuracy: 100.000	 validation loss: 0.5375	 validation accuracy: 76.869 
train(max_min): 	train loss: 0.2002	 train accuracy: 100.000	 validation loss: 0.4883	 validation accuracy: 79.690 
best val accuracy: 79.689704 	 corresponding train accuracy: 98.919681
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.5398 	 test accuracy:	 75.668 
confusion matrix: 
[307  67]
[106 231]

classification report: 
              precision    recall  f1-score   support

          HC       0.74      0.82      0.78       374
         MDD       0.78      0.69      0.73       337

    accuracy                           0.76       711
   macro avg       0.76      0.75      0.75       711
weighted avg       0.76      0.76      0.76       711

========================	test end	========================

========================	2023-04-17 22:09:50	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2023	 train accuracy: 100.000	 validation loss: 0.3132	 validation accuracy: 93.512 
train(max_min): 	train loss: 0.2023	 train accuracy: 100.000	 validation loss: 0.3104	 validation accuracy: 93.935 
best val accuracy: 93.935120 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2332 	 test accuracy:	 92.968 
confusion matrix: 
[354  20]
[ 30 307]

classification report: 
              precision    recall  f1-score   support

          HC       0.92      0.95      0.93       374
         MDD       0.94      0.91      0.92       337

    accuracy                           0.93       711
   macro avg       0.93      0.93      0.93       711
weighted avg       0.93      0.93      0.93       711

========================	test end	========================

========================	2023-04-17 22:14:42	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2018	 train accuracy: 100.000	 validation loss: 0.2971	 validation accuracy: 94.922 
train(max_min): 	train loss: 0.2018	 train accuracy: 100.000	 validation loss: 0.2958	 validation accuracy: 95.063 
best val accuracy: 95.063470 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2015 	 test accuracy:	 94.233 
confusion matrix: 
[358  16]
[ 25 312]

classification report: 
              precision    recall  f1-score   support

          HC       0.93      0.96      0.95       374
         MDD       0.95      0.93      0.94       337

    accuracy                           0.94       711
   macro avg       0.94      0.94      0.94       711
weighted avg       0.94      0.94      0.94       711

========================	test end	========================

========================	2023-04-17 22:16:17	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2047	 train accuracy: 100.000	 validation loss: 0.2940	 validation accuracy: 96.051 
train(max_min): 	train loss: 0.2026	 train accuracy: 100.000	 validation loss: 0.2903	 validation accuracy: 96.192 
best val accuracy: 96.191819 	 corresponding train accuracy: 99.906059
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1936 	 test accuracy:	 94.374 
confusion matrix: 
[354  20]
[ 20 317]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.95      0.95       374
         MDD       0.94      0.94      0.94       337

    accuracy                           0.94       711
   macro avg       0.94      0.94      0.94       711
weighted avg       0.94      0.94      0.94       711

========================	test end	========================

========================	2023-04-17 22:19:05	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2021	 train accuracy: 100.000	 validation loss: 0.3261	 validation accuracy: 92.102 
train(max_min): 	train loss: 0.2018	 train accuracy: 100.000	 validation loss: 0.3186	 validation accuracy: 93.653 
best val accuracy: 93.653032 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2294 	 test accuracy:	 91.983 
confusion matrix: 
[360  14]
[ 43 294]

classification report: 
              precision    recall  f1-score   support

          HC       0.89      0.96      0.93       374
         MDD       0.95      0.87      0.91       337

    accuracy                           0.92       711
   macro avg       0.92      0.92      0.92       711
weighted avg       0.92      0.92      0.92       711

========================	test end	========================

========================	2023-04-17 22:40:01	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2036	 train accuracy: 100.000	 validation loss: 0.3247	 validation accuracy: 92.525 
train(max_min): 	train loss: 0.2036	 train accuracy: 100.000	 validation loss: 0.3172	 validation accuracy: 94.358 
best val accuracy: 94.358251 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2313 	 test accuracy:	 93.249 
confusion matrix: 
[363  11]
[ 37 300]

classification report: 
              precision    recall  f1-score   support

          HC       0.91      0.97      0.94       374
         MDD       0.96      0.89      0.93       337

    accuracy                           0.93       711
   macro avg       0.94      0.93      0.93       711
weighted avg       0.93      0.93      0.93       711

========================	test end	========================

========================	2023-04-17 22:42:29	========================
model name: 	LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: LSTM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: LSTM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2060	 train accuracy: 100.000	 validation loss: 0.3055	 validation accuracy: 93.935 
train(max_min): 	train loss: 0.2032	 train accuracy: 100.000	 validation loss: 0.2987	 validation accuracy: 95.063 
best val accuracy: 95.063470 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.2432 	 test accuracy:	 92.405 
confusion matrix: 
[359  15]
[ 39 298]

classification report: 
              precision    recall  f1-score   support

          HC       0.90      0.96      0.93       374
         MDD       0.95      0.88      0.92       337

    accuracy                           0.92       711
   macro avg       0.93      0.92      0.92       711
weighted avg       0.93      0.92      0.92       711

========================	test end	========================

========================	2023-04-17 22:49:54	========================
model name: 	TCN_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TCN_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2240	 train accuracy: 99.202	 validation loss: 0.2455	 validation accuracy: 97.179 
train(max_min): 	train loss: 0.2240	 train accuracy: 99.202	 validation loss: 0.2451	 validation accuracy: 97.602 
best val accuracy: 97.602257 	 corresponding train accuracy: 98.778769
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1085 	 test accuracy:	 97.328 
confusion matrix: 
[365   9]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.98      0.97       374
         MDD       0.97      0.97      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-17 22:56:53	========================
model name: 	TCN_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TCN_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2274	 train accuracy: 98.826	 validation loss: 0.2388	 validation accuracy: 98.166 
train(max_min): 	train loss: 0.2270	 train accuracy: 98.920	 validation loss: 0.2378	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 98.919681
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1042 	 test accuracy:	 97.609 
confusion matrix: 
[367   7]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.98      0.98       374
         MDD       0.98      0.97      0.97       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-17 23:01:28	========================
model name: 	Transformer_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1994	 train accuracy: 100.000	 validation loss: 0.2272	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.1994	 train accuracy: 100.000	 validation loss: 0.2253	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1226 	 test accuracy:	 97.890 
confusion matrix: 
[369   5]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.98      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-17 23:13:35	========================
model name: 	Transformer_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: Transformer_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1992	 train accuracy: 100.000	 validation loss: 0.2316	 validation accuracy: 97.320 
train(max_min): 	train loss: 0.1992	 train accuracy: 100.000	 validation loss: 0.2311	 validation accuracy: 98.166 
best val accuracy: 98.166432 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1136 	 test accuracy:	 97.609 
confusion matrix: 
[367   7]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.98      0.98       374
         MDD       0.98      0.97      0.97       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-17 23:28:43	========================
model name: 	AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2149	 train accuracy: 100.000	 validation loss: 0.2540	 validation accuracy: 97.602 
train(max_min): 	train loss: 0.2147	 train accuracy: 100.000	 validation loss: 0.2539	 validation accuracy: 97.743 
best val accuracy: 97.743300 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1214 	 test accuracy:	 97.468 
confusion matrix: 
[368   6]
[ 12 325]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.98      0.98       374
         MDD       0.98      0.96      0.97       337

    accuracy                           0.97       711
   macro avg       0.98      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-17 23:35:34	========================
model name: 	AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2160	 train accuracy: 100.000	 validation loss: 0.2501	 validation accuracy: 97.743 
train(max_min): 	train loss: 0.2156	 train accuracy: 100.000	 validation loss: 0.2496	 validation accuracy: 97.884 
best val accuracy: 97.884344 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1224 	 test accuracy:	 97.187 
confusion matrix: 
[366   8]
[ 12 325]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.98      0.97       374
         MDD       0.98      0.96      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-17 23:41:36	========================
model name: 	AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2084	 train accuracy: 100.000	 validation loss: 0.2419	 validation accuracy: 97.884 
train(max_min): 	train loss: 0.2082	 train accuracy: 100.000	 validation loss: 0.2419	 validation accuracy: 98.166 
best val accuracy: 98.166432 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1104 	 test accuracy:	 98.172 
confusion matrix: 
[369   5]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-17 23:50:07	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2498	 train accuracy: 98.920	 validation loss: 0.2629	 validation accuracy: 98.307 
train(max_min): 	train loss: 0.2496	 train accuracy: 98.920	 validation loss: 0.2628	 validation accuracy: 98.307 
best val accuracy: 98.307475 	 corresponding train accuracy: 98.919681
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1257 	 test accuracy:	 97.609 
confusion matrix: 
[366   8]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.97      0.97       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-17 23:54:39	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2290	 train accuracy: 99.765	 validation loss: 0.2480	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2290	 train accuracy: 99.859	 validation loss: 0.2479	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 99.765148
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1044 	 test accuracy:	 98.312 
confusion matrix: 
[370   4]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-17 23:57:29	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2384	 train accuracy: 99.436	 validation loss: 0.2515	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2379	 train accuracy: 99.624	 validation loss: 0.2513	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 99.624237
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1120 	 test accuracy:	 98.312 
confusion matrix: 
[369   5]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 00:00:50	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2301	 train accuracy: 99.718	 validation loss: 0.2510	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2292	 train accuracy: 99.812	 validation loss: 0.2510	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 99.812118
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1249 	 test accuracy:	 98.453 
confusion matrix: 
[370   4]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 00:03:42	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-18 00:04:32	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-18 00:09:40	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-18 00:11:34	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2040	 train accuracy: 100.000	 validation loss: 0.2310	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2038	 train accuracy: 100.000	 validation loss: 0.2299	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1040 	 test accuracy:	 97.046 
confusion matrix: 
[354  20]
[  1 336]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.95      0.97       374
         MDD       0.94      1.00      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-18 00:15:02	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2080	 train accuracy: 100.000	 validation loss: 0.2206	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.2079	 train accuracy: 100.000	 validation loss: 0.2206	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0712 	 test accuracy:	 99.156 
confusion matrix: 
[373   1]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 00:20:30	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2083	 train accuracy: 100.000	 validation loss: 0.2261	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2080	 train accuracy: 100.000	 validation loss: 0.2260	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0847 	 test accuracy:	 98.453 
confusion matrix: 
[371   3]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 00:23:04	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2115	 train accuracy: 100.000	 validation loss: 0.2251	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2111	 train accuracy: 100.000	 validation loss: 0.2249	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0721 	 test accuracy:	 98.875 
confusion matrix: 
[371   3]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 09:20:08	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2059	 train accuracy: 100.000	 validation loss: 0.2164	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2058	 train accuracy: 100.000	 validation loss: 0.2162	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0889 	 test accuracy:	 99.156 
confusion matrix: 
[373   1]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 09:23:12	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2072	 train accuracy: 100.000	 validation loss: 0.2209	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.2072	 train accuracy: 100.000	 validation loss: 0.2206	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0900 	 test accuracy:	 98.594 
confusion matrix: 
[373   1]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.97      0.98       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 09:26:02	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2168	 train accuracy: 99.906	 validation loss: 0.2337	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2167	 train accuracy: 99.953	 validation loss: 0.2332	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 99.906059
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0974 	 test accuracy:	 98.594 
confusion matrix: 
[373   1]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.97      0.98       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 09:28:39	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-18 09:29:44	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2102	 train accuracy: 100.000	 validation loss: 0.2255	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2102	 train accuracy: 100.000	 validation loss: 0.2253	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1069 	 test accuracy:	 98.172 
confusion matrix: 
[370   4]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 09:32:00	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2172	 train accuracy: 100.000	 validation loss: 0.2349	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2169	 train accuracy: 100.000	 validation loss: 0.2346	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 99.953030
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0773 	 test accuracy:	 99.015 
confusion matrix: 
[372   2]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 09:34:28	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2217	 train accuracy: 99.953	 validation loss: 0.2496	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.2213	 train accuracy: 99.953	 validation loss: 0.2493	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 99.906059
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0983 	 test accuracy:	 99.156 
confusion matrix: 
[372   2]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 09:37:52	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2151	 train accuracy: 100.000	 validation loss: 0.2454	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.2144	 train accuracy: 100.000	 validation loss: 0.2409	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0792 	 test accuracy:	 98.312 
confusion matrix: 
[368   6]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 09:41:07	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2290	 train accuracy: 99.859	 validation loss: 0.2481	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2290	 train accuracy: 99.859	 validation loss: 0.2479	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 99.624237
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1368 	 test accuracy:	 98.312 
confusion matrix: 
[369   5]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 09:45:15	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2274	 train accuracy: 99.859	 validation loss: 0.2499	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.2272	 train accuracy: 99.953	 validation loss: 0.2499	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 99.906059
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1101 	 test accuracy:	 98.312 
confusion matrix: 
[370   4]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 09:52:49	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2343	 train accuracy: 99.718	 validation loss: 0.2487	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2341	 train accuracy: 99.765	 validation loss: 0.2487	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 99.765148
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1409 	 test accuracy:	 98.031 
confusion matrix: 
[367   7]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 09:56:37	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2341	 train accuracy: 99.577	 validation loss: 0.2471	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2341	 train accuracy: 99.671	 validation loss: 0.2471	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 99.671207
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1311 	 test accuracy:	 98.453 
confusion matrix: 
[372   2]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.99      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 09:59:02	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2643	 train accuracy: 98.215	 validation loss: 0.2647	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.2643	 train accuracy: 98.403	 validation loss: 0.2647	 validation accuracy: 98.449 
best val accuracy: 98.448519 	 corresponding train accuracy: 98.403006
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1715 	 test accuracy:	 95.921 
confusion matrix: 
[364  10]
[ 19 318]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.97      0.96       374
         MDD       0.97      0.94      0.96       337

    accuracy                           0.96       711
   macro avg       0.96      0.96      0.96       711
weighted avg       0.96      0.96      0.96       711

========================	test end	========================

========================	2023-04-18 10:04:05	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2420	 train accuracy: 99.342	 validation loss: 0.2651	 validation accuracy: 97.602 
train(max_min): 	train loss: 0.2420	 train accuracy: 99.342	 validation loss: 0.2648	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 98.778769
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1455 	 test accuracy:	 97.609 
confusion matrix: 
[370   4]
[ 13 324]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.99      0.96      0.97       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 10:05:28	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2427	 train accuracy: 99.577	 validation loss: 0.2568	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.2422	 train accuracy: 99.577	 validation loss: 0.2567	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 99.577266
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1509 	 test accuracy:	 98.594 
confusion matrix: 
[368   6]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       374
         MDD       0.98      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 10:08:13	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2139	 train accuracy: 100.000	 validation loss: 0.2342	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.2138	 train accuracy: 100.000	 validation loss: 0.2339	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0914 	 test accuracy:	 98.734 
confusion matrix: 
[373   1]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 10:11:29	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2158	 train accuracy: 100.000	 validation loss: 0.2310	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2158	 train accuracy: 100.000	 validation loss: 0.2309	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0957 	 test accuracy:	 98.453 
confusion matrix: 
[370   4]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 10:14:34	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2103	 train accuracy: 100.000	 validation loss: 0.2302	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2103	 train accuracy: 100.000	 validation loss: 0.2299	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 99.812118
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0948 	 test accuracy:	 98.734 
confusion matrix: 
[374   0]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.97      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 10:18:46	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2104	 train accuracy: 100.000	 validation loss: 0.2230	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2104	 train accuracy: 100.000	 validation loss: 0.2230	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0859 	 test accuracy:	 99.156 
confusion matrix: 
[374   0]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 10:22:11	========================
model name: 	TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2143	 train accuracy: 99.953	 validation loss: 0.2279	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.2142	 train accuracy: 100.000	 validation loss: 0.2277	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0902 	 test accuracy:	 99.156 
confusion matrix: 
[374   0]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 10:25:44	========================
model name: 	AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2017	 train accuracy: 100.000	 validation loss: 0.2219	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2014	 train accuracy: 100.000	 validation loss: 0.2211	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0964 	 test accuracy:	 98.031 
confusion matrix: 
[369   5]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.98      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 10:30:27	========================
model name: 	AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2019	 train accuracy: 100.000	 validation loss: 0.2224	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.2017	 train accuracy: 100.000	 validation loss: 0.2224	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0971 	 test accuracy:	 97.750 
confusion matrix: 
[369   5]
[ 11 326]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.98      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 10:34:50	========================
model name: 	AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2084	 train accuracy: 100.000	 validation loss: 0.2570	 validation accuracy: 97.884 
train(max_min): 	train loss: 0.2082	 train accuracy: 100.000	 validation loss: 0.2570	 validation accuracy: 98.025 
best val accuracy: 98.025388 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1304 	 test accuracy:	 97.046 
confusion matrix: 
[367   7]
[ 14 323]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.98      0.97       374
         MDD       0.98      0.96      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-18 10:41:28	========================
model name: 	AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	2023-04-18 10:44:35	========================
model name: 	AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2094	 train accuracy: 100.000	 validation loss: 0.2480	 validation accuracy: 98.166 
train(max_min): 	train loss: 0.2091	 train accuracy: 100.000	 validation loss: 0.2472	 validation accuracy: 98.449 
best val accuracy: 98.448519 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1452 	 test accuracy:	 97.187 
confusion matrix: 
[370   4]
[ 16 321]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.99      0.97       374
         MDD       0.99      0.95      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-18 10:49:14	========================
model name: 	AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: AT_TIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: AT_TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: SE	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2181	 train accuracy: 100.000	 validation loss: 0.2578	 validation accuracy: 98.307 
train(max_min): 	train loss: 0.2176	 train accuracy: 100.000	 validation loss: 0.2554	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1612 	 test accuracy:	 97.890 
confusion matrix: 
[367   7]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 10:52:50	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	smooth: True	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 10:56:37	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2130	 train accuracy: 99.953	 validation loss: 0.2359	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.2127	 train accuracy: 100.000	 validation loss: 0.2354	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0901 	 test accuracy:	 99.015 
confusion matrix: 
[373   1]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 11:04:08	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2085	 train accuracy: 100.000	 validation loss: 0.2492	 validation accuracy: 97.884 
train(max_min): 	train loss: 0.2078	 train accuracy: 100.000	 validation loss: 0.2413	 validation accuracy: 98.307 
best val accuracy: 98.307475 	 corresponding train accuracy: 99.953030
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0782 	 test accuracy:	 98.875 
confusion matrix: 
[367   7]
[  1 336]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.98      0.99       374
         MDD       0.98      1.00      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 11:35:00	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2163	 train accuracy: 100.000	 validation loss: 0.2383	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2163	 train accuracy: 100.000	 validation loss: 0.2381	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0875 	 test accuracy:	 97.890 
confusion matrix: 
[367   7]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 11:39:47	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2048	 train accuracy: 100.000	 validation loss: 0.2213	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2048	 train accuracy: 100.000	 validation loss: 0.2210	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0786 	 test accuracy:	 99.015 
confusion matrix: 
[372   2]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 13:06:26	========================
model name: 	MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_ADD_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: ADD_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1992	 train accuracy: 100.000	 validation loss: 0.2201	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2200	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0894 	 test accuracy:	 98.031 
confusion matrix: 
[372   2]
[ 12 325]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.99      0.96      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 13:21:30	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 13:22:14	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 13:34:33	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2122	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2047	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 99.953030
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0828 	 test accuracy:	 98.594 
confusion matrix: 
[370   4]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 13:52:06	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 13:53:48	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 13:54:41	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 13:55:10	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1997	 train accuracy: 99.953	 validation loss: 0.2260	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.1997	 train accuracy: 99.953	 validation loss: 0.2147	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 99.953030
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.1043 	 test accuracy:	 97.890 
confusion matrix: 
[367   7]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 14:03:06	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2178	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2101	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 99.906059
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0929 	 test accuracy:	 98.031 
confusion matrix: 
[368   6]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 14:15:14	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 14:17:29	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2135	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2069	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 99.953030
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0871 	 test accuracy:	 98.312 
confusion matrix: 
[367   7]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.98       374
         MDD       0.98      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 14:27:50	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 14:29:10	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2216	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2122	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0850 	 test accuracy:	 98.312 
confusion matrix: 
[369   5]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 14:43:48	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2197	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2098	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0813 	 test accuracy:	 98.734 
confusion matrix: 
[372   2]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 14:54:33	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 15:04:11	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1993	 train accuracy: 99.953	 validation loss: 0.2094	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1993	 train accuracy: 99.953	 validation loss: 0.2030	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 99.953030
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0770 	 test accuracy:	 98.875 
confusion matrix: 
[371   3]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 15:18:21	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2163	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2110	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0901 	 test accuracy:	 98.172 
confusion matrix: 
[370   4]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 15:32:38	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2061	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2029	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0926 	 test accuracy:	 98.453 
confusion matrix: 
[369   5]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 15:41:02	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================
test: 			test loss: 	0.0866 	 test accuracy:	 98.312 
confusion matrix: 
[368   6]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 15:43:39	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 36	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2162	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2045	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0913 	 test accuracy:	 98.453 
confusion matrix: 
[385   2]
[  9 315]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       387
         MDD       0.99      0.97      0.98       324

    accuracy                           0.98       711
   macro avg       0.99      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 15:54:16	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re3_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re3_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.3	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2234	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2163	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0963 	 test accuracy:	 98.312 
confusion matrix: 
[371   3]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 16:06:26	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2109	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2036	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0829 	 test accuracy:	 98.594 
confusion matrix: 
[372   2]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 16:15:53	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================
test: 			test loss: 	0.0772 	 test accuracy:	 98.734 
confusion matrix: 
[371   3]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 16:17:03	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop2_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop2_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.2	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2223	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2182	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 99.859089
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0823 	 test accuracy:	 98.594 
confusion matrix: 
[368   6]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       374
         MDD       0.98      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 16:26:24	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0003_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0003	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 3	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2148	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2115	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0862 	 test accuracy:	 98.312 
confusion matrix: 
[370   4]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 16:37:13	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2222	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2137	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0766 	 test accuracy:	 98.734 
confusion matrix: 
[370   4]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 16:46:32	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 16:56:20	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 16:59:30	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 17:00:06	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 17:01:13	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 17:07:20	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 17:32:33	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================
test: 			test loss: 	0.0767 	 test accuracy:	 98.875 
confusion matrix: 
[373   1]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 17:32:55	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================
test: 			test loss: 	0.0786 	 test accuracy:	 98.594 
confusion matrix: 
[373   1]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.97      0.98       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 17:34:24	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 2	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 17:37:49	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 2	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 17:38:46	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 2	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 17:40:12	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 2	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.5445	 train accuracy: 75.857	 validation loss: 0.4825	 validation accuracy: 82.087 
train(max_min): 	train loss: 0.5445	 train accuracy: 75.857	 validation loss: 0.4825	 validation accuracy: 82.087 
best val accuracy: 82.087447 	 corresponding train accuracy: 75.857210
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0786 	 test accuracy:	 98.594 
confusion matrix: 
[373   1]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.97      0.98       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 17:42:28	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2202	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2149	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0803 	 test accuracy:	 98.875 
confusion matrix: 
[372   2]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 18:25:51	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 18:28:48	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2065	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2030	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0667 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 18:37:20	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2155	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2073	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0735 	 test accuracy:	 98.875 
confusion matrix: 
[371   3]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 18:56:34	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 6	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2182	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2157	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0826 	 test accuracy:	 98.594 
confusion matrix: 
[372   2]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 18:59:46	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2069	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2053	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0673 	 test accuracy:	 99.156 
confusion matrix: 
[372   2]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 19:07:21	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2126	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2097	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0693 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 19:12:32	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2063	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2045	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0708 	 test accuracy:	 99.015 
confusion matrix: 
[373   1]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 19:15:25	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2070	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2042	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0692 	 test accuracy:	 99.015 
confusion matrix: 
[372   2]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 19:22:23	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 19:24:15	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 19:24:44	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 19:30:40	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================
test: 			test loss: 	0.0589 	 test accuracy:	 99.437 
confusion matrix: 
[373   1]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 19:31:36	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================
test: 			test loss: 	0.0615 	 test accuracy:	 99.156 
confusion matrix: 
[373   1]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 19:34:23	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2149	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2103	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================
test: 			test loss: 	0.0792 	 test accuracy:	 98.594 
confusion matrix: 
[371   3]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 19:39:59	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 19:45:08	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================
test: 			test loss: 	0.0652 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 19:45:27	========================
model name: 	MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	mode: train	model_name: MultiTIM_train_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================
test: 			test loss: 	0.0651 	 test accuracy:	 99.015 
confusion matrix: 
[370   4]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================



========================	2023-04-18 20:17:38	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0651 	 test accuracy:	 99.015 
confusion matrix: 
[370   4]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0652 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 20:25:34	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0651 	 test accuracy:	 99.015 
confusion matrix: 
[370   4]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0652 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 20:35:55	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0651 	 test accuracy:	 99.015 
confusion matrix: 
[370   4]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0652 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 20:37:11	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0651 	 test accuracy:	 99.015 
confusion matrix: 
[370   4]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0652 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 20:39:24	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 2	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 20:40:48	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 2	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 20:41:29	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 2	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.4499	 train accuracy: 83.185	 validation loss: 0.4024	 validation accuracy: 87.024 
train(max_min): 	train loss: 0.4499	 train accuracy: 83.185	 validation loss: 0.4024	 validation accuracy: 87.024 
best val accuracy: 87.023977 	 corresponding train accuracy: 83.184594
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.3414 	 test accuracy:	 84.529 
confusion matrix: 
[327  47]
[ 63 274]

classification report: 
              precision    recall  f1-score   support

          HC       0.84      0.87      0.86       374
         MDD       0.85      0.81      0.83       337

    accuracy                           0.85       711
   macro avg       0.85      0.84      0.84       711
weighted avg       0.85      0.85      0.85       711

test: 			test loss: 	0.3414 	 test accuracy:	 84.529 
confusion matrix: 
[327  47]
[ 63 274]

classification report: 
              precision    recall  f1-score   support

          HC       0.84      0.87      0.86       374
         MDD       0.85      0.81      0.83       337

    accuracy                           0.85       711
   macro avg       0.85      0.84      0.84       711
weighted avg       0.85      0.85      0.85       711

========================	test end	========================

========================	2023-04-18 20:42:36	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch2_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 2	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.4349	 train accuracy: 85.439	 validation loss: 0.3734	 validation accuracy: 89.140 
train(max_min): 	train loss: 0.4349	 train accuracy: 85.439	 validation loss: 0.3734	 validation accuracy: 89.140 
best val accuracy: 89.139633 	 corresponding train accuracy: 85.439173
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.3187 	 test accuracy:	 86.779 
confusion matrix: 
[345  29]
[ 65 272]

classification report: 
              precision    recall  f1-score   support

          HC       0.84      0.92      0.88       374
         MDD       0.90      0.81      0.85       337

    accuracy                           0.87       711
   macro avg       0.87      0.86      0.87       711
weighted avg       0.87      0.87      0.87       711

test: 			test loss: 	0.3187 	 test accuracy:	 86.779 
confusion matrix: 
[345  29]
[ 65 272]

classification report: 
              precision    recall  f1-score   support

          HC       0.84      0.92      0.88       374
         MDD       0.90      0.81      0.85       337

    accuracy                           0.87       711
   macro avg       0.87      0.86      0.87       711
weighted avg       0.87      0.87      0.87       711

========================	test end	========================

========================	2023-04-18 20:53:49	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2090	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2069	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0764 	 test accuracy:	 98.594 
confusion matrix: 
[370   4]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0764 	 test accuracy:	 98.875 
confusion matrix: 
[368   6]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       374
         MDD       0.98      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 20:59:23	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2059	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2037	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0815 	 test accuracy:	 98.594 
confusion matrix: 
[371   3]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0736 	 test accuracy:	 98.875 
confusion matrix: 
[371   3]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 21:04:36	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2054	 validation accuracy: 99.859 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2036	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0705 	 test accuracy:	 99.297 
confusion matrix: 
[373   1]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0689 	 test accuracy:	 99.297 
confusion matrix: 
[373   1]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 21:10:38	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2063	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2048	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0793 	 test accuracy:	 98.875 
confusion matrix: 
[371   3]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0802 	 test accuracy:	 99.015 
confusion matrix: 
[372   2]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 21:15:49	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2066	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2045	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0709 	 test accuracy:	 99.297 
confusion matrix: 
[373   1]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0758 	 test accuracy:	 99.156 
confusion matrix: 
[369   5]
[  1 336]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       374
         MDD       0.99      1.00      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 21:22:43	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2050	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2041	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0677 	 test accuracy:	 99.015 
confusion matrix: 
[373   1]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0673 	 test accuracy:	 99.437 
confusion matrix: 
[373   1]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 21:27:15	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2067	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2063	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0700 	 test accuracy:	 99.156 
confusion matrix: 
[372   2]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0685 	 test accuracy:	 99.297 
confusion matrix: 
[372   2]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 21:32:34	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 21:54:29	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2025	 validation accuracy: 99.718 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2014	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0730 	 test accuracy:	 98.875 
confusion matrix: 
[371   3]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0786 	 test accuracy:	 98.875 
confusion matrix: 
[370   4]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 21:58:51	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2085	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2060	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0754 	 test accuracy:	 98.453 
confusion matrix: 
[369   5]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0817 	 test accuracy:	 98.453 
confusion matrix: 
[366   8]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       374
         MDD       0.98      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 22:05:11	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2068	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2066	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0676 	 test accuracy:	 99.156 
confusion matrix: 
[373   1]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0726 	 test accuracy:	 99.156 
confusion matrix: 
[373   1]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 22:11:18	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 22:23:15	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2139	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2067	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0708 	 test accuracy:	 99.015 
confusion matrix: 
[372   2]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0715 	 test accuracy:	 99.015 
confusion matrix: 
[372   2]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 22:28:28	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2188	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2098	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0618 	 test accuracy:	 99.156 
confusion matrix: 
[372   2]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0579 	 test accuracy:	 99.578 
confusion matrix: 
[372   2]
[  1 336]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      1.00       374
         MDD       0.99      1.00      1.00       337

    accuracy                           1.00       711
   macro avg       1.00      1.00      1.00       711
weighted avg       1.00      1.00      1.00       711

========================	test end	========================

========================	2023-04-18 22:33:41	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2082	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2073	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0616 	 test accuracy:	 99.297 
confusion matrix: 
[373   1]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0668 	 test accuracy:	 99.156 
confusion matrix: 
[372   2]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 22:39:56	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2153	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2130	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0599 	 test accuracy:	 99.578 
confusion matrix: 
[373   1]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      1.00       374
         MDD       1.00      0.99      1.00       337

    accuracy                           1.00       711
   macro avg       1.00      1.00      1.00       711
weighted avg       1.00      1.00      1.00       711

test: 			test loss: 	0.0675 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 22:46:30	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2114	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2074	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0619 	 test accuracy:	 99.297 
confusion matrix: 
[371   3]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0673 	 test accuracy:	 99.297 
confusion matrix: 
[371   3]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 23:34:08	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 23:34:57	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 23:36:30	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 23:37:18	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1996	 train accuracy: 100.000	 validation loss: 0.2177	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.1996	 train accuracy: 100.000	 validation loss: 0.2156	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0814 	 test accuracy:	 98.594 
confusion matrix: 
[372   2]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0892 	 test accuracy:	 98.453 
confusion matrix: 
[373   1]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      1.00      0.99       374
         MDD       1.00      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.99      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 23:44:07	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 23:49:21	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-18 23:50:10	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2029	 validation accuracy: 99.859 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2019	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0600 	 test accuracy:	 99.437 
confusion matrix: 
[374   0]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0709 	 test accuracy:	 99.015 
confusion matrix: 
[373   1]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-18 23:53:57	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2042	 train accuracy: 100.000	 validation loss: 0.2312	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.2042	 train accuracy: 100.000	 validation loss: 0.2307	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1163 	 test accuracy:	 98.453 
confusion matrix: 
[373   1]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      1.00      0.99       374
         MDD       1.00      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.99      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.1147 	 test accuracy:	 98.453 
confusion matrix: 
[373   1]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      1.00      0.99       374
         MDD       1.00      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.99      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-18 23:57:40	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2178	 validation accuracy: 99.718 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2177	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1145 	 test accuracy:	 99.156 
confusion matrix: 
[373   1]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.1118 	 test accuracy:	 99.156 
confusion matrix: 
[374   0]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-19 00:03:08	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-19 00:04:49	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1993	 train accuracy: 100.000	 validation loss: 0.2173	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1993	 train accuracy: 100.000	 validation loss: 0.2154	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0925 	 test accuracy:	 98.312 
confusion matrix: 
[370   4]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0972 	 test accuracy:	 98.312 
confusion matrix: 
[371   3]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-19 00:07:50	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2158	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1990	 train accuracy: 100.000	 validation loss: 0.2149	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0949 	 test accuracy:	 98.031 
confusion matrix: 
[367   7]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0996 	 test accuracy:	 98.594 
confusion matrix: 
[370   4]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-19 00:17:54	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1999	 train accuracy: 100.000	 validation loss: 0.2236	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1998	 train accuracy: 100.000	 validation loss: 0.2231	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1021 	 test accuracy:	 98.172 
confusion matrix: 
[369   5]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.1016 	 test accuracy:	 98.172 
confusion matrix: 
[369   5]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-19 00:20:52	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2356	 validation accuracy: 98.025 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2349	 validation accuracy: 98.307 
best val accuracy: 98.307475 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1006 	 test accuracy:	 98.172 
confusion matrix: 
[367   7]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.1014 	 test accuracy:	 98.031 
confusion matrix: 
[365   9]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.98       374
         MDD       0.97      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-19 09:25:16	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2081	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2059	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0782 	 test accuracy:	 98.734 
confusion matrix: 
[370   4]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0805 	 test accuracy:	 98.734 
confusion matrix: 
[370   4]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-19 09:29:51	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2133	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2057	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0590 	 test accuracy:	 99.437 
confusion matrix: 
[373   1]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0621 	 test accuracy:	 99.437 
confusion matrix: 
[372   2]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-19 09:34:53	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	2023-04-19 09:35:42	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1987	 train accuracy: 100.000	 validation loss: 0.2134	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1987	 train accuracy: 100.000	 validation loss: 0.2051	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0752 	 test accuracy:	 98.453 
confusion matrix: 
[366   8]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       374
         MDD       0.98      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0823 	 test accuracy:	 98.453 
confusion matrix: 
[368   6]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       374
         MDD       0.98      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-19 09:44:57	========================
model name: 	MultiTIM_AT_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_BiDIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2266	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2228	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1166 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.1208 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-19 09:50:58	========================
model name: 	MultiTIM_AT_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_BiDIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_BiDIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: True	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2243	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2180	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1248 	 test accuracy:	 99.297 
confusion matrix: 
[372   2]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.1255 	 test accuracy:	 99.015 
confusion matrix: 
[370   4]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-19 10:13:41	========================
model name: 	TIM_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: TIM_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_BiDIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2315	 train accuracy: 99.436	 validation loss: 0.2453	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2315	 train accuracy: 99.530	 validation loss: 0.2453	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 99.436355
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0884 	 test accuracy:	 98.453 
confusion matrix: 
[366   8]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       374
         MDD       0.98      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0958 	 test accuracy:	 98.312 
confusion matrix: 
[366   8]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.98       374
         MDD       0.98      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-19 10:19:43	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2339	 validation accuracy: 98.166 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2189	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1189 	 test accuracy:	 98.031 
confusion matrix: 
[370   4]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0972 	 test accuracy:	 98.453 
confusion matrix: 
[369   5]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-19 10:26:35	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2075	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2055	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0698 	 test accuracy:	 99.015 
confusion matrix: 
[370   4]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0714 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-21 14:29:55	========================
model name: 	MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 6


========================	2023-04-21 14:37:20	========================
model name: 	MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MultiTIM_train_ADD_DIFF_IEMOCAP_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 6


========================	train begin	========================
train(final): 		train loss: 0.4214	 train accuracy: 100.000	 validation loss: 0.4223	 validation accuracy: 100.000 
train(max_min): 	train loss: 0.4214	 train accuracy: 100.000	 validation loss: 0.4222	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0763 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

test: 			test loss: 	0.0785 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-04-21 15:03:54	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2424	 train accuracy: 98.732	 validation loss: 0.2510	 validation accuracy: 97.884 
train(max_min): 	train loss: 0.2424	 train accuracy: 99.014	 validation loss: 0.2504	 validation accuracy: 98.166 
best val accuracy: 98.166432 	 corresponding train accuracy: 99.013621
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1227 	 test accuracy:	 95.921 
confusion matrix: 
[369   5]
[ 24 313]

classification report: 
              precision    recall  f1-score   support

          HC       0.94      0.99      0.96       374
         MDD       0.98      0.93      0.96       337

    accuracy                           0.96       711
   macro avg       0.96      0.96      0.96       711
weighted avg       0.96      0.96      0.96       711

test: 			test loss: 	0.1230 	 test accuracy:	 96.062 
confusion matrix: 
[369   5]
[ 23 314]

classification report: 
              precision    recall  f1-score   support

          HC       0.94      0.99      0.96       374
         MDD       0.98      0.93      0.96       337

    accuracy                           0.96       711
   macro avg       0.96      0.96      0.96       711
weighted avg       0.96      0.96      0.96       711

========================	test end	========================

========================	2023-04-21 15:11:24	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2090	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2089	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0793 	 test accuracy:	 98.594 
confusion matrix: 
[370   4]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0810 	 test accuracy:	 98.453 
confusion matrix: 
[369   5]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-21 15:18:11	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2062	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2053	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0650 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0655 	 test accuracy:	 99.015 
confusion matrix: 
[370   4]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-21 15:47:36	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2123	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2117	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0704 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0650 	 test accuracy:	 98.875 
confusion matrix: 
[371   3]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-23 15:08:33	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2108	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2108	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0842 	 test accuracy:	 98.172 
confusion matrix: 
[371   3]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0848 	 test accuracy:	 98.312 
confusion matrix: 
[371   3]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-23 15:15:33	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1992	 train accuracy: 100.000	 validation loss: 0.2126	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1992	 train accuracy: 100.000	 validation loss: 0.2123	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0675 	 test accuracy:	 98.594 
confusion matrix: 
[371   3]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0920 	 test accuracy:	 98.453 
confusion matrix: 
[369   5]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-23 15:20:49	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2055	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2042	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0721 	 test accuracy:	 98.875 
confusion matrix: 
[370   4]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0721 	 test accuracy:	 98.875 
confusion matrix: 
[370   4]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-23 15:26:36	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2020	 validation accuracy: 99.859 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2008	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0758 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0738 	 test accuracy:	 98.875 
confusion matrix: 
[370   4]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-23 15:32:49	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1987	 train accuracy: 100.000	 validation loss: 0.2092	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1987	 train accuracy: 100.000	 validation loss: 0.2060	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0839 	 test accuracy:	 98.312 
confusion matrix: 
[371   3]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0809 	 test accuracy:	 98.453 
confusion matrix: 
[371   3]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-23 15:38:12	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2038	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2022	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0656 	 test accuracy:	 99.578 
confusion matrix: 
[373   1]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      1.00       374
         MDD       1.00      0.99      1.00       337

    accuracy                           1.00       711
   macro avg       1.00      1.00      1.00       711
weighted avg       1.00      1.00      1.00       711

test: 			test loss: 	0.0648 	 test accuracy:	 99.578 
confusion matrix: 
[373   1]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      1.00       374
         MDD       1.00      0.99      1.00       337

    accuracy                           1.00       711
   macro avg       1.00      1.00      1.00       711
weighted avg       1.00      1.00      1.00       711

========================	test end	========================

========================	2023-04-23 15:43:17	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2063	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2054	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0642 	 test accuracy:	 99.297 
confusion matrix: 
[371   3]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0670 	 test accuracy:	 99.156 
confusion matrix: 
[370   4]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-23 16:04:31	========================
model name: 	TIM_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: TIM_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2381	 train accuracy: 99.342	 validation loss: 0.2477	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.2381	 train accuracy: 99.389	 validation loss: 0.2477	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 99.342414
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1079 	 test accuracy:	 98.031 
confusion matrix: 
[366   8]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.1113 	 test accuracy:	 97.750 
confusion matrix: 
[366   8]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-23 16:23:06	========================
model name: 	TIM_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: TIM_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2	


========================	2023-04-23 16:23:32	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	2023-04-23 16:25:25	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re1_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.1	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2008	 train accuracy: 99.906	 validation loss: 0.2226	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2007	 train accuracy: 99.906	 validation loss: 0.2199	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 99.906059
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0966 	 test accuracy:	 98.031 
confusion matrix: 
[369   5]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.98      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0966 	 test accuracy:	 98.031 
confusion matrix: 
[369   5]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.98      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-23 16:33:46	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2444	 train accuracy: 98.779	 validation loss: 0.2545	 validation accuracy: 98.025 
train(max_min): 	train loss: 0.2444	 train accuracy: 98.779	 validation loss: 0.2544	 validation accuracy: 98.166 
best val accuracy: 98.166432 	 corresponding train accuracy: 98.684829
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1158 	 test accuracy:	 96.765 
confusion matrix: 
[369   5]
[ 18 319]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.99      0.97       374
         MDD       0.98      0.95      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

test: 			test loss: 	0.1163 	 test accuracy:	 96.765 
confusion matrix: 
[369   5]
[ 18 319]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.99      0.97       374
         MDD       0.98      0.95      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-23 16:38:48	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2423	 train accuracy: 98.779	 validation loss: 0.2495	 validation accuracy: 97.038 
train(max_min): 	train loss: 0.2423	 train accuracy: 99.061	 validation loss: 0.2492	 validation accuracy: 97.461 
best val accuracy: 97.461213 	 corresponding train accuracy: 99.060592
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1215 	 test accuracy:	 96.765 
confusion matrix: 
[368   6]
[ 17 320]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.98      0.97       374
         MDD       0.98      0.95      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

test: 			test loss: 	0.1216 	 test accuracy:	 96.624 
confusion matrix: 
[369   5]
[ 19 318]

classification report: 
              precision    recall  f1-score   support

          HC       0.95      0.99      0.97       374
         MDD       0.98      0.94      0.96       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-23 16:43:39	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2400	 train accuracy: 99.014	 validation loss: 0.2503	 validation accuracy: 97.038 
train(max_min): 	train loss: 0.2389	 train accuracy: 99.061	 validation loss: 0.2492	 validation accuracy: 97.461 
best val accuracy: 97.461213 	 corresponding train accuracy: 98.825740
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1256 	 test accuracy:	 96.624 
confusion matrix: 
[365   9]
[ 15 322]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.98      0.97       374
         MDD       0.97      0.96      0.96       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

test: 			test loss: 	0.1242 	 test accuracy:	 96.624 
confusion matrix: 
[365   9]
[ 15 322]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.98      0.97       374
         MDD       0.97      0.96      0.96       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-04-23 16:55:14	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	2023-04-23 16:55:51	========================
model name: 	MultiTIM_1_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_1_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2111	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2090	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0714 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0786 	 test accuracy:	 98.875 
confusion matrix: 
[369   5]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-23 17:06:08	========================
model name: 	Transformer_DeltaTIM_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: Transformer_DeltaTIM_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2152	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2083	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0648 	 test accuracy:	 99.437 
confusion matrix: 
[372   2]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0725 	 test accuracy:	 98.875 
confusion matrix: 
[371   3]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-23 19:53:46	========================
model name: 	Transformer_DeltaTIM_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: Transformer_DeltaTIM_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2074	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2015	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0671 	 test accuracy:	 99.297 
confusion matrix: 
[369   5]
[  0 337]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       374
         MDD       0.99      1.00      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0673 	 test accuracy:	 99.297 
confusion matrix: 
[370   4]
[  1 336]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       374
         MDD       0.99      1.00      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-23 20:47:17	========================
model name: 	Transformer_DeltaTIM_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: Transformer_DeltaTIM_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer_DeltaTIM	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2035	 validation accuracy: 99.718 
train(max_min): 	train loss: 0.1991	 train accuracy: 100.000	 validation loss: 0.2025	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0677 	 test accuracy:	 99.297 
confusion matrix: 
[371   3]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0646 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-23 22:30:51	========================
model name: 	MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2130	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2125	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0773 	 test accuracy:	 98.734 
confusion matrix: 
[370   4]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0802 	 test accuracy:	 98.312 
confusion matrix: 
[368   6]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-23 22:47:20	========================
model name: 	MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2143	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2137	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0795 	 test accuracy:	 99.015 
confusion matrix: 
[370   4]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0787 	 test accuracy:	 98.453 
confusion matrix: 
[371   3]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-23 22:52:44	========================
model name: 	MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2070	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2060	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0746 	 test accuracy:	 98.734 
confusion matrix: 
[371   3]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0739 	 test accuracy:	 98.875 
confusion matrix: 
[372   2]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-25 17:27:20	========================
model name: 	MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2075	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1989	 train accuracy: 100.000	 validation loss: 0.2071	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0724 	 test accuracy:	 98.875 
confusion matrix: 
[370   4]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0733 	 test accuracy:	 98.875 
confusion matrix: 
[370   4]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-25 17:32:26	========================
model name: 	MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2096	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2084	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0730 	 test accuracy:	 98.594 
confusion matrix: 
[369   5]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0745 	 test accuracy:	 98.312 
confusion matrix: 
[370   4]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-25 17:37:28	========================
model name: 	MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	2023-04-25 17:38:55	========================
model name: 	MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.2167	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.1987	 train accuracy: 100.000	 validation loss: 0.2151	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0846 	 test accuracy:	 98.453 
confusion matrix: 
[369   5]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0863 	 test accuracy:	 98.453 
confusion matrix: 
[369   5]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-25 18:55:51	========================
model name: 	MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	2023-04-25 18:57:12	========================
model name: 	MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2144	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2128	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0707 	 test accuracy:	 99.297 
confusion matrix: 
[373   1]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0704 	 test accuracy:	 99.297 
confusion matrix: 
[373   1]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-25 19:01:53	========================
model name: 	MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2093	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2061	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0708 	 test accuracy:	 98.734 
confusion matrix: 
[369   5]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0697 	 test accuracy:	 98.594 
confusion matrix: 
[370   4]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-25 19:08:33	========================
model name: 	MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2098	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2053	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0753 	 test accuracy:	 98.734 
confusion matrix: 
[370   4]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0814 	 test accuracy:	 98.312 
confusion matrix: 
[367   7]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.98       374
         MDD       0.98      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-25 19:13:50	========================
model name: 	MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2067	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2021	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0688 	 test accuracy:	 99.156 
confusion matrix: 
[370   4]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0731 	 test accuracy:	 99.015 
confusion matrix: 
[369   5]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-25 19:17:10	========================
model name: 	MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2078	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2041	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0706 	 test accuracy:	 98.734 
confusion matrix: 
[372   2]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0731 	 test accuracy:	 98.875 
confusion matrix: 
[372   2]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-25 19:22:07	========================
model name: 	MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_finetune_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2117	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2078	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0666 	 test accuracy:	 99.297 
confusion matrix: 
[371   3]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0696 	 test accuracy:	 99.156 
confusion matrix: 
[370   4]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-25 19:53:53	========================
model name: 	Transformer_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: Transformer_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 4	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1996	 train accuracy: 100.000	 validation loss: 0.3916	 validation accuracy: 91.114 
train(max_min): 	train loss: 0.1996	 train accuracy: 100.000	 validation loss: 0.3578	 validation accuracy: 91.819 
best val accuracy: 91.819464 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.3024 	 test accuracy:	 90.858 
confusion matrix: 
[355  19]
[ 46 291]

classification report: 
              precision    recall  f1-score   support

          HC       0.89      0.95      0.92       374
         MDD       0.94      0.86      0.90       337

    accuracy                           0.91       711
   macro avg       0.91      0.91      0.91       711
weighted avg       0.91      0.91      0.91       711

test: 			test loss: 	0.3015 	 test accuracy:	 90.717 
confusion matrix: 
[356  18]
[ 48 289]

classification report: 
              precision    recall  f1-score   support

          HC       0.88      0.95      0.92       374
         MDD       0.94      0.86      0.90       337

    accuracy                           0.91       711
   macro avg       0.91      0.90      0.91       711
weighted avg       0.91      0.91      0.91       711

========================	test end	========================

========================	2023-04-25 20:06:11	========================
model name: 	Transformer_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: Transformer_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.4262	 validation accuracy: 89.563 
train(max_min): 	train loss: 0.1988	 train accuracy: 100.000	 validation loss: 0.3465	 validation accuracy: 91.255 
best val accuracy: 91.255289 	 corresponding train accuracy: 99.859089
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.3705 	 test accuracy:	 88.608 
confusion matrix: 
[332  42]
[ 39 298]

classification report: 
              precision    recall  f1-score   support

          HC       0.89      0.89      0.89       374
         MDD       0.88      0.88      0.88       337

    accuracy                           0.89       711
   macro avg       0.89      0.89      0.89       711
weighted avg       0.89      0.89      0.89       711

test: 			test loss: 	0.2784 	 test accuracy:	 89.733 
confusion matrix: 
[345  29]
[ 44 293]

classification report: 
              precision    recall  f1-score   support

          HC       0.89      0.92      0.90       374
         MDD       0.91      0.87      0.89       337

    accuracy                           0.90       711
   macro avg       0.90      0.90      0.90       711
weighted avg       0.90      0.90      0.90       711

========================	test end	========================

========================	2023-04-25 20:18:37	========================
model name: 	Transformer_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: Transformer_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1993	 train accuracy: 100.000	 validation loss: 0.2313	 validation accuracy: 98.025 
train(max_min): 	train loss: 0.1993	 train accuracy: 100.000	 validation loss: 0.2308	 validation accuracy: 98.307 
best val accuracy: 98.307475 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1129 	 test accuracy:	 98.031 
confusion matrix: 
[369   5]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.98      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.1119 	 test accuracy:	 98.031 
confusion matrix: 
[367   7]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-25 21:19:58	========================
model name: 	Transformer_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: Transformer_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: Transformer	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1993	 train accuracy: 100.000	 validation loss: 0.2281	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.1993	 train accuracy: 100.000	 validation loss: 0.2262	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1100 	 test accuracy:	 98.031 
confusion matrix: 
[370   4]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.1130 	 test accuracy:	 98.312 
confusion matrix: 
[367   7]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.98       374
         MDD       0.98      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-25 21:51:44	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2186	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2168	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0780 	 test accuracy:	 98.594 
confusion matrix: 
[369   5]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0818 	 test accuracy:	 98.594 
confusion matrix: 
[372   2]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-25 21:56:36	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2209	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2142	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0767 	 test accuracy:	 98.734 
confusion matrix: 
[369   5]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0779 	 test accuracy:	 98.734 
confusion matrix: 
[370   4]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-26 14:08:09	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2011	 train accuracy: 100.000	 validation loss: 0.2053	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2051	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0754 	 test accuracy:	 98.875 
confusion matrix: 
[371   3]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0796 	 test accuracy:	 98.453 
confusion matrix: 
[370   4]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-26 14:12:23	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.2043	 train accuracy: 100.000	 validation loss: 0.2082	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.2039	 train accuracy: 100.000	 validation loss: 0.2063	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0664 	 test accuracy:	 99.437 
confusion matrix: 
[373   1]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0661 	 test accuracy:	 99.437 
confusion matrix: 
[372   2]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-27 22:29:13	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 36	dilation: 8	filters: 36	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	2023-04-27 22:54:47	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	2023-04-27 22:57:29	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	2023-04-27 22:59:54	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2107	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2106	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0692 	 test accuracy:	 99.156 
confusion matrix: 
[372   2]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0695 	 test accuracy:	 99.297 
confusion matrix: 
[371   3]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-27 23:06:31	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2242	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2202	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1109 	 test accuracy:	 97.609 
confusion matrix: 
[370   4]
[ 13 324]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.99      0.96      0.97       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.1152 	 test accuracy:	 97.468 
confusion matrix: 
[370   4]
[ 14 323]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.99      0.98       374
         MDD       0.99      0.96      0.97       337

    accuracy                           0.97       711
   macro avg       0.98      0.97      0.97       711
weighted avg       0.98      0.97      0.97       711

========================	test end	========================

========================	2023-04-27 23:11:42	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2202	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2193	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0923 	 test accuracy:	 98.453 
confusion matrix: 
[369   5]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0982 	 test accuracy:	 98.031 
confusion matrix: 
[368   6]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-27 23:18:30	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2073	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2064	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0748 	 test accuracy:	 98.594 
confusion matrix: 
[371   3]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0713 	 test accuracy:	 98.734 
confusion matrix: 
[370   4]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-27 23:24:37	========================
model name: 	MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MultiTIM_AT_DIFF_MODMA_order3_drop1_mfcc_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 313	num_class: 2


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2041	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2041	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0685 	 test accuracy:	 99.437 
confusion matrix: 
[373   1]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0691 	 test accuracy:	 99.297 
confusion matrix: 
[372   2]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-04-28 14:31:33	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterTrue
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterTrue	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: True	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	is_weight: False	seq_len: 100	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2246	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2185	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0864 	 test accuracy:	 98.031 
confusion matrix: 
[369   5]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.98      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0945 	 test accuracy:	 97.750 
confusion matrix: 
[367   7]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-28 14:43:09	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2084	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2071	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0758 	 test accuracy:	 98.734 
confusion matrix: 
[370   4]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0778 	 test accuracy:	 98.453 
confusion matrix: 
[368   6]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       374
         MDD       0.98      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-04-28 14:48:16	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2044	 validation accuracy: 99.718 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2001	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0650 	 test accuracy:	 99.437 
confusion matrix: 
[373   1]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0638 	 test accuracy:	 99.437 
confusion matrix: 
[374   0]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-01 20:41:24	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2121	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2082	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0665 	 test accuracy:	 99.297 
confusion matrix: 
[373   1]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0668 	 test accuracy:	 99.297 
confusion matrix: 
[374   0]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-07 13:39:19	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2078	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2074	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0706 	 test accuracy:	 98.734 
confusion matrix: 
[369   5]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0723 	 test accuracy:	 98.594 
confusion matrix: 
[368   6]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       374
         MDD       0.98      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-07 13:44:53	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2097	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2089	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0713 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0691 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-07 13:49:42	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2069	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2063	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0673 	 test accuracy:	 99.297 
confusion matrix: 
[371   3]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0707 	 test accuracy:	 99.156 
confusion matrix: 
[372   2]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-07 13:54:37	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2053	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2033	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0629 	 test accuracy:	 99.015 
confusion matrix: 
[372   2]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0619 	 test accuracy:	 99.156 
confusion matrix: 
[372   2]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-07 14:09:44	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2151	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2083	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0637 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0665 	 test accuracy:	 98.594 
confusion matrix: 
[367   7]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       374
         MDD       0.98      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-07 14:14:42	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2084	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2056	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0654 	 test accuracy:	 99.156 
confusion matrix: 
[369   5]
[  1 336]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       374
         MDD       0.99      1.00      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0671 	 test accuracy:	 99.297 
confusion matrix: 
[370   4]
[  1 336]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       374
         MDD       0.99      1.00      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-07 14:21:48	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2087	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2079	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0720 	 test accuracy:	 99.156 
confusion matrix: 
[372   2]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0760 	 test accuracy:	 98.734 
confusion matrix: 
[370   4]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-07 14:33:44	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-07 14:33:58	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	2023-05-07 14:36:28	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MultiTIM_AT_DIFF_CASIA_order3_drop1_mfcc_epoch100_l2re1_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.4215	 train accuracy: 100.000	 validation loss: 0.4230	 validation accuracy: 100.000 
train(max_min): 	train loss: 0.4215	 train accuracy: 100.000	 validation loss: 0.4227	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0745 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

test: 			test loss: 	0.0838 	 test accuracy:	 99.931 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 241   0   0   1]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-05-07 14:48:02	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: CASIA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	2023-05-07 14:48:36	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-07 14:51:09	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.3620	 train accuracy: 92.250	 validation loss: 0.3349	 validation accuracy: 93.089 
train(max_min): 	train loss: 0.3611	 train accuracy: 92.344	 validation loss: 0.3349	 validation accuracy: 93.230 
best val accuracy: 93.229901 	 corresponding train accuracy: 91.874119
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.2830 	 test accuracy:	 90.577 
confusion matrix: 
[359  15]
[ 52 285]

classification report: 
              precision    recall  f1-score   support

          HC       0.87      0.96      0.91       374
         MDD       0.95      0.85      0.89       337

    accuracy                           0.91       711
   macro avg       0.91      0.90      0.90       711
weighted avg       0.91      0.91      0.91       711

test: 			test loss: 	0.2837 	 test accuracy:	 90.577 
confusion matrix: 
[359  15]
[ 52 285]

classification report: 
              precision    recall  f1-score   support

          HC       0.87      0.96      0.91       374
         MDD       0.95      0.85      0.89       337

    accuracy                           0.91       711
   macro avg       0.91      0.90      0.90       711
weighted avg       0.91      0.91      0.91       711

========================	test end	========================

========================	2023-05-07 15:02:49	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2005	 train accuracy: 100.000	 validation loss: 0.2202	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2004	 train accuracy: 100.000	 validation loss: 0.2155	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0827 	 test accuracy:	 98.172 
confusion matrix: 
[368   6]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0786 	 test accuracy:	 98.594 
confusion matrix: 
[369   5]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-07 15:14:05	========================
model name: 	TCN_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: TCN_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.3180	 train accuracy: 94.551	 validation loss: 0.3370	 validation accuracy: 92.102 
train(max_min): 	train loss: 0.3180	 train accuracy: 94.598	 validation loss: 0.3366	 validation accuracy: 92.384 
best val accuracy: 92.383639 	 corresponding train accuracy: 94.598403
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.2709 	 test accuracy:	 89.030 
confusion matrix: 
[356  18]
[ 60 277]

classification report: 
              precision    recall  f1-score   support

          HC       0.86      0.95      0.90       374
         MDD       0.94      0.82      0.88       337

    accuracy                           0.89       711
   macro avg       0.90      0.89      0.89       711
weighted avg       0.90      0.89      0.89       711

test: 			test loss: 	0.2680 	 test accuracy:	 89.451 
confusion matrix: 
[349  25]
[ 50 287]

classification report: 
              precision    recall  f1-score   support

          HC       0.87      0.93      0.90       374
         MDD       0.92      0.85      0.88       337

    accuracy                           0.89       711
   macro avg       0.90      0.89      0.89       711
weighted avg       0.90      0.89      0.89       711

========================	test end	========================

========================	2023-05-07 15:16:16	========================
model name: 	TCN_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: TCN_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: TCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2406	 train accuracy: 98.309	 validation loss: 0.2499	 validation accuracy: 97.461 
train(max_min): 	train loss: 0.2406	 train accuracy: 98.450	 validation loss: 0.2497	 validation accuracy: 97.602 
best val accuracy: 97.602257 	 corresponding train accuracy: 97.228746
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1191 	 test accuracy:	 97.468 
confusion matrix: 
[366   8]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.98      0.98       374
         MDD       0.98      0.97      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

test: 			test loss: 	0.1359 	 test accuracy:	 96.765 
confusion matrix: 
[366   8]
[ 15 322]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.98      0.97       374
         MDD       0.98      0.96      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-05-08 15:08:11	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-08 15:08:41	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2187	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2138	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0911 	 test accuracy:	 98.453 
confusion matrix: 
[370   4]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0918 	 test accuracy:	 98.594 
confusion matrix: 
[371   3]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 15:13:35	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2078	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2078	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0695 	 test accuracy:	 98.875 
confusion matrix: 
[370   4]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0714 	 test accuracy:	 98.875 
confusion matrix: 
[369   5]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 15:23:43	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-08 15:24:38	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2153	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1986	 train accuracy: 100.000	 validation loss: 0.2105	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0656 	 test accuracy:	 99.297 
confusion matrix: 
[372   2]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0700 	 test accuracy:	 99.297 
confusion matrix: 
[372   2]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 15:29:57	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2034	 validation accuracy: 99.718 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2023	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0747 	 test accuracy:	 99.015 
confusion matrix: 
[370   4]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0778 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 15:37:15	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2072	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2048	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0730 	 test accuracy:	 98.875 
confusion matrix: 
[371   3]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0803 	 test accuracy:	 98.875 
confusion matrix: 
[372   2]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 15:43:28	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2110	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.1985	 train accuracy: 100.000	 validation loss: 0.2088	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0833 	 test accuracy:	 98.453 
confusion matrix: 
[370   4]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0824 	 test accuracy:	 98.031 
confusion matrix: 
[371   3]
[ 11 326]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-05-08 15:50:13	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1992	 train accuracy: 100.000	 validation loss: 0.2084	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.1992	 train accuracy: 100.000	 validation loss: 0.2042	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0704 	 test accuracy:	 99.156 
confusion matrix: 
[373   1]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0725 	 test accuracy:	 99.015 
confusion matrix: 
[372   2]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 15:56:03	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.1993	 train accuracy: 100.000	 validation loss: 0.2054	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.1993	 train accuracy: 100.000	 validation loss: 0.2010	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0716 	 test accuracy:	 99.015 
confusion matrix: 
[373   1]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0770 	 test accuracy:	 98.734 
confusion matrix: 
[371   3]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 16:01:30	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2114	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2086	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0658 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0636 	 test accuracy:	 99.437 
confusion matrix: 
[372   2]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 16:07:13	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2087	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2064	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0734 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0778 	 test accuracy:	 98.875 
confusion matrix: 
[369   5]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 16:15:32	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2082	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2046	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0721 	 test accuracy:	 99.297 
confusion matrix: 
[373   1]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0682 	 test accuracy:	 99.297 
confusion matrix: 
[373   1]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 16:19:16	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2047	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2023	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0677 	 test accuracy:	 99.578 
confusion matrix: 
[374   0]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      1.00       374
         MDD       1.00      0.99      1.00       337

    accuracy                           1.00       711
   macro avg       1.00      1.00      1.00       711
weighted avg       1.00      1.00      1.00       711

test: 			test loss: 	0.0695 	 test accuracy:	 99.297 
confusion matrix: 
[374   0]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 16:22:37	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2061	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2056	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0724 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0782 	 test accuracy:	 98.875 
confusion matrix: 
[369   5]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 16:25:28	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2051	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2040	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0712 	 test accuracy:	 99.015 
confusion matrix: 
[373   1]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0785 	 test accuracy:	 98.875 
confusion matrix: 
[372   2]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 16:30:54	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2058	 validation accuracy: 99.718 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2050	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0748 	 test accuracy:	 98.875 
confusion matrix: 
[370   4]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0780 	 test accuracy:	 98.875 
confusion matrix: 
[370   4]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 16:37:12	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2106	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2096	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0715 	 test accuracy:	 99.156 
confusion matrix: 
[372   2]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0695 	 test accuracy:	 99.015 
confusion matrix: 
[372   2]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-08 16:50:52	========================
model name: 	MTCN_AT_DIFF_DAIC2_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_DAIC2_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: DAIC2	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 188	num_class: 2	


========================	2023-05-08 20:07:30	========================
model name: 	MTCN_AT_DIFF_DAIC21_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_DAIC21_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: DAIC21	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-08 20:09:23	========================
model name: 	MTCN_AT_DIFF_DAIC21_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_DAIC21_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: DAIC21	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-11 09:44:56	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse_clusterFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2103	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2072	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0705 	 test accuracy:	 98.875 
confusion matrix: 
[373   1]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0715 	 test accuracy:	 99.297 
confusion matrix: 
[374   0]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-11 09:52:35	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2060	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2051	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0629 	 test accuracy:	 99.437 
confusion matrix: 
[371   3]
[  1 336]

classification report: 
              precision    recall  f1-score   support

          HC       1.00      0.99      0.99       374
         MDD       0.99      1.00      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0675 	 test accuracy:	 99.437 
confusion matrix: 
[372   2]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-11 09:57:56	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2094	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2060	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0722 	 test accuracy:	 98.875 
confusion matrix: 
[372   2]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0783 	 test accuracy:	 98.734 
confusion matrix: 
[372   2]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-11 10:10:50	========================
model name: 	MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_v	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2087	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2085	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0700 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0784 	 test accuracy:	 99.015 
confusion matrix: 
[369   5]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-11 10:16:12	========================
model name: 	MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_v	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2047	 validation accuracy: 99.718 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2039	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0679 	 test accuracy:	 99.297 
confusion matrix: 
[372   2]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0768 	 test accuracy:	 99.297 
confusion matrix: 
[371   3]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-11 10:21:41	========================
model name: 	MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_v	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2066	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2032	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0682 	 test accuracy:	 99.437 
confusion matrix: 
[373   1]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0747 	 test accuracy:	 99.297 
confusion matrix: 
[372   2]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-11 10:30:28	========================
model name: 	MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_v	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2014	 validation accuracy: 99.859 
train(max_min): 	train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2014	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0796 	 test accuracy:	 98.875 
confusion matrix: 
[369   5]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0781 	 test accuracy:	 98.875 
confusion matrix: 
[370   4]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-11 10:34:41	========================
model name: 	MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_v	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2035	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2014	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0668 	 test accuracy:	 99.297 
confusion matrix: 
[373   1]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0789 	 test accuracy:	 98.594 
confusion matrix: 
[370   4]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-11 10:45:06	========================
model name: 	MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: v_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-11 10:45:27	========================
model name: 	MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: v_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2062	 train accuracy: 100.000	 validation loss: 0.2319	 validation accuracy: 98.307 
train(max_min): 	train loss: 0.2061	 train accuracy: 100.000	 validation loss: 0.2316	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0750 	 test accuracy:	 98.594 
confusion matrix: 
[371   3]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0748 	 test accuracy:	 98.875 
confusion matrix: 
[371   3]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-11 10:48:23	========================
model name: 	MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: v_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2081	 train accuracy: 100.000	 validation loss: 0.2331	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.2079	 train accuracy: 100.000	 validation loss: 0.2326	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0797 	 test accuracy:	 98.734 
confusion matrix: 
[369   5]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0889 	 test accuracy:	 98.594 
confusion matrix: 
[369   5]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-11 10:50:38	========================
model name: 	MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: v_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2078	 train accuracy: 100.000	 validation loss: 0.2321	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2074	 train accuracy: 100.000	 validation loss: 0.2318	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0864 	 test accuracy:	 98.734 
confusion matrix: 
[372   2]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0907 	 test accuracy:	 98.453 
confusion matrix: 
[370   4]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-05-11 10:52:35	========================
model name: 	MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: v_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2086	 train accuracy: 100.000	 validation loss: 0.2347	 validation accuracy: 99.295 
train(max_min): 	train loss: 0.2084	 train accuracy: 100.000	 validation loss: 0.2335	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0945 	 test accuracy:	 98.453 
confusion matrix: 
[369   5]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.1006 	 test accuracy:	 98.172 
confusion matrix: 
[369   5]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.98       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-05-11 10:57:29	========================
model name: 	MTCN_v_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: v_v	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2081	 train accuracy: 100.000	 validation loss: 0.2330	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2080	 train accuracy: 100.000	 validation loss: 0.2330	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0695 	 test accuracy:	 99.015 
confusion matrix: 
[372   2]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0773 	 test accuracy:	 98.312 
confusion matrix: 
[372   2]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-05-11 10:59:06	========================
model name: 	MTCN_v_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: v_v	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2071	 train accuracy: 100.000	 validation loss: 0.2297	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2070	 train accuracy: 100.000	 validation loss: 0.2289	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0866 	 test accuracy:	 98.453 
confusion matrix: 
[372   2]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.99      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0897 	 test accuracy:	 98.734 
confusion matrix: 
[371   3]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-11 11:02:14	========================
model name: 	MTCN_v_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: v_v	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2074	 train accuracy: 100.000	 validation loss: 0.2321	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2072	 train accuracy: 100.000	 validation loss: 0.2319	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0950 	 test accuracy:	 99.015 
confusion matrix: 
[373   1]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0935 	 test accuracy:	 98.875 
confusion matrix: 
[372   2]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-11 11:04:06	========================
model name: 	MTCN_v_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: v_v	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2104	 train accuracy: 100.000	 validation loss: 0.2374	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2104	 train accuracy: 100.000	 validation loss: 0.2370	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1030 	 test accuracy:	 98.875 
confusion matrix: 
[372   2]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.1072 	 test accuracy:	 98.734 
confusion matrix: 
[372   2]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-11 11:06:21	========================
model name: 	MTCN_v_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: v_v	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2070	 train accuracy: 100.000	 validation loss: 0.2266	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.2070	 train accuracy: 100.000	 validation loss: 0.2264	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0912 	 test accuracy:	 98.453 
confusion matrix: 
[371   3]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.1066 	 test accuracy:	 97.890 
confusion matrix: 
[369   5]
[ 10 327]

classification report: 
              precision    recall  f1-score   support

          HC       0.97      0.99      0.98       374
         MDD       0.98      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-05-11 11:31:36	========================
model name: 	MTCN_v_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: v_v	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2054	 train accuracy: 100.000	 validation loss: 0.2292	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2053	 train accuracy: 100.000	 validation loss: 0.2286	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1005 	 test accuracy:	 98.875 
confusion matrix: 
[370   4]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.1030 	 test accuracy:	 98.875 
confusion matrix: 
[371   3]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-11 12:11:15	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2064	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2047	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0691 	 test accuracy:	 99.297 
confusion matrix: 
[374   0]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0766 	 test accuracy:	 99.015 
confusion matrix: 
[373   1]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-13 20:27:57	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V2	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-13 20:29:06	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-13 20:29:22	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.4236	 train accuracy: 100.000	 validation loss: 0.8689	 validation accuracy: 84.097 
train(max_min): 	train loss: 0.4236	 train accuracy: 100.000	 validation loss: 0.5381	 validation accuracy: 89.583 
best val accuracy: 89.583333 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.6041 	 test accuracy:	 83.194 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0   0   0   0 242]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       0.00      0.00      0.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       0.49      1.00      0.66       237

    accuracy                           0.83      1440
   macro avg       0.75      0.83      0.78      1440
weighted avg       0.75      0.83      0.78      1440

test: 			test loss: 	0.2250 	 test accuracy:	 87.500 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0  62   0   0 180]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      0.26      0.41       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       0.57      1.00      0.72       237

    accuracy                           0.88      1440
   macro avg       0.93      0.88      0.86      1440
weighted avg       0.93      0.88      0.86      1440

========================	test end	========================

========================	2023-05-13 20:35:51	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 10	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	2023-05-13 20:38:34	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.4259	 train accuracy: 100.000	 validation loss: 1.1654	 validation accuracy: 84.097 
train(max_min): 	train loss: 0.4259	 train accuracy: 100.000	 validation loss: 0.5278	 validation accuracy: 96.528 
best val accuracy: 96.527778 	 corresponding train accuracy: 95.162037
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.9335 	 test accuracy:	 83.194 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0   0   0   0 242]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       0.00      0.00      0.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       0.49      1.00      0.66       237

    accuracy                           0.83      1440
   macro avg       0.75      0.83      0.78      1440
weighted avg       0.75      0.83      0.78      1440

test: 			test loss: 	0.2465 	 test accuracy:	 95.069 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 193   0   0  49]
[  0   0   0 243   0   0]
[  0   6   0   0 238   0]
[  0   0  16   0   0 221]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       0.97      1.00      0.99       233
  frustrated       0.92      0.80      0.86       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      0.98      0.99       244
         sad       0.82      0.93      0.87       237

    accuracy                           0.95      1440
   macro avg       0.95      0.95      0.95      1440
weighted avg       0.95      0.95      0.95      1440

========================	test end	========================

========================	2023-05-13 20:42:51	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.4218	 train accuracy: 100.000	 validation loss: 0.5508	 validation accuracy: 87.847 
train(max_min): 	train loss: 0.4218	 train accuracy: 100.000	 validation loss: 0.4269	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.2716 	 test accuracy:	 85.972 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0  40   0   0 202]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      0.17      0.28       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       0.54      1.00      0.70       237

    accuracy                           0.86      1440
   macro avg       0.92      0.86      0.83      1440
weighted avg       0.92      0.86      0.83      1440

test: 			test loss: 	0.0995 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-05-13 20:52:41	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 10	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	2023-05-13 20:58:29	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.4211	 train accuracy: 100.000	 validation loss: 0.7012	 validation accuracy: 85.625 
train(max_min): 	train loss: 0.4211	 train accuracy: 100.000	 validation loss: 0.4252	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 99.930556
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.4316 	 test accuracy:	 84.514 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0  19   0   0 223]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      0.08      0.15       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       0.52      1.00      0.68       237

    accuracy                           0.85      1440
   macro avg       0.92      0.85      0.80      1440
weighted avg       0.92      0.85      0.80      1440

test: 			test loss: 	0.0714 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-05-13 21:08:50	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.4245	 train accuracy: 100.000	 validation loss: 0.4256	 validation accuracy: 100.000 
train(max_min): 	train loss: 0.4245	 train accuracy: 100.000	 validation loss: 0.4256	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0742 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

test: 			test loss: 	0.1016 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-05-13 21:13:31	========================
model name: 	MTCN_AT_v_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_v_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V1	attention_type: AF	multi_type: AT_v	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.4235	 train accuracy: 100.000	 validation loss: 0.9117	 validation accuracy: 84.097 
train(max_min): 	train loss: 0.4235	 train accuracy: 100.000	 validation loss: 0.4292	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.6417 	 test accuracy:	 83.194 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0   0   0   0 242]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       0.00      0.00      0.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       0.49      1.00      0.66       237

    accuracy                           0.83      1440
   macro avg       0.75      0.83      0.78      1440
weighted avg       0.75      0.83      0.78      1440

test: 			test loss: 	0.0741 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-05-13 21:21:42	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.4255	 train accuracy: 100.000	 validation loss: 0.7998	 validation accuracy: 84.792 
train(max_min): 	train loss: 0.4253	 train accuracy: 100.000	 validation loss: 0.4252	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.5366 	 test accuracy:	 83.611 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0   6   0   0 236]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      0.02      0.05       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       0.50      1.00      0.67       237

    accuracy                           0.84      1440
   macro avg       0.92      0.84      0.79      1440
weighted avg       0.92      0.84      0.79      1440

test: 			test loss: 	0.0811 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-05-13 21:31:58	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 188	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.4280	 train accuracy: 100.000	 validation loss: 0.6586	 validation accuracy: 87.083 
train(max_min): 	train loss: 0.4279	 train accuracy: 100.000	 validation loss: 0.4254	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.3756 	 test accuracy:	 85.556 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0  34   0   0 208]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      0.14      0.25       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       0.53      1.00      0.70       237

    accuracy                           0.86      1440
   macro avg       0.92      0.86      0.82      1440
weighted avg       0.92      0.86      0.82      1440

test: 			test loss: 	0.0623 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-05-13 21:37:51	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 188	num_class: 6	


========================	2023-05-13 21:40:49	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse	epochs: 100	lr: 0.0002	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse_clusterFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 10	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: CASIA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 188	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.4321	 train accuracy: 100.000	 validation loss: 0.5300	 validation accuracy: 93.125 
train(max_min): 	train loss: 0.4318	 train accuracy: 100.000	 validation loss: 0.4374	 validation accuracy: 99.861 
best val accuracy: 99.861111 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.2058 	 test accuracy:	 92.083 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 128   0   0 114]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      0.53      0.69       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       0.68      1.00      0.81       237

    accuracy                           0.92      1440
   macro avg       0.95      0.92      0.92      1440
weighted avg       0.95      0.92      0.92      1440

test: 			test loss: 	0.0699 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-05-13 21:49:15	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	is_cluster: False	dataset_name: MODMA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-13 22:01:10	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-13 22:06:02	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2000	 train accuracy: 100.000	 validation loss: 0.2102	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.1999	 train accuracy: 100.000	 validation loss: 0.2099	 validation accuracy: 99.436 
best val accuracy: 99.435825 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0777 	 test accuracy:	 98.734 
confusion matrix: 
[371   3]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0767 	 test accuracy:	 98.734 
confusion matrix: 
[370   4]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-13 22:11:22	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2008	 validation accuracy: 100.000 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2003	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0630 	 test accuracy:	 99.437 
confusion matrix: 
[372   2]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0675 	 test accuracy:	 99.156 
confusion matrix: 
[372   2]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-13 22:20:56	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	augment: False	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	is_cluster: False	dataset_name: MODMA	order: 3	version: V1	attention_type: AF	multi_type: AT_DIFF	patience: 10	is_mask: False	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2057	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2048	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0653 	 test accuracy:	 99.437 
confusion matrix: 
[373   1]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0735 	 test accuracy:	 99.156 
confusion matrix: 
[373   1]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-13 22:26:49	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2055	 validation accuracy: 99.718 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2048	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0722 	 test accuracy:	 99.156 
confusion matrix: 
[373   1]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0794 	 test accuracy:	 99.015 
confusion matrix: 
[372   2]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-13 22:33:25	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2077	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.2009	 train accuracy: 100.000	 validation loss: 0.2043	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0637 	 test accuracy:	 99.437 
confusion matrix: 
[373   1]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0709 	 test accuracy:	 99.297 
confusion matrix: 
[373   1]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-13 22:38:37	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2011	 train accuracy: 100.000	 validation loss: 0.2088	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.2011	 train accuracy: 100.000	 validation loss: 0.2065	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0626 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0622 	 test accuracy:	 99.578 
confusion matrix: 
[373   1]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      1.00       374
         MDD       1.00      0.99      1.00       337

    accuracy                           1.00       711
   macro avg       1.00      1.00      1.00       711
weighted avg       1.00      1.00      1.00       711

========================	test end	========================

========================	2023-05-13 22:44:04	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2011	 train accuracy: 100.000	 validation loss: 0.2035	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2033	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0690 	 test accuracy:	 99.297 
confusion matrix: 
[371   3]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0831 	 test accuracy:	 98.453 
confusion matrix: 
[371   3]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-05-13 22:49:24	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2011	 train accuracy: 100.000	 validation loss: 0.2040	 validation accuracy: 99.718 
train(max_min): 	train loss: 0.2011	 train accuracy: 100.000	 validation loss: 0.2011	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0671 	 test accuracy:	 99.156 
confusion matrix: 
[373   1]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0755 	 test accuracy:	 99.015 
confusion matrix: 
[373   1]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-13 22:58:30	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2071	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2046	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0710 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0880 	 test accuracy:	 98.453 
confusion matrix: 
[367   7]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.98      0.99       374
         MDD       0.98      0.99      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-05-13 23:04:53	========================
model name: 	MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_v	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2011	 train accuracy: 100.000	 validation loss: 0.2064	 validation accuracy: 99.436 
train(max_min): 	train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2052	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0676 	 test accuracy:	 99.437 
confusion matrix: 
[372   2]
[  2 335]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0850 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-13 23:09:58	========================
model name: 	MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_v	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2011	 train accuracy: 100.000	 validation loss: 0.2011	 validation accuracy: 99.859 
train(max_min): 	train loss: 0.2011	 train accuracy: 100.000	 validation loss: 0.2005	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0793 	 test accuracy:	 98.875 
confusion matrix: 
[373   1]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0757 	 test accuracy:	 99.156 
confusion matrix: 
[373   1]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-13 23:14:04	========================
model name: 	MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_v	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2011	 train accuracy: 100.000	 validation loss: 0.2037	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.2010	 train accuracy: 100.000	 validation loss: 0.2019	 validation accuracy: 99.859 
best val accuracy: 99.858956 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0712 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0772 	 test accuracy:	 99.297 
confusion matrix: 
[372   2]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-13 23:25:38	========================
model name: 	MTCN_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: v	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2111	 train accuracy: 100.000	 validation loss: 0.2464	 validation accuracy: 97.884 
train(max_min): 	train loss: 0.2111	 train accuracy: 100.000	 validation loss: 0.2429	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1308 	 test accuracy:	 98.453 
confusion matrix: 
[369   5]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.1431 	 test accuracy:	 98.594 
confusion matrix: 
[370   4]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-13 23:30:01	========================
model name: 	MTCN_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: v	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2108	 train accuracy: 100.000	 validation loss: 0.2389	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.2102	 train accuracy: 100.000	 validation loss: 0.2386	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1189 	 test accuracy:	 98.453 
confusion matrix: 
[371   3]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.1242 	 test accuracy:	 98.172 
confusion matrix: 
[368   6]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-05-13 23:31:26	========================
model name: 	MTCN_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: v	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2098	 train accuracy: 100.000	 validation loss: 0.2437	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2095	 train accuracy: 100.000	 validation loss: 0.2421	 validation accuracy: 99.154 
best val accuracy: 99.153738 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0903 	 test accuracy:	 98.594 
confusion matrix: 
[372   2]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0929 	 test accuracy:	 99.015 
confusion matrix: 
[372   2]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-13 23:35:43	========================
model name: 	MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: v_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2085	 train accuracy: 100.000	 validation loss: 0.2473	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.2080	 train accuracy: 100.000	 validation loss: 0.2454	 validation accuracy: 98.731 
best val accuracy: 98.730606 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1174 	 test accuracy:	 97.750 
confusion matrix: 
[372   2]
[ 14 323]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.99      0.98       374
         MDD       0.99      0.96      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.1223 	 test accuracy:	 97.609 
confusion matrix: 
[371   3]
[ 14 323]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.99      0.98       374
         MDD       0.99      0.96      0.97       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-05-13 23:38:06	========================
model name: 	MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: v_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2107	 train accuracy: 100.000	 validation loss: 0.2415	 validation accuracy: 98.872 
train(max_min): 	train loss: 0.2106	 train accuracy: 100.000	 validation loss: 0.2405	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1472 	 test accuracy:	 98.453 
confusion matrix: 
[372   2]
[  9 328]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.97      0.98       337

    accuracy                           0.98       711
   macro avg       0.99      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.1723 	 test accuracy:	 97.328 
confusion matrix: 
[370   4]
[ 15 322]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.99      0.97       374
         MDD       0.99      0.96      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-05-13 23:40:36	========================
model name: 	MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: v_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2081	 train accuracy: 100.000	 validation loss: 0.2377	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2081	 train accuracy: 100.000	 validation loss: 0.2365	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0935 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0950 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-13 23:42:51	========================
model name: 	MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_v_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: v_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2072	 train accuracy: 100.000	 validation loss: 0.2379	 validation accuracy: 98.590 
train(max_min): 	train loss: 0.2072	 train accuracy: 100.000	 validation loss: 0.2371	 validation accuracy: 98.590 
best val accuracy: 98.589563 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1687 	 test accuracy:	 98.594 
confusion matrix: 
[371   3]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.1701 	 test accuracy:	 98.031 
confusion matrix: 
[368   6]
[  8 329]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.98      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-05-14 00:03:23	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0001_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0001_pretrainFalse	epochs: 100	lr: 0.0001	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: CASIA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 188	num_class: 6	


========================	2023-05-14 00:08:52	========================
model name: 	MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0002_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 10	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: CASIA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 188	num_class: 6	


========================	train begin	========================
train(final): 		train loss: 0.4275	 train accuracy: 100.000	 validation loss: 0.4416	 validation accuracy: 100.000 
train(max_min): 	train loss: 0.4275	 train accuracy: 100.000	 validation loss: 0.4329	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0864 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

test: 			test loss: 	0.0554 	 test accuracy:	 100.000 
confusion matrix: 
[241   0   0   0   0   0]
[  0 233   0   0   0   0]
[  0   0 242   0   0   0]
[  0   0   0 243   0   0]
[  0   0   0   0 244   0]
[  0   0   0   0   0 237]

classification report: 
              precision    recall  f1-score   support

       angry       1.00      1.00      1.00       241
     excited       1.00      1.00      1.00       233
  frustrated       1.00      1.00      1.00       242
       happy       1.00      1.00      1.00       243
     neutral       1.00      1.00      1.00       244
         sad       1.00      1.00      1.00       237

    accuracy                           1.00      1440
   macro avg       1.00      1.00      1.00      1440
weighted avg       1.00      1.00      1.00      1440

========================	test end	========================

========================	2023-05-14 09:11:34	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2238	 train accuracy: 99.859	 validation loss: 0.2518	 validation accuracy: 98.166 
train(max_min): 	train loss: 0.2238	 train accuracy: 100.000	 validation loss: 0.2511	 validation accuracy: 98.449 
best val accuracy: 98.448519 	 corresponding train accuracy: 99.718178
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1186 	 test accuracy:	 97.046 
confusion matrix: 
[369   5]
[ 16 321]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.99      0.97       374
         MDD       0.98      0.95      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

test: 			test loss: 	0.1158 	 test accuracy:	 96.906 
confusion matrix: 
[368   6]
[ 16 321]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.98      0.97       374
         MDD       0.98      0.95      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-05-14 09:28:27	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-14 09:29:10	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-14 09:39:00	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-14 09:40:03	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2156	 train accuracy: 100.000	 validation loss: 0.2489	 validation accuracy: 98.025 
train(max_min): 	train loss: 0.2148	 train accuracy: 100.000	 validation loss: 0.2481	 validation accuracy: 98.166 
best val accuracy: 98.166432 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.1171 	 test accuracy:	 97.187 
confusion matrix: 
[368   6]
[ 14 323]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.98      0.97       374
         MDD       0.98      0.96      0.97       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

test: 			test loss: 	0.1226 	 test accuracy:	 96.624 
confusion matrix: 
[367   7]
[ 17 320]

classification report: 
              precision    recall  f1-score   support

          HC       0.96      0.98      0.97       374
         MDD       0.98      0.95      0.96       337

    accuracy                           0.97       711
   macro avg       0.97      0.97      0.97       711
weighted avg       0.97      0.97      0.97       711

========================	test end	========================

========================	2023-05-14 09:50:10	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2112	 train accuracy: 100.000	 validation loss: 0.2430	 validation accuracy: 98.731 
train(max_min): 	train loss: 0.2109	 train accuracy: 100.000	 validation loss: 0.2427	 validation accuracy: 98.872 
best val accuracy: 98.871650 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0969 	 test accuracy:	 97.750 
confusion matrix: 
[365   9]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.98      0.98       374
         MDD       0.97      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

test: 			test loss: 	0.0982 	 test accuracy:	 97.750 
confusion matrix: 
[364  10]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.97      0.98       374
         MDD       0.97      0.98      0.98       337

    accuracy                           0.98       711
   macro avg       0.98      0.98      0.98       711
weighted avg       0.98      0.98      0.98       711

========================	test end	========================

========================	2023-05-14 09:56:39	========================
model name: 	MTCN_finetune_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue
addition: 	parameter setting:	model_name: MTCN_finetune_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2013	 train accuracy: 100.000	 validation loss: 0.2065	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.2013	 train accuracy: 100.000	 validation loss: 0.2053	 validation accuracy: 99.577 
best val accuracy: 99.576869 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0751 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0742 	 test accuracy:	 99.015 
confusion matrix: 
[371   3]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-14 10:02:13	========================
model name: 	MTCN_finetune_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue
addition: 	parameter setting:	model_name: MTCN_finetune_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2052	 train accuracy: 100.000	 validation loss: 0.2231	 validation accuracy: 99.154 
train(max_min): 	train loss: 0.2052	 train accuracy: 100.000	 validation loss: 0.2206	 validation accuracy: 99.718 
best val accuracy: 99.717913 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0761 	 test accuracy:	 98.875 
confusion matrix: 
[373   1]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      1.00      0.99       374
         MDD       1.00      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0724 	 test accuracy:	 99.297 
confusion matrix: 
[373   1]
[  4 333]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-14 10:06:08	========================
model name: 	MTCN_finetune_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue
addition: 	parameter setting:	model_name: MTCN_finetune_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2016	 train accuracy: 100.000	 validation loss: 0.2133	 validation accuracy: 99.013 
train(max_min): 	train loss: 0.2015	 train accuracy: 100.000	 validation loss: 0.2121	 validation accuracy: 99.295 
best val accuracy: 99.294781 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0830 	 test accuracy:	 98.734 
confusion matrix: 
[371   3]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0927 	 test accuracy:	 98.594 
confusion matrix: 
[371   3]
[  7 330]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-14 10:14:07	========================
model name: 	MTCN_finetune_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue
addition: 	parameter setting:	model_name: MTCN_finetune_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainTrue	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: True	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2024	 train accuracy: 100.000	 validation loss: 0.2194	 validation accuracy: 98.449 
train(max_min): 	train loss: 0.2022	 train accuracy: 100.000	 validation loss: 0.2189	 validation accuracy: 99.013 
best val accuracy: 99.012694 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0772 	 test accuracy:	 98.734 
confusion matrix: 
[371   3]
[  6 331]

classification report: 
              precision    recall  f1-score   support

          HC       0.98      0.99      0.99       374
         MDD       0.99      0.98      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0834 	 test accuracy:	 98.734 
confusion matrix: 
[370   4]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-14 19:47:27	========================
model name: 	MTCN_finetune_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_finetune_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	train begin	========================
train(final): 		train loss: 0.2012	 train accuracy: 100.000	 validation loss: 0.2037	 validation accuracy: 99.577 
train(max_min): 	train loss: 0.2012	 train accuracy: 100.000	 validation loss: 0.2008	 validation accuracy: 100.000 
best val accuracy: 100.000000 	 corresponding train accuracy: 100.000000
========================	train end	========================

========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0696 	 test accuracy:	 99.156 
confusion matrix: 
[373   1]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

test: 			test loss: 	0.0740 	 test accuracy:	 99.156 
confusion matrix: 
[371   3]
[  3 334]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      0.99      0.99       374
         MDD       0.99      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711

========================	test end	========================

========================	2023-05-14 20:08:00	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	test begin	========================

========================	test begin	========================
test: 			test loss: 	0.0696 	 test accuracy:	 99.156 
confusion matrix: 
[373   1]
[  5 332]

classification report: 
              precision    recall  f1-score   support

          HC       0.99      1.00      0.99       374
         MDD       1.00      0.99      0.99       337

    accuracy                           0.99       711
   macro avg       0.99      0.99      0.99       711
weighted avg       0.99      0.99      0.99       711


========================	2023-05-14 20:09:30	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-14 20:16:27	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-14 20:18:47	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	


========================	2023-05-14 20:21:45	========================
model name: 	MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse
addition: 	parameter setting:	model_name: MTCN_AT_DIFF_MODMA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse	epochs: 100	lr: 0.0004	pretrain_model_path: models/MTCN_AT_DIFF_CASIA_order3_drop1_epoch100_l2re2_lr0004_pretrainFalse.pt	batch_size: 64	spilt_rate: [0.6, 0.2, 0.2]	weight_decay: 0.2	optimizer_type: 2	beta1: 0.93	beta2: 0.98	gamma: 0.3	step_size: 30	random_seed: 34	model_type: MTCN	data_type: mfcc	save: True	scheduler_type: 1	warmup: 400	initial_lr: 0.05	load_weight: False	dataset_name: MODMA	order: 3	version: V1	multi_type: AT_DIFF	merge_type: linear	patience: 10	d_model: 256	n_head: 8	d_qkv: 64	d_ff: 1024	n_layer: 3	feature_dim: 39	dilation: 8	filters: 39	kernel_size: 2	drop_rate: 0.1	seq_len: 313	num_class: 2	

