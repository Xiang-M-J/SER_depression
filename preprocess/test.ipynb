{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "a = np.random.random([1,160000])\n",
    "b = librosa.feature.mfcc(y=a,sr=16000, n_mfcc=13, win_length=800, hop_length=512)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data1 = np.load(\"npy/MODMA.npy\", allow_pickle=True).item()\n",
    "x1 = data1['x']\n",
    "data2 = np.load(\"npy/MODMA___.npy\", allow_pickle=True).item()\n",
    "x2 = data2['x']\n",
    "print(x1.shape)\n",
    "print(x2.shape)\n",
    "print(np.std(abs(x1-x2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import nnAudio.Spectrogram\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "data = np.random.random([10,160000])\n",
    "transform_mfcc = torchaudio.transforms.MFCC(sample_rate=16000, n_mfcc=13,\n",
    "                                                melkwargs={\"n_fft\": 800, \"hop_length\": 512})\n",
    "nn_mfcc = nnAudio.Spectrogram.MFCC(sr=16000, n_mfcc=13, n_fft=800, hop_length=512)\n",
    "y = transform_mfcc(torch.Tensor(data))\n",
    "y_ = librosa.feature.mfcc(y=data, sr=16000, n_mfcc=13, n_fft=800)\n",
    "y_2 = nn_mfcc(torch.Tensor(data))\n",
    "print(np.mean(abs(y_2.numpy()-y_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = np.load(\"npy/scores.npy\", allow_pickle=True)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torchaudio.transforms\n",
    "import torch\n",
    "import torchaudio.functional as F\n",
    "import time\n",
    "import numpy as np\n",
    "a = np.random.random([1, 441000]).astype(np.float32)\n",
    "resample = torchaudio.transforms.Resample(44100, 16000)\n",
    "\n",
    "T1 = time.time()\n",
    "y = librosa.resample(a, orig_sr=44100, target_sr=16000)\n",
    "T2 = time.time()\n",
    "print(T2-T1)\n",
    "T1 = time.time()\n",
    "y1 = F.resample(\n",
    "    torch.Tensor(a),\n",
    "    44100,\n",
    "    16000,\n",
    "    lowpass_filter_width=16,\n",
    "    rolloff=0.95,\n",
    "    resampling_method=\"kaiser_window\",\n",
    "    beta=14,\n",
    ")\n",
    "T2 = time.time()\n",
    "print(T2-T1)\n",
    "T1 = time.time()\n",
    "y2 = resample(torch.Tensor(a))\n",
    "T2 = time.time()\n",
    "print(T2-T1)\n",
    "print(np.sum(abs(y - y1.numpy())))\n",
    "print(np.sum(abs(y - y2.numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "a = np.random.random([10, 44100])\n",
    "b = np.random.random([10, 16000])\n",
    "\n",
    "a_mfcc = librosa.feature.mfcc(y=a, sr=44100, n_mfcc=13)\n",
    "b_mfcc = librosa.feature.mfcc(y=b, sr=16000, n_mfcc=13)\n",
    "print(a_mfcc.shape)\n",
    "print(b_mfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from process_utils import get_file_dict\n",
    "conf = np.load(\"npy/conf.npy\", allow_pickle=True).item()\n",
    "key = list(conf.keys())[0]\n",
    "wav_dict = get_file_dict(\"MODMA\")\n",
    "\n",
    "concat_data = None\n",
    "concat_data_ = None\n",
    "for wav in (wav_dict[key]):\n",
    "    data, sr = torchaudio.load(wav)\n",
    "    if concat_data is None:\n",
    "        concat_data = data\n",
    "    else:\n",
    "        concat_data = torch.cat([concat_data, data], dim=1)\n",
    "\n",
    "for wav in (wav_dict[key]):\n",
    "    data, sr = librosa.load(wav, sr=None)\n",
    "    if concat_data_ is None:\n",
    "        concat_data_ = data\n",
    "    else:\n",
    "        concat_data_ = np.hstack([concat_data_, data])\n",
    "print(np.sum(abs(concat_data.numpy()-concat_data_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "torchaudio.save()对于librosa是无损保存(当保存为float32类型时)，非float32也只有微小的精度损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.random.random([441000])\n",
    "y1 = librosa.resample(data, orig_sr=44100, target_sr=16000).astype(np.float32)\n",
    "torchaudio.save(\"tmp.wav\", torch.Tensor(y1).unsqueeze(0), sample_rate=16000)\n",
    "time.sleep(0.3)\n",
    "data, sr = librosa.load(\"tmp.wav\", sr=None)\n",
    "print(np.sum(abs(y1-data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from header import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "data = np.load(\"npy/ABC.npy\", allow_pickle=True).item()\n",
    "x = data['x']\n",
    "x = x[200]\n",
    "df = pd.DataFrame(x.T)\n",
    "plt.figure(figsize=(100,100))\n",
    "sns.heatmap(df.corr(),annot=True, vmax=1, square=True)\n",
    "plt.savefig(\"corr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from header import *\n",
    "from process_utils import data_distribution\n",
    "distribute = data_distribution(\"MODMA\")\n",
    "index = np.array(list(distribute.index))\n",
    "value = distribute.values\n",
    "no_zero_index = value != 0\n",
    "index = index[no_zero_index]\n",
    "value = value[no_zero_index]\n",
    "index_ = list(index[:9].astype(str))\n",
    "index_.append(\"(46,]\")\n",
    "value_ = list(value[:9])\n",
    "value_.append(np.sum(value[9:]))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.pie(value_, labels=index_, autopct='%1.1f%%')\n",
    "plt.title(\"MODMA数据集音频时长(s)分布\")\n",
    "plt.axis('equal')\n",
    "# plt.xlabel(\"时长分布(s)\")\n",
    "# plt.ylabel(\"样本数\")\n",
    "plt.savefig(\"dis.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from header import *\n",
    "import seaborn as sns\n",
    "data = np.load(\"data/MODMA_V1_order3.npy\", allow_pickle=True).item()\n",
    "x = data['x']\n",
    "x = x[1000]\n",
    "df = pd.DataFrame(x.T)\n",
    "plt.figure(figsize=(40,40))\n",
    "sns.heatmap(df.corr(),annot=True, vmax=1, square=True)\n",
    "plt.savefig(\"corr_order3.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from header import *\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "data = np.load(\"data/MODMA_V1_order3.npy\", allow_pickle=True).item()\n",
    "x = data['x']\n",
    "X = x[0].T\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "K = 5\n",
    "total_labels = []\n",
    "for k in range(K):\n",
    "    gmm = GMM(n_components=100).fit(X)\n",
    "    labels = gmm.predict(X)\n",
    "    total_labels.append(labels)\n",
    "\n",
    "# total_mono_labels = []\n",
    "total_labels2index = []\n",
    "for k in range(K):\n",
    "    labels = total_labels[k]\n",
    "    mono_labels = []\n",
    "    labels2index = []\n",
    "    for i in range(1, len(labels)):\n",
    "        if labels[i] not in mono_labels:\n",
    "            mono_labels.append(labels[i])\n",
    "            labels2index.append(i)\n",
    "    # total_mono_labels.append(mono_labels)\n",
    "    total_labels2index.append(labels2index)\n",
    "\n",
    "label2index = np.array(total_labels2index).flatten()\n",
    "label2index = Counter(label2index)\n",
    "a1 = sorted(label2index.items(),key = lambda x:x[1],reverse = True)\n",
    "b = np.array(a1[:100])\n",
    "index = np.sort(b[:,0])\n",
    "print(index)\n",
    "# print(label2index.keys())\n",
    "# print(label2index.values())\n",
    "# print(len(label2index.keys()))\n",
    "# print(list(set(labels)))\n",
    "# total_labels.append(labels)\n",
    "# print(len(total_labels))\n",
    "# print(len(labels))\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from process_utils import multiGMM\n",
    "import numpy as np\n",
    "path = \"data/MODMA_V1_order3.npy\"\n",
    "data = np.load(path, allow_pickle=True).item()\n",
    "x = data['x']\n",
    "X = x[3]\n",
    "# np.count_nonzero(x[3], axis=1)\n",
    "diff_x = np.diff(X, axis=1)\n",
    "counts = np.count_nonzero(diff_x, axis=1)\n",
    "print(max(counts))\n",
    "# b,s,t,w = np.unique(x[3], return_counts=True,return_index=True,return_inverse=True, axis=1)\n",
    "# print(b)\n",
    "# print(s)\n",
    "# print(t)\n",
    "# print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from process_utils import mGMM\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "path = \"data/MODMA_V1_order3.npy\"\n",
    "n_components = 100\n",
    "data = np.load(path, allow_pickle=True).item()\n",
    "x = data['x']\n",
    "X = x[0].T\n",
    "label2index = mGMM(X=X, K=8, n_components=n_components)\n",
    "label2index = np.array(label2index).flatten()\n",
    "label2index_dict = Counter(label2index)\n",
    "label2index_sorted = sorted(label2index_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "label2index = np.array(label2index_sorted[:n_components])\n",
    "index = np.sort(label2index[:, 0])\n",
    "print(label2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: \n",
      "2.065164331597222\n",
      "std: \n",
      "0.8299153548129508\n",
      "max: \n",
      "7.40025\n",
      "min: \n",
      "0.6266875\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0, 1]     221\n(1, 2]    4014\n(2, 3]    2050\n(3, 4]     659\n(4, 5]     204\n(5, 6]      44\n(6, 7]       7\n(7, 8]       1\ndtype: int64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from process_utils import data_distribution\n",
    "data_distribution(\"datasets/IEMOCAP\", step=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_3896\\401080917.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[0msrc_data_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m\"x\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx_src_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"y\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0my_src_\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[0mtgt_data_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m\"x\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx_tgt_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"y\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0my_tgt_\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 32\u001B[1;33m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"data/CASIA_4label.npy\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msrc_data_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     33\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"data/RAVDESS_4label.npy\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtgt_data_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_3896\\401080917.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[0msrc_data_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m\"x\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx_src_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"y\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0my_src_\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[0mtgt_data_\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m\"x\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx_tgt_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"y\"\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0my_tgt_\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 32\u001B[1;33m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"data/CASIA_4label.npy\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msrc_data_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     33\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"data/RAVDESS_4label.npy\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtgt_data_\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_37_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_37_64.PyDBFrame.do_wait_suspend\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mD:\\PyCharm 2022.3.1\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1158\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1159\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1160\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1161\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1162\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\PyCharm 2022.3.1\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1173\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1174\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1175\u001B[1;33m                 \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1176\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1177\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from process_utils import CASIA_code, RAVDESS_code\n",
    "src_data = np.load(\"data/CASIA_V2_order3.npy\", allow_pickle=True).item()\n",
    "tgt_data = np.load(\"data/RAVDESS_V1_order3.npy\", allow_pickle=True).item()\n",
    "x_src = src_data['x']\n",
    "y_src = src_data['y']\n",
    "x_tgt = tgt_data['x']\n",
    "y_tgt = tgt_data['y']\n",
    "src_label = ['anger', 'happy', 'sad', 'surprise']\n",
    "tgt_label = ['anger', 'happy', 'sad', 'surprised']\n",
    "src_id = []\n",
    "tgt_id = []\n",
    "src_index = []\n",
    "tgt_index = []\n",
    "\n",
    "for l in src_label:\n",
    "    id = CASIA_code(l)\n",
    "    for i in range(y_src.shape[0]):\n",
    "        if np.argmax(y_src[i]) == np.argmax(id):\n",
    "            src_index.append(i)\n",
    "for l in tgt_label:\n",
    "    id = RAVDESS_code(l)\n",
    "    for i in range(y_tgt.shape[0]):\n",
    "        if np.argmax(y_tgt[i]) == np.argmax(id):\n",
    "            tgt_index.append(i)\n",
    "x_src_ = x_src[src_index]\n",
    "y_src_ = np.argmax(y_src[src_index])\n",
    "x_tgt_ = x_tgt[tgt_index]\n",
    "y_tgt_ = np.argmax(y_tgt[tgt_index])\n",
    "src_data_ = {\"x\": x_src_, \"y\": y_src_}\n",
    "tgt_data_ = {\"x\": x_tgt_, \"y\": y_tgt_}\n",
    "np.save(\"data/CASIA_4label.npy\", src_data_)\n",
    "np.save(\"data/RAVDESS_4label.npy\", tgt_data_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load(\"data/MODMA_V1_order3_cluster.npy\")\n",
    "data_ = np.load(\"data/MODMA_V1_order3.npy\", allow_pickle=True).item()\n",
    "new_data = {'x': data.astype(np.float32), 'y': data_['y']}\n",
    "np.save(\"data/MODMA_V1_order3_c.npy\", new_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-08T22:17:17.513461Z",
     "end_time": "2023-04-08T22:17:17.868429Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data = np.load(\"data/CASIA_V1_order3.npy\", allow_pickle=True).item()\n",
    "y = data['y']\n",
    "print(y.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-13T13:52:57.176328Z",
     "end_time": "2023-04-13T13:52:58.159324Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load(\"data/CASIA_V1_order3.npy\", allow_pickle=True).item()\n",
    "x, y = data['x'], data['y']\n",
    "x_ = []\n",
    "y_ = []\n",
    "for i in range(x.shape[0]):\n",
    "    if (y[i] == np.array([0, 0, 0, 1, 0, 0])).all():\n",
    "        x_.append(x[i])\n",
    "        y_.append(np.array([1, 0]))\n",
    "    if (y[i] == np.array([0, 0, 0, 0, 1, 0])).all():\n",
    "        x_.append(x[i])\n",
    "        y_.append(np.array([0, 1]))\n",
    "\n",
    "x_ = np.array(x_).astype(np.float32)\n",
    "y_ = np.array(y_).astype(np.float32)\n",
    "data = {'x': x_, 'y': y_}\n",
    "np.save(\"data/CASIA2_V1_order3.npy\", data)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-04T23:36:34.726996Z",
     "end_time": "2023-05-04T23:40:35.005527Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
