{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class C:\n",
    "    def __init__(self,x,y,z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "    def print(self):\n",
    "        for i in self.__dict__:\n",
    "            print(f\"{i}: {self.__dict__[i]}\")\n",
    "\n",
    "c = C(1,2,3)\n",
    "c.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from config import Args\n",
    "arg = Args()\n",
    "arg.write()\n",
    "arg.mode = \"train\"\n",
    "print(\"修改后：\")\n",
    "print(arg.addition())\n",
    "arg.load(\"hyperparameter.npy\")\n",
    "print(\"修改前：\")\n",
    "print(arg.addition())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import plot_2\n",
    "plot_2(\"results/data/pretrain_drop1_mfcc_smoothTrue_epoch100_l2re1_lr0002_train_metric.npy\", \"now\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load(\"pretrain_model.pt\")\n",
    "model_dict = model.state_dict()\n",
    "# for k, v in model_dict.items():\n",
    "#     print(k)\n",
    "\n",
    "model_ = torch.load(\"models/model_drop1_mfcc_smoothTrue_epoch50_l2re1_lr0001_best.pt\")\n",
    "model_dict_ = model_.state_dict()\n",
    "# for k, v in model_dict_.items():\n",
    "#     print(k)\n",
    "pretrained_dict = {k.replace(\"extractor\", \"generalFeatureExtractor\"): v for k, v in model_dict.items() if k.replace(\"extractor\", \"generalFeatureExtractor\") in model_dict_}\n",
    "for k, v in pretrained_dict.items():\n",
    "    print(k)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load(\"preprocess/npy/MODMA_16kHz_fastV3_order2.npy\", allow_pickle=True).item()\n",
    "x = data['x']\n",
    "print(x.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from test_files import test_\n",
    "test_(\n",
    "    model_path=\"models/train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0002_pretrainTrue_best.pt\", wav_path=\"preprocess/MODMA_16kHz\", num=100, num_class=2, order=3)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "files = np.load(\"sample_wav.npy\")\n",
    "# expect_length = 160000\n",
    "# stack_data = None\n",
    "# for wav in files:\n",
    "#     data, sr = torchaudio.load(wav)\n",
    "#     actual_length = data.shape[1]\n",
    "#     if actual_length < expect_length:\n",
    "#         data = torch.cat([data, torch.zeros([1, expect_length - actual_length])], dim=1)\n",
    "#     elif actual_length > expect_length:\n",
    "#         data = data[:, :expect_length]\n",
    "#     if stack_data is None:\n",
    "#         stack_data = data\n",
    "#     else:\n",
    "#         stack_data = torch.cat([stack_data, data], dim=0)\n",
    "# stack_data = stack_data.numpy().astype(np.float32)\n",
    "# mfcc = librosa.feature.mfcc(y=stack_data, sr=16000, n_mfcc=13, n_fft=800)\n",
    "# mfcc_delta = librosa.feature.delta(mfcc, width=3)\n",
    "# mfcc_acc = librosa.feature.delta(mfcc_delta, width=3)\n",
    "# mfcc = np.concatenate([mfcc, mfcc_delta, mfcc_acc], axis=1).astype(np.float32)\n",
    "\n",
    "mfcc_ = np.load(\"mfcc.npy\").astype(np.float32)\n",
    "labels = np.load(\"labels.npy\")\n",
    "data = np.load(\"preprocess/npy/MODMA_16kHz_fastV2_order3.npy\", allow_pickle=True).item()\n",
    "print(data['y'])\n",
    "for i in range(100):\n",
    "    print(f\"{files[i]}:{labels[i]}\")\n",
    "# print(np.max(np.abs(mfcc_-mfcc)))\n",
    "# print(np.min(np.abs(mfcc_)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import smooth_labels\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "a = torch.rand([4, 4])\n",
    "b = torch.Tensor([[1.,0.,0.,0.],\n",
    "                  [0.,1.,0.,0.],\n",
    "                  [0.,0.,1.,0.],\n",
    "                  [0.,1.,0.,0.]])\n",
    "loss1 = F.cross_entropy(a,b,label_smoothing=0.1)\n",
    "loss2 = F.cross_entropy(a, smooth_labels(b, 0.1))\n",
    "print(loss1)\n",
    "print(loss2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import get_newest_file\n",
    "print(get_newest_file(\"models\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class simplemodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simplemodel, self).__init__()\n",
    "        self.share_net = nn.Linear(4, 4, bias=False)\n",
    "        self.fc1 = nn.Linear(4,2, bias=False)\n",
    "        self.fc2 = nn.Linear(4,2, bias=False)\n",
    "    def forward(self, x, index):\n",
    "        x = self.share_net(x)\n",
    "        if index == 1:\n",
    "            x = self.fc1(x)\n",
    "        else:\n",
    "            x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "x1 = torch.rand([4,4])\n",
    "x2 = torch.rand([4,4])\n",
    "y1 = torch.rand([4,2])\n",
    "y2 = torch.rand([4,2])\n",
    "model = simplemodel()\n",
    "# optimizer1 = torch.optim.Adam(\n",
    "#     [{'params': model.share_net.parameters(), 'lr': 0.001},\n",
    "#      {'params': model.fc1.parameters(), 'lr': 2e-3}])\n",
    "# optimizer2 = torch.optim.Adam(\n",
    "#     [{'params': model.share_net.parameters(), 'lr': 0.001},\n",
    "#      {'params': model.fc2.parameters(), 'lr': 2e-3}])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "out1 = model(x1,1)\n",
    "out2 = model(x2,2)\n",
    "print(model.share_net.weight)\n",
    "print(model.fc1.weight)\n",
    "print(model.fc2.weight)\n",
    "loss1 = F.cross_entropy(out1, y1)\n",
    "loss2 = F.cross_entropy(out2, y2)\n",
    "# optimizer1.zero_grad()\n",
    "# loss1.backward()\n",
    "# optimizer1.step()\n",
    "optimizer.zero_grad()\n",
    "loss1.backward()\n",
    "optimizer.step()\n",
    "print(\"loss1: \")\n",
    "print(model.share_net.weight)\n",
    "print(model.fc1.weight)\n",
    "print(model.fc2.weight)\n",
    "# optimizer2.zero_grad()\n",
    "# loss2.backward()\n",
    "# optimizer2.step()\n",
    "optimizer.zero_grad()\n",
    "loss2.backward()\n",
    "optimizer.step()\n",
    "print(\"loss2: \")\n",
    "print(model.share_net.weight)\n",
    "print(model.fc1.weight)\n",
    "print(model.fc2.weight)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import smooth_labels\n",
    "import torch\n",
    "\n",
    "x = torch.rand([100,16])\n",
    "y = torch.rand([100,16])\n",
    "loss1 = torch.nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "loss2 = torch.nn.CrossEntropyLoss()\n",
    "print(loss1(x,y))\n",
    "print(loss2(x, smooth_labels(y,0.1)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "lr = 1e-3\n",
    "lrs = []\n",
    "for i in range(100):\n",
    "    lr_ = lr * (1. - i/100)\n",
    "    lrs.append(lr_)\n",
    "\n",
    "plt.plot(lrs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def print_(model):\n",
    "    for name, params in model.named_parameters():\n",
    "        print('-->name:', name)\n",
    "        print('-->para:', params)\n",
    "        print('-->grad_requires:', params.requires_grad)\n",
    "        print('-->grad_value:', params.grad)\n",
    "        print(\"===\")\n",
    "\n",
    "class simpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simpleModel, self).__init__()\n",
    "        self.l = nn.Linear(4,2, bias=False)\n",
    "    def forward(self,x):\n",
    "        x = self.l(x)\n",
    "        return x\n",
    "\n",
    "def train_step(model, optimizer, x, y):\n",
    "    out = model(x)\n",
    "    loss = torch.nn.CrossEntropyLoss()(out, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "x = torch.rand([4,4])\n",
    "y = torch.rand([4,2])\n",
    "model = simpleModel()\n",
    "print_(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "train_step(model, optimizer, x,y)\n",
    "print_(model)\n",
    "\n",
    "train_step(model, optimizer, x, y)\n",
    "print_(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops.layers.torch import Rearrange\n",
    "model1 = nn.Sequential(\n",
    "    Rearrange(\"N L C W -> N L (C W)\"),\n",
    "    Rearrange(\"N L C -> N C L\"),\n",
    ")\n",
    "model2 = Rearrange(\"N L C W -> N C (L W)\")\n",
    "x = torch.rand([4,313,39,1])\n",
    "y1 = model1(x)\n",
    "y2 = model2(x)\n",
    "print(torch.sum(torch.abs(y1-y2)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load(\"models/SET_official_train_order3_drop1_mfcc_smoothTrue_epoch60_l2re1_lr0008_pretrainFalse.pt\")\n",
    "torch.save(model, \"test.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "wav, sr = librosa.load(\"preprocess/datasets/RAVDESS/anger/03-01-05-01-01-01-01.wav\", sr=None)\n",
    "mfcc = librosa.feature.mfcc(y=wav, sr=sr)\n",
    "print(mfcc.shape)\n",
    "mfcc_mean = np.mean(mfcc.T, axis=0)\n",
    "print(mfcc_mean.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from einops.layers.torch import Rearrange\n",
    "import torch\n",
    "x = torch.rand([4, 13, 100])\n",
    "y1 = x.view(x.shape[0], -1)\n",
    "y2 = Rearrange(\"N C L -> N (C L)\")(x)\n",
    "print(torch.sum(torch.abs(y1-y2)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import myDataset\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "x = np.arange(20)\n",
    "y = np.arange(20)\n",
    "dataset = myDataset(x, y)\n",
    "loader = torch.utils.data.dataloader.DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=False\n",
    ")\n",
    "train_iter = iter(loader)\n",
    "print(len(loader))\n",
    "for _ in range(10):\n",
    "    try:\n",
    "        print(next(train_iter))\n",
    "    except StopIteration:\n",
    "        train_iter = iter(loader)\n",
    "        print(next(train_iter))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cat([torch.zeros([12, 1]), torch.ones([12, 1])], dim=1).float()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from utils import print_model\n",
    "class simplemodel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simplemodel, self).__init__()\n",
    "        self.base = nn.Linear(4,4, bias=False)\n",
    "        self.l1 = nn.Linear(4,3, bias=False)\n",
    "        self.l2 = nn.Linear(4,2, bias=False)\n",
    "    def forward(self, x, flag):\n",
    "        x = self.base(x)\n",
    "        if flag:\n",
    "            x = self.l1(x)\n",
    "        else:\n",
    "            x = self.l2(x)\n",
    "        return x\n",
    "\n",
    "model = simplemodel()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "x = torch.rand([4,4])\n",
    "y1_ = torch.rand([4,3])\n",
    "y2_ = torch.rand([4,2])\n",
    "y1 = model(x, True)\n",
    "y2 = model(x, False)\n",
    "loss1 = torch.nn.CrossEntropyLoss()(y1, y1_)\n",
    "loss2 = torch.nn.CrossEntropyLoss()(y2, y2_)\n",
    "loss = loss1+loss2\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "print_model(model)\n",
    "optimizer.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test():\n",
    "    x = [[1,2,3], [2,3,4], [3,4,5]]\n",
    "    return x\n",
    "x,y,z = test()\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import plot\n",
    "import numpy as np\n",
    "wav2vec2_data = np.load(\"ser_pretrain/results/wav2vec2.npy\", allow_pickle=True).item()\n",
    "# plot(wav2vec2_data, model_name=\"wav2vec2\",result_path=\"ser_pretrain/results/\")\n",
    "print(np.max(wav2vec2_data['val_acc']))\n",
    "print(wav2vec2_data['train_acc'][np.argmax(wav2vec2_data['val_acc'])])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utils import plot\n",
    "import numpy as np\n",
    "hubert_data = np.load(\"ser_pretrain/results/hubert.npy\", allow_pickle=True).item()\n",
    "# plot(wav2vec2_data, model_name=\"hubert\",result_path=\"ser_pretrain/results/\")\n",
    "print(np.max(hubert_data['val_acc']))\n",
    "print(hubert_data['train_acc'][np.argmax(hubert_data['val_acc'])])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_accuracy = [1,2,5,6,7,7,7,10,5,5,5,5,5,5,5,5]\n",
    "from utils import EarlyStopping\n",
    "early_stop = EarlyStopping(5)\n",
    "for i in range(len(val_accuracy)):\n",
    "    print(val_accuracy[i])\n",
    "    if early_stop(val_accuracy[i]):\n",
    "        break\n",
    "print(\"hello\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "model = torch.load(\"models/MultiTIM_train_DAIC_order3_drop1_mfcc_epoch20_l2re2_lr0001_pretrainFalse_clusterFalse.pt\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops.layers.torch import Rearrange\n",
    "# merge = nn.Sequential(\n",
    "#             Rearrange(\"N C L H -> N (C L) H\"),\n",
    "#             nn.AdaptiveAvgPool1d(1),\n",
    "#             Rearrange(\"N (C L) -> N C L H\", C=3)\n",
    "#         )\n",
    "x = torch.rand([2,3,4,2])\n",
    "y = Rearrange(\"N C L H -> N (C L) H\")(x)\n",
    "y = nn.AdaptiveAvgPool1d(1)(y)\n",
    "y = Rearrange(\"N (C L) H -> N C L H\", C=3)(y)\n",
    "y1 = torch.mean(x, dim=-1, keepdim=True)\n",
    "print(x)\n",
    "print(y)\n",
    "print(y1-y)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-18T22:25:29.669576Z",
     "end_time": "2023-04-18T22:25:29.677549Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
